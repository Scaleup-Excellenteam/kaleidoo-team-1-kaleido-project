[
  {
    "filetype": "application/pdf",
    "text": "1\nFinding lines ‚Äì part 2\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\nÔÅΩ Edge detection\nÔÅΩ Canny edge detector ÔÅΩ Berkeley edge probability\nÔÅΩ Line fitting\nÔÅΩ Hough transform ÔÅΩ (Generalized) Hough transform application ÔÅΩ RANSAC\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting a parametric model to data\n# parameters 2 parametric equation\ny = mx + b\n3 r2 = (x-x0)2 + (y-y0)2\nparameters m, b\nr, x0, y0\nImage credit Zhaozheng Yin @ wisc.edu\nImage credit Yuan-Liang Tang on Mathworks\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting a parametric model to data\nÔÅΩ Design questions:\nÔÅΩ What is a good model to represent our data? ÔÅΩ Do we plan to fit multiple instances?\nÔÅΩ Challenges:\nÔÅΩ Which features belong to the model? To which instance? ÔÅΩ How many instances are there? ÔÅΩ Computational complexity (typically we cannot examine all\npossible models).\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\ndetection of power lines in helicopter navigation systems\nImage credit: Horev et al. SIAM‚Äô15\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\nlane detection from car cameras in crashpreventing systems\n6\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\ndetection of long filaments in high-throughput biological imaging\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\nSports\n8\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\n‚ÄúInteractive 3D Architectural Modeling from Unordered Photo Collections‚Äù Sinha et al. 2008\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Challenges of line fitting\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Challenges of line fitting\nÔÅΩ Which points on which line? ÔÅΩ Noisy edge detection:\nÔÅΩ Clutter ÔÅΩ Missed parts ÔÅΩ Points are only approximately\nalong the line\nÔÅΩ Large search space. ÔÅΩ How many lines are there?\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Voting\nÔÅΩ Problem:\nÔÅΩ We cannot try all possible models\nÔÅΩ Solution by voting:\nÔÅΩ Features (points) vote for models they are compatible with ÔÅΩ Search for models with lots of votes\nfeature space\nmodel space\n2\nVoting\nr e e m a r a p\nt\nl\ne d o M\nModel parameter 1\n12\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\nÔÅΩ\n14\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\nÔÅΩ\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\nÔÅΩ\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Finding lines with the Hough transform\nÔÅΩ Discretize Hough space ÔÅΩ Each edge point votes for all possible parameters in Hough\nspace\nÔÅΩ Parameters with lots of votes indicate lines in image space\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Polar representation for lines\nÔÅΩ\nd\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough-transform algorithm\nÔÅΩ\n19\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example\nFor a given point (x0,y0)\nd(q)=x0cosq+y0sinq\ny\nd\nx\n20\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Example\nFor a given point (x0,y0)\nd(q)=x0cosq+y0sinq\ny\nd\nx\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: an image with straight lines\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Properties\nÔÅΩ Noise and clutter votes are inconsistent, so will not\naccumulate.\nÔÅΩ Can handle occlusions if not all points are present as long as\nmodel gets enough votes.\nÔÅΩ Efficient.\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: a real image\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: a real image\n25\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Impact of noise on Hough transform\nÔÅΩ What difficulties does noise introduce?\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Impact of noise on Hough transform\nÔÅΩ Here everything is ‚Äúnoise‚Äù but we still see peaks in the\nvote space\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Voting: Practical tips\nÔÅΩ Use only trustworthy points\nÔÅΩ E.g., edges points with significant gradient magnitude\n(alternatively weight votes)\nÔÅΩ Szeliski suggests using edgels instead of points\nÔÅΩ Choose a good quantization grid\nÔÅΩ Not too coarse ‚Äì too many lines fall in the same bucket ÔÅΩ Not too fine ‚Äì collinear points vote for different lines\nÔÅΩ Smooth the voting (vote also for neighbors) ÔÅΩ Non-maxima suppression ÔÅΩ Refit line using accumulated votes ÔÅΩ Reduce number of parameters, if possible\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hough transform summary\nÔÅΩ Pros\nÔÅΩ Can handle occlusions ÔÅΩ Some robustness to noise ÔÅΩ Can detect multiple lines in a single pass over the image\nÔÅΩ Cons\nÔÅΩ Clutter can produce spurious peaks in parameter space ÔÅΩ Hard to select the right quantization\n29\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Generalized Hough Transform\nÔÅΩ Can be extended to other parametric models such as:\ncircles, ellipses, rectangles etc.\nÔÅΩ Complexity increases exponentially with the number of\nparameters.\nÔÅΩ Can be used to detect complex non-parametric models as\ndescribed in Leibe et al. ‚ÄúCombined object categorization and segmentation with an implicit shape model‚Äù.\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\nÔÅΩ Edge detection\nÔÅΩ Canny edge detector ÔÅΩ Berkeley edge probability\nÔÅΩ Line fitting\nÔÅΩ Hough transform ÔÅΩ RANSAC\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANdom SAmple Consensus [Fischler & Bolles 1981]\nÔÅΩ Key ideas:\nÔÅΩ Look for ‚Äúinliers‚Äù and use only them ÔÅΩ If we fit a model to ‚Äúoutliers‚Äù we will not get a good fitting\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC algorithm\nLoop: 1.Randomly select a group of points 2.Fit a model to the selected group 3.Find the inliers of the computed model 4.If number of inliers is large enough re-compute model using only inliers 5.Compute number of inliers of updated model The winner: model with the largest number of inlier\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\nÔÅΩ Input:\nA set of edge points\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\nÔÅΩ Step 1:\nSelect two points\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\nÔÅΩ Step 2:\nFit a line to the selected points\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\nÔÅΩ Step 3:\nIdentify inliers\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\nÔÅΩ Step 4:\nFit line to inliers\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\nÔÅΩ Step 5:\nCount number of new inliers\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC ‚Äì stopping criteria\nÔÅΩ\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC ‚Äì for multiple models?\nÔÅΩ How can we use RANSAC to compute multiple models?\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC - summary\nÔÅΩ Pros\nÔÅΩ General method that works well for lots of model fitting\nproblems\nÔÅΩ Easy to implement\nÔÅΩ Cons\nÔÅΩ When the percentage of outliers is high too many iterations\nare needed and failure rate increases\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "43\nEnd ‚Äì finding lines\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nFinding lines ‚Äì part 1\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\nÔÅΩ Edge detection\nÔÅΩ Canny edge detector ÔÅΩ Berkeley edge probability\nÔÅΩ Line fitting\nÔÅΩ Hough transform ÔÅΩ RANSAC\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why edges?\nÔÅΩ We know edges are special\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge detection - goal\nÔÅΩ Goal:\nMap image from 2d array of pixels to a set of curves or line segments or contours. ÔÅΩ Most semantic and shape information from the image can be\nencoded in the edges\nÔÅΩ A more compact representation than a complete image\nÔÅΩ Ideal:\nArtist‚Äôs Line drawing (but artists use prior knowledge)\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What can cause an edge?\nSurface normal discontinuity\nDepth discontinuity\nIllumination discontinuity\nSurface color discontinuity\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What can cause an edge?\nReflectance change: appearance information, texture\nChange in surface orientation: shape\n6\nLihi Zelnik-Manor, Computer Vision\nDepth discontinuity: object boundary\nCast shadows",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contrast and invariance\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edges look like steep cliffs\n8\nLihi Zelnik-Manor, Computer Vision\nSource: S. Seitz",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\nÔÅΩ Edge detection\nÔÅΩ Canny edge detector ÔÅΩ Berkeley edge probability\nÔÅΩ Line fitting\nÔÅΩ Hough transform ÔÅΩ RANSAC\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivatives and edges\nÔÅΩ An edge is a place of rapid change in the image intensity\nfunction.\nimage\nintensity function (along horizontal scanline)\nfirst derivative\nedges correspond to extrema of derivative\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image gradient\nThe gradient of an image:\nThe gradient points in the direction of most rapid change in intensity\nThe gradient direction (orientation of edge normal) is given by:\nThe edge strength is given by the gradient magnitude\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Differentiation and convolution\nFor 2D function, f(x,y), the partial derivative is:\nÔÅ•ÔÅ•ÔÅ•),(),(lim),(0yxfyxfxyxfÔÄ≠ÔÄ´ÔÄΩÔÇ∂ÔÇ∂ÔÇÆ\nFor discrete data, we can approximate using finite differences:\n(,)(1,)(,)fxyfxyfxyxxÔÇ∂ÔÄ´ÔÄ≠ÔÇªÔÇ∂ÔÅÑ\nTo implement above as convolution, what would be the associated filter?\n1 1\n12\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Assorted finite difference filters\n>> My = fspecial(‚Äòsobel‚Äô); >> outim = imfilter(double(im), My); >> imagesc(outim); >> colormap gray;\n13\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Partial derivatives of an image\nxyxfÔÇ∂ÔÇ∂),(\nWhich shows changes with respect to x? y?\n14\nLihi Zelnik-Manor, Computer Vision\nyyxfÔÇ∂ÔÇ∂),(",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Intensity profile of one row\nIntensity\nGradient\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\nConsider a single row or column of the image\nÔÅΩ Plotting intensity as a function of position gives a signal\nWhere is the edge?\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\nÔÅΩ Finite difference filters respond strongly to noise\nÔÅΩ Image noise results in pixels that look very different from\ntheir neighbors\nÔÅΩ Generally, the larger the noise the stronger the response\nÔÅΩ What can be done?\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\nÔÅΩ Finite difference filters respond strongly to noise\nÔÅΩ Image noise results in pixels that look very different from\ntheir neighbors\nÔÅΩ Generally, the larger the noise the stronger the response\nÔÅΩ What can be done?\nÔÅΩ Smoothing the image should help ‚Äì it forces pixels to look\nmore like their neighbors\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Solution: smooth first\nf\ng\nfgÔÄ™\nÔÄ®ÔÄ©dfgdxÔÄ™\nWhere is the edge?\nLook for peaks in\n19\nLihi Zelnik-Manor, Computer Vision\nÔÄ®ÔÄ©dfgdxÔÄ™",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative theorem of convolution\nDifferentiation property of convolution:\nf\ndgdx\ndfgdxÔÄ™\n20\nLihi Zelnik-Manor, Computer Vision\nÔÄ®ÔÄ©\nddfgfgdxdxÔÄ™ÔÄΩÔÄ™",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative of Gaussian filter\nÔÅõÔÅù11ÔÄ™ÔÄ≠ÔÄΩ\nIs this a separable filter?\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative of Gaussian filters\nx-direction\ny-direction\nWhich one finds horizontal/vertical edges?\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smoothing tradeoffs\n1 pixel\n3 pixels\n7 pixels\nSmoothed derivative removes noise, but blurs edge. Also finds edges at different ‚Äúscales‚Äù.\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Laplacian of Gaussian (LoG filter)\nf\n22dgdx\n22dfgdxÔÄ™\nWhere is the edge? Zero-crossings of bottom graph\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "2D edge detection filters\nGaussian\nderivative of Gaussian\ng\ndgdx\n25\nLihi Zelnik-Manor, Computer Vision\nLaplacian of Gaussian\n2222dgdgdxdyÔÄ´",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "DoG = Difference of Gaussians\nÔÅΩ Can approximate Laplacian filter\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is a good edge detector? ÔÅΩ Good detection:\nÔÅΩ Minimize false positives (wrong detections)\nÔÅΩ Minimize false negatives (missing real edges)\nÔÅΩ Maximize true detections\nÔÅΩ Good localization:\nÔÅΩ Detected edges should be as close as possible to the\ntrue edges\nÔÅΩ Single response:\nÔÅΩ Return a single detection for each true edge point\nÔÅΩ Connect detections to lines\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is a good edge detector? ÔÅΩ Good detection\nÔÅΩ Good localization\nÔÅΩ Single response\nWhich of these detections is the best?\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What are the parameters?\nÔÅΩ Scale ÔÅΩ Threshold\n29\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scale selection\nÔÅΩ Recall: We first smooth the image with a Gaussian\nkernel to reduce noise.\nÔÅΩ The scale of the Gaussian determines how much\nsmoothing we apply\n‚Ä¶\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effect of œÉ on derivatives\nÔÅΩ The apparent structures differ depending on Gaussian‚Äôs\nscale parameter.\nÔÅΩ Large scale: larger scale edges detected ÔÅΩ Small scale: finer features detected\nœÉ = 1 pixel\nœÉ = 3 pixels\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "How do we chose the scale? ÔÅΩ It depends what we‚Äôre looking for:\nÔÅΩ Too fine of a scale‚Ä¶can‚Äôt see the forest for the trees. ÔÅΩ Too coarse of a scale‚Ä¶can‚Äôt tell the maple grain from the\ncherry.\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What are the parameters?\nÔÅΩ Scale ÔÅΩ Threshold\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Thresholding\nÔÅΩ Choose a threshold value ÔÅΩ Set any pixels less than thresh to zero (off) ÔÅΩ Set any pixels greater than or equal to thresh to one (on)\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original image\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Gradient magnitude\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Using a low threshold\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Using a higher threshold\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Canny edge detector\nÔÅΩ Probably the most widely used edge detector in computer\nvision\nÔÅΩ Key idea:\ndetect step-edges that are corrupted by additive Gaussian noise\nÔÅΩ Theorem:\nCanny has shown that the first derivative of the Gaussian closely approximates the operator that optimizes the product of signal-to-noise ratio and localization\nJ. Canny, A Computational Approach To Edge Detection, IEEE Trans. Pattern Analysis and Machine Intelligence, 8:679--‚Äê714, 1986.\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Canny edge detector\nÔÅΩ\nÔÅΩ\nÔÅΩ\nÔÅΩ\nFilter image with derivative of Gaussian Find magnitude and orientation of gradient Non-maximum suppression: (Localization) ÔÅΩ Thin multi-pixel wide ‚Äúridges‚Äù down to single pixel width Linking and thresholding (hysteresis): (Linking) ÔÅΩ Define two thresholds: low and high ÔÅΩ Use the high threshold to start edge curves and the low\nthreshold to continue them\nÔÅΩ\nMATLAB: edge(image, ‚Äòcanny‚Äô);\nÔÅΩ\n>>help edge\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example - input\noriginal image (Lena)\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example ‚Äì step 1\nnorm of the gradient\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example ‚Äì step 2\nthresholding\n43\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example ‚Äì step 3\nthresholding\n44\nLihi Zelnik-Manor, Computer Vision\nHow to turn these thick regions of the gradient into curves?",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Non-maximum suppression\nCheck if pixel q is local maximum along gradient direction,\nselect single max across width of the edge ÔÅΩ requires checking interpolated pixels p and r\n45\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example ‚Äì step 3\nThinning (non-maximum supression)\n46\nLihi Zelnik-Manor, Computer Vision\nProblem: pixels along this edge didn‚Äôt survive the thresholding",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge linking\nÔÅΩ Assume the marked point is an edge point. ÔÅΩ Then we construct the tangent to the edge curve (which is normal to the gradient at that point) and use this to predict the next points (here either r or s).\n47\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nÔÅΩ Check that maximum value of gradient value is\nsufficiently large ÔÅΩ drop-outs? use hysteresis\nÔÅΩ use a high threshold to start edge curves and a low threshold to\ncontinue them.\n48\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\noriginal image\nhigh threshold (strong edges)\nlow threshold (weak edges)\n49\nLihi Zelnik-Manor, Computer Vision\nhysteresis threshold",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nhigh threshold (strong edges)\n50\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nlow threshold (weak edges)\n51\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nhysteresis threshold\n52\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Canny - results\n53\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Object boundaries vs. edges\nBackground 54\nTexture\nLihi Zelnik-Manor, Computer Vision\nShadows",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\nÔÅΩ Edge detection\nÔÅΩ Canny edge detector ÔÅΩ Berkeley edge probability\nÔÅΩ Line fitting\nÔÅΩ Hough transform ÔÅΩ RANSAC\n55\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "At Berkeley:\n1. Collect Data Set of Human segmented images\n2.\nLearn Local Boundary Model for combining brightness, color and texture\n3. Global framework to capture closure, continuity 4. Detect and localize junctions Integrate low, mid and high-level information for grouping and figure-ground segmentation\nD. Martin, C. Fowlkes, D. Tal, J. Malik. \"A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics\", ICCV, 2001\nhtpp://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/\n56\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Berkeley Segmentation DataSet [BSDS]\nInput\nHuman segmentation\n57\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "id"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~1970\n58\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~1990\n59\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~2004\n60\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~2008\nInclude global cues\n61\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "Martin, Fowlkes, Malik PAMI 04\nGradient\nCue Combination\nBrightness\nColor\nModel\nTexture\nÔÅΩ Goal: learn the posterior probability of a boundary\nPb(x,y,ÔÅ±) from local information only\nÔÅΩ Challenges:\nÔÅΩ computing the cues, ÔÅΩ cue combination\n62\nLihi Zelnik-Manor, Computer Vision\nPb",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: gradient cue\nImage\nOE = Oriented Energy\n63\nLihi Zelnik-Manor, Computer Vision\n+",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: brightness and color cues\nImage\nBG = Brightness Gradient\nCG = Color Gradient\n64\nLihi Zelnik-Manor, Computer Vision\nDifference of L* distributions\nBG = œá2(h1(L),h2(L))\nDifference of a* distributions\nCG = œá2(h1(a),h2(a))+ œá2(h1(b),h2(b))",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: texture cue\nImage\nTG = Texture Gradient\n65\nLihi Zelnik-Manor, Computer Vision\nDifference of filter distributions\nTG= ùëì œá2(h1(f),h2(f))",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: cue design\nImage\n66\nLihi Zelnik-Manor, Computer Vision\nMultiple orientations\nMultiple disk radii",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Filter banks\norientations\nscales\n‚ÄúEdges‚Äù\n‚ÄúBars‚Äù\n‚ÄúSpots‚Äù\nÔÅΩ What filters to put in the bank?\nÔÅΩ Typically we want a combination of scales and\norientations, different types of patterns.\nMatlab code available for these examples: http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html\n67\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page67",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Filter bank\n68\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page68",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "g p\nj .\n2 p a c n\ni t s u a m o c . r e r o p x e s a x e\n/\nl\nt .\nw w w\n/ / :\np\nt t\nh m o r f\ne g a m\nI\n69\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page69",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "70\nShowing magnitude of responses\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page70",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "71\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page71",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "72\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page72",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "73\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page73",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "74\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page74",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "75\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page75",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "76\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page76",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "77\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page77",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "78\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page78",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "79\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page79",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "80\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page80",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "81\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page81",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "82\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page82",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "83\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page83",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "84\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page84",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "85\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page85",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "86\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page86",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "87\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page87",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "88\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page88",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n2\n3\nYou try: Can you match the texture to the response?\nFilters\nA\nB\nC\nMean abs responses\n89\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page89",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n2\n3\nYou try: Can you match the texture to the response?\nFilters\nA\nB\nC\nMean abs responses\n90\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page90",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "91\nLihi Zelnik-Manor, Computer Vision\n[r1, r2, ‚Ä¶, r38]\nWe can form a feature vector from the list of responses at each pixel.",
    "offset": "page91",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Martin, Fowlkes, Malik PAMI 04\nGradient OE\nCue Combination\nBrightness BG\nColor CG\nModel\nTexture TG\nÔÅΩ Goal: learn the posterior probability of a boundary\nPb(x,y,ÔÅ±) from local information only\nÔÅΩ Challenges:\nÔÅΩ computing the cues, ÔÅΩ cue combination\n92\nLihi Zelnik-Manor, Computer Vision\nPb",
    "offset": "page92",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "93\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page93",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "94\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page94",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Parameter tuning (cue optimization)\nÔÅΩ Scale ÔÅΩ Disk radius ÔÅΩ Number of bins in histogram\nTrained on labeled data\n95\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page95",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Cue combination\nÔÅΩ Tested many options:\nÔÅΩ Logistic regression ‚Äì the winner! ÔÅΩ SVM (support vector machines) ÔÅΩ Hierarchical Mixture of Experts ÔÅΩ Classification trees\n96\nLihi Zelnik-Manor, Computer Vision\nThe logistic function",
    "offset": "page96",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Various cue combinations\n97\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page97",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example results\n98\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page98",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forty years of contour detection\nRoberts (1965)\nSobel (1968)\nPrewitt (1970)\nMarr Hildreth (1980)\nCanny (1986)\nPerona Malik (1990)\n99\nLihi Zelnik-Manor, Computer Vision\nMartin Fowlkes Malik (2004)\nMaire Arbelaez Fowlkes Malik (2008)\n99",
    "offset": "page99",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Global pB boundary detector\nFigure from Fowlkes",
    "offset": "page100",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests (Dollar Zitnick ICCV 2013)\nÔÅΩ Goal: quickly predict whether each pixel is an\nedge\nÔÅΩ Insights\nÔÅΩ Predictions can be learned from training data ÔÅΩ Predictions for nearby pixels should not be\nindependent\nÔÅΩ Solution\nÔÅΩ Train structured random forests to split data into\npatches with similar boundaries based on features\nÔÅΩ Predict boundaries at patch level, rather than pixel level, and aggregate (average votes)\nhttp://research.microsoft.com/pubs/202540/DollarICCV13edges.pdf\nBoundaries in patch",
    "offset": "page101",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests\nÔÅΩ Algorithm\n1. Extract overlapping 32x32 patches at three scales\n2.\nFeatures are pixel values and pairwise differences in feature maps (LUV color, gradient magnitude, oriented gradient)\n3. Predict ùëá boundary maps in the central 16x16 region using ùëá trained decision trees\n4. Average predictions for each pixel across all patches",
    "offset": "page102",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests Results\nBSDS 500\nNYU Depth dataset edges",
    "offset": "page103",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests\nGround truth\nResults (multiscale)",
    "offset": "page104",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forty years of contour detection\nRoberts (1965)\nSobel (1968)\nPrewitt (1970)\nMarr Hildreth (1980)\nCanny (1986)\nPerona Malik (1990)\n105\nLihi Zelnik-Manor, Computer Vision\nMartin Fowlkes Malik (2004)\nMaire Arbelaez Fowlkes Malik (2008)\nDollar Zitnick (2013)",
    "offset": "page105",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Crisp Boundary Detection using Pointwise Mutual Information (Isola et al. ECCV 2014)\nPixel color combinations that are unlikely to be together are edges\nAlgorithm:\nKernel density estimation\nSpectral clustering\nhttp://web.mit.edu/phillipi/www/publications/crisp_boundaries.pdf",
    "offset": "page106",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Crisp Boundary Detection using Pointwise Mutual Information",
    "offset": "page107",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\nÔÅΩ Trevor Darell ÔÅΩ Kristen Grauman ÔÅΩ Jitendra Malik ÔÅΩ FeiFei Li ÔÅΩ Derek Hoiem ÔÅΩ and Seitz, Marschner, Lazebnik and others\n108\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page108",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "109\nEnd ‚Äì finding lines\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page109",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nImage Resampling",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image Scaling\nThis image is too big to fit on the screen. How can we generate a half-sized version?\nSource: S. Seitz",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\n1/4\nThrow away every other row and column to create a 1/2 size image - called image sub-sampling\n1/8\nSource: S. Seitz",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\n1/2\n1/4 (2x zoom)\nWhy does this look so crufty?\n1/8 (4x zoom)\nSource: S. Seitz",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\nSource: F. Durand",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Even worse for synthetic images\nSource: L. Zhang",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Aliasing\nOccurs when your sampling rate is not high enough to capture the amount of detail in your image ‚Ä¢ Can give you the wrong signal/image‚Äîan alias\nTo do sampling right, need to understand the structure of your signal/image\nEnter Monsieur Fourier‚Ä¶\nTo avoid aliasing:\n‚Äì sampling rate ‚â• 2 * max frequency in the image ‚Ä¢ said another way: ‚â• two samples per cycle\n‚Äì This minimum sampling rate is called the Nyquist rate\nSource: L. Zhang",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Wagon-wheel effect\n(See http://www.michaelbach.de/ot/mot_wagonWheel/index.html)\nSource: L. Zhang",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Nyquist limit ‚Äì 2D example\nGood sampling\nBad sampling",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Aliasing\nWhen downsampling by a factor of two\n‚Äì Original image has frequencies that are too high\nHow can we fix this?",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pre-filtering\nG 1/4\nGaussian 1/2\nSolution: filter the image, then subsample\nG 1/8\nSource: S. Seitz",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Subsampling with Gaussian pre-filtering\nGaussian 1/2\nG 1/4\nSolution: filter the image, then subsample\nG 1/8\nSource: S. Seitz",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1/2\nCompare with...\n1/4 (2x zoom)\n1/8 (4x zoom)\nSource: S. Seitz",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pre-filtering ‚Ä¢ Solution: filter the image, then subsample\nblur\nF0\nsubsample\nF0 H*\nblur\nF1 subsample ‚Ä¶\nF2\nF1 H*",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramid\nblur\nF0\nsubsample\nF0 H*\nblur\nF1 subsample ‚Ä¶\nF2\nF1 H*",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramids [Burt and Adelson, 1983]\nIn computer graphics, a mip map [Williams, 1983] ‚Ä¢ A precursor to wavelet transform\nGaussian Pyramids have all sorts of applications in computer vision\nSource: S. Seitz",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramids [Burt and Adelson, 1983]\nHow much space does a Gaussian pyramid take compared to the original image?\nSource: S. Seitz",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian Pyramid",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "lt"
  },
  {
    "filetype": "application/pdf",
    "text": "0G\nThe Laplacian Pyramid\n)expand(1ÔÄ´ÔÄ≠ÔÄΩiiiGGL\nGaussian Pyramid\n)expand(1ÔÄ´ÔÄ´ÔÄΩiiiGLG\nnG\n2G\n=\n1G\n=\n=\nLaplacian Pyramid\nnnGLÔÄΩ\n2L\n1L\n0L",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nImage Interpolation",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image Scaling\nLast time:\nThis image is too big to fit on the screen. How can we generate a half-sized version?\nSource: S. Seitz",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Upsampling\nThis image is too small for this screen: ‚Ä¢ How can we make it 10 times as big? ‚Ä¢ Simplest approach: repeat each row and column 10 times\n(‚ÄúNearest neighbor interpolation‚Äù)",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nd = 1 in this example\n1\n2\n3\n4\n5\nRecall how a digital image is formed\nIt is a discrete point-sampling of a continuous function ‚Ä¢ If we could somehow reconstruct the original function, any new image could be generated, at any resolution and scale\nAdapted from: S. Seitz",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nd = 1 in this example\n1\n2\n3\n4\n5\nRecall how a digital image is formed\nIt is a discrete point-sampling of a continuous function ‚Ä¢ If we could somehow reconstruct the original function, any new image could be generated, at any resolution and scale\nAdapted from: S. Seitz",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\n1\n1\n2\n2.5\n3\n4\n5\nWhat if we don‚Äôt know ?\nGuess an approximation: ‚Ä¢ Can be done in a principled way: filtering ‚Ä¢ Convert to a continuous function:\nReconstruct by convolution with a reconstruction filter, h\nd = 1 in this example\nAdapted from: S. Seitz",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\n‚ÄúIdeal‚Äù reconstruction\nNearest-neighbor interpolation\nLinear interpolation\nGaussian reconstruction\nSource: B. Curless",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Reconstruction filters ‚Ä¢ What does the 2D version of this hat function look like?\nperforms linear interpolation\n(tent function) performs bilinear interpolation\nOften implemented without cross-correlation\nE.g., http://en.wikipedia.org/wiki/Bilinear_interpolation\nBetter filters give better resampled images\nBicubic is common choice\nCubic reconstruction filter",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nOriginal image: x 10\nNearest-neighbor interpolation\nBilinear interpolation\nBicubic interpolation",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nAlso used for resampling",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Raster to Vector Graphics",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Depixelating Pixel Art",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nAlgorithms and Applications in Computer Vision\nLihi Zelnik-Manor lihi@ee.technion.ac.il\nLihi Zelnik-Manor, Computer vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\nÔÅΩ ‚ÄúWhat is computer vision?‚Äù ÔÅΩ Administration\n2\nLihi Zelnik-Manor, Computer vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is computer vision?\nDone?\n3\nLihi Zelnik-Manor, Computer vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The goal of computer vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is computer vision?\nÔÅΩ Automatic understanding of images and video\nÔÅΩ Measurement: Computing properties of the 3D world from\nvisual data\nÔÅΩ Perception and interpretation: Algorithms and representations to allow a machine to recognize objects, people, scenes, and activities.\nÔÅΩ Image enhancement: super-resolution, synthesis, deblur\n(computational photography).\n5\nLihi Zelnik-Manor, Computer vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision for measurement\nReal-time stereo\nStructure from motion\nMulti-view stereo for community photo collections\nNASA Mars Rover\nPollefeys et al.\nGoesele et al.\n6\nLihi Zelnik-Manor, Computer vision\nSlide credit: L. Lazebnik",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision for perception, interpretation\nThe Wicked Twister\nride\nsky\namusement park\nCedar Point\nFerris wheel\nride\nObjects Activities Scenes Locations Text / writing Faces Gestures Motions Emotions‚Ä¶\n12 E\nLake Erie\nwater\nride\ntree\ntree\npeople waiting in line\npeople sitting on ride\numbrellas\n7\ndeck\ntree\nbench\ncarousel\ntree\npedestrians\nLihi Zelnik-Manor, Computer vision\nmaxair",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "‚ÄúEnhancing‚Äù images (c.f. Computational Photography)\nTexture synthesis / increased field of view (uncropping) (image credit: Efros and Leung)\nSuper-resolution / denoising (source: 2d3)\nInpainting / image completion (image credit: Hays and Efros)",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Related disciplines\nGraphics\nArtificial intelligence\nMachine learning\nImage processing\nComputer vision\nCognitive science\nAlgorithms\n9\nLihi Zelnik-Manor, Computer vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision and graphics\nImages\nVision\nModel\nGraphics\nInverse problems: analysis and synthesis.\n10\nLihi Zelnik-Manor, Computer vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why study computer vision?\nÔÅΩ Vision is useful\nÔÅΩ Vision is interesting\nÔÅΩ Vision is difficult\nÔÅΩ Half of primate cerebral cortex is devoted to visual processing ÔÅΩ Achieving human-level visual perception is probably\n‚ÄúAI-complete‚Äù (is this really true??)\n11\nLihi Zelnik-Manor, Computer vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is vision useful?\nÔÅΩ As image sources multiply, so do applications\nÔÅΩ Relieve humans of boring, easy tasks\nÔÅΩ Enhance human abilities: human-computer interaction,\nvisualization\nÔÅΩ Perception for robotics / autonomous agents\nÔÅΩ Organize and give access to visual content\n12\nLihi Zelnik-Manor, Computer vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is it interesting? ÔÅΩ Images and videos are everywhere!\nPersonal photo albums\nMovies, news, sports\nSurveillance and security\nMedical and scientific images\n13\nLihi Zelnik-Manor, Computer vision\nSlide credit; L. Lazebnik",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is it difficult?\n14\nLihi Zelnik-Manor, Computer vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Viewing angle\n15\nLihi Zelnik-Manor, Computer vision\nMichelangelo, David",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Lighting\n16\nLihi Zelnik-Manor, Computer vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Size\n17\nLihi Zelnik-Manor, Computer vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Occlusions\n18\nLihi Zelnik-Manor, Computer vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Deformation\n19\nLihi Zelnik-Manor, Computer vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Deformation\n20\nLihi Zelnik-Manor, Computer vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Camera limitations (e.g. saturation)\n21\nLihi Zelnik-Manor, Computer vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Motion blur\n22\nLihi Zelnik-Manor, Computer vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Intra-class variability\n23\nLihi Zelnik-Manor, Computer vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "But there are lots of cues we can exploit‚Ä¶\nSource: S. Lazebnik",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Bottom line ÔÅΩ Perception is an inherently ambiguous problem\nÔÅΩ Many different 3D scenes could have given rise to a particular\n2D picture\nÔÅΩ We often need to use prior knowledge about the structure of\nthe world\nImage source: F. Durand",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computer vision in practice\n26\nLihi Zelnik-Manor, Computer vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision Demo?\nTerminator 2\n27\nwe‚Äôre not quite there yet‚Ä¶.\nLihi Zelnik-Manor, Computer vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Earth viewers (3D modeling)\nImage from Microsoft‚Äôs Virtual Earth (see also: Google Earth)\n28\nLihi Zelnik-Manor, Computer vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photosynth\nhttp://labs.live.com/photosynth/\nBased on Photo Tourism technology developed by Noah Snavely, Steve Seitz, and Rick Szeliski\n29\nLihi Zelnik-Manor, Computer vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photo Tourism overview\nScene reconstruction\nPhoto Explorer\nInput photographs\nRelative camera positions and orientations\nPoint cloud\nSparse correspondence\nSystem for interactive browsing and exploring large collections of photos of a scene. Computes viewpoint of each photo as well as a sparse 3d model of the scene.\n30\nLihi Zelnik-Manor, Computer vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photo Tourism overview\n31\nLihi Zelnik-Manor, Computer vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Optical character recognition (OCR)\nÔÅΩ Technology to convert scanned docs to text ÔÅΩ If you have a scanner, it probably came with OCR\nsoftware\nDigit recognition, AT&T labs http://www.research.att.com/~yann/\nLicense plate readers http://en.wikipedia.org/wiki/Automatic_number_plate_recognition\n32\nLihi Zelnik-Manor, Computer vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Face detection\nÔÅΩ Most digital cameras now detect faces in realtime\n33\nLihi Zelnik-Manor, Computer vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smile detection?\nSony Cyber-shot¬Æ T70 Digital Still Camera\n34\nLihi Zelnik-Manor, Computer vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Face Recognition\nhttp://developers.face.com/tools/",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Object recognition (in supermarkets)\nLaneHawk by EvolutionRobotics ‚ÄúA smart camera is flush-mounted in the checkout lane, continuously watching for items. When an item is detected and recognized, the cashier verifies the quantity of items that were found under the basket, and continues to close the transaction. The item can remain under the basket, and with LaneHawk,you are assured to get paid for it‚Ä¶ ‚Äú\n36\nLihi Zelnik-Manor, Computer vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Biometrics\nWho is she?\n37\nLihi Zelnik-Manor, Computer vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision-based biometrics\n‚ÄúHow the Afghan Girl was Identified by Her Iris Patterns‚Äù Read the story\n38\nLihi Zelnik-Manor, Computer vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Login without a password‚Ä¶\nFingerprint scanners on many new laptops, other devices\nFace recognition systems now beginning to appear more widely http://www.sensiblevision.com/\n39\nLihi Zelnik-Manor, Computer vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Object recognition (in mobile phones)\n40\nLihi Zelnik-Manor, Computer vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Google Goggles",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "da"
  },
  {
    "filetype": "application/pdf",
    "text": "Google Search by Image",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Leaf Recognition",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Special effects: shape capture\nThe Matrix movies, ESC Entertainment, XYZRGB, NRC\n44\nLihi Zelnik-Manor, Computer vision",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Special effects: motion capture\nPirates of the Carribean, Industrial Light and Magic\n45\nLihi Zelnik-Manor, Computer vision",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sports\nSportvision first down line Nice explanation on www.howstuffworks.com\n46\nLihi Zelnik-Manor, Computer vision",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smart cars\nÔÅΩ Mobileye https://www.youtube.com/watch?v=HXpiyLUEOOY ÔÅΩ Tesla https://www.youtube.com/watch?v=4CZe5DXeYzw\n47\nLihi Zelnik-Manor, Computer vision\nSource: Amnon Shashua",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision-based interaction (and games)\nDigimask: put your face on a 3D avatar.\nNintendo Wii has camera-based IR tracking built in. See Lee‚Äôs work at CMU on clever tricks on using it to create a multi-touch display!\n‚ÄúGame turns moviegoers into Human Joysticks‚Äù, CNET Camera tracking a crowd, based on this work.\n48\nLihi Zelnik-Manor, Computer vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Kinect",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision in space\nNASA'S Mars Exploration Rover Spirit captured this westward view from atop a low plateau where Spirit spent the closing months of 2007. Vision systems (JPL) used for several tasks\nPanorama stitching ‚Ä¢ 3D terrain modeling ‚Ä¢ Obstacle detection, position tracking ‚Ä¢ For more, read ‚ÄúComputer Vision on Mars‚Äù by Matthies et al. Lihi Zelnik-Manor, Computer vision\nPanorama stitching ‚Ä¢ 3D terrain modeling ‚Ä¢ Obstacle detection, position tracking ‚Ä¢ For more, read ‚ÄúComputer Vision on Mars‚Äù by Matthies et al. Lihi Zelnik-Manor, Computer vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Robotics\nNASA‚Äôs Mars Spirit Rover http://en.wikipedia.org/wiki/Spirit_rover\nhttp://www.robocup.org/\n51\nLihi Zelnik-Manor, Computer vision",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Medical imaging\n3D imaging MRI, CT\n52\nImage guided surgery Grimson et al., MIT\nLihi Zelnik-Manor, Computer vision",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Current state of the art\nÔÅΩ You just saw examples of current systems. ÔÅΩ Many of these are less than 5 years old\nÔÅΩ This is a very active research area, and rapidly changing\nÔÅΩ Many new apps in the next 5 years\nÔÅΩ To learn more about vision applications and companies\nÔÅΩ David Lowe maintains an excellent overview of vision\ncompanies ÔÅΩ http://www.cs.ubc.ca/spider/lowe/vision.html\n53\nLihi Zelnik-Manor, Computer vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "AI has come\nÔÅΩ https://openai.com/blog/introducing-openai/\nÔÅΩ Toyota Invests $1 Billion in Artificial Intelligence in U.S.\nhttp://www.nytimes.com/2015/11/06/technology/toyota- silicon-valley-artificial-intelligence-research- center.html?_r=0\nÔÅΩ Facebook AI Research (FAIR)\nhttps://research.facebook.com/ai\n54\nLihi Zelnik-Manor, Computer vision",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Again, what is computer vision?\nÔÅΩ Mathematics of geometry of image formation? ÔÅΩ Statistics of the natural world? ÔÅΩ Models for neuroscience? ÔÅΩ Engineering methods for matching images? ÔÅΩ Science Fiction?\n55\nLihi Zelnik-Manor, Computer vision",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\nÔÅΩ ‚ÄúWhat is computer vision?‚Äù ÔÅΩ Administration\n56\nLihi Zelnik-Manor, Computer vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Course overview (tentative)\n1.\nLow-level vision\n2.\nÔÅΩ\nimage processing, edge detection, feature detection, cameras, image formation Basic Geometry\nÔÅΩ\nprojective geometry, Optical flow, panoramas\n3.\nRecognition\nÔÅΩ\nface detection / recognition, category recognition, segmentation\n4.\nIntroduction to Deep Learning",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Prerequisites\nÔÅΩ : What I expect you to already know ÔÅΩ A good working knowledge of Python programming\n(or willingness and time to pick it up quickly!)\nÔÅΩ Linear algebra\n58\nLihi Zelnik-Manor, Computer vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Books\nÔÅΩ Rick Szeliski‚Äôs book:\nComputer Vision: Algorithms and applications\nÔÅΩ Forsyth and Ponce,\nComputer Vision: A Modern Approach.\n59\nLihi Zelnik-Manor, Computer vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Szeliski Book\n60\nLihi Zelnik-Manor, Computer vision",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "sl"
  },
  {
    "filetype": "application/pdf",
    "text": "Forsyth & Ponce Book\n61\nLihi Zelnik-Manor, Computer vision",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Programming\nÔÅΩ Problem sets and projects will involve Python programming (you are\nfree to use alternative packages).a\n62\nLihi Zelnik-Manor, Computer vision",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Grading\nÔÅΩ There will be three components to the course grade\nÔÅΩ HW assignments, 2-3, including programming projects\nÔÅΩ Final Project\nÔÅΩ Class attendance, class participation, short quizes?a\n63\nLihi Zelnik-Manor, Computer vision",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Problem sets ‚Äì still not finalized\nÔÅΩ\nÔÅΩ\nÔÅΩ\nÔÅΩ\nPset1 ‚Äì Edge detection and voting techniques Pset2 ‚Äì Image segmentation Pset3 ‚Äì Feature tracking and alignment Pset4 ‚Äì Recognition\nÔÅΩ\nÔÅΩ\nCan discuss, but must have your own code. Submit work in singles.a\n64\nLihi Zelnik-Manor, Computer vision",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Course goals‚Ä¶.\nÔÅΩ You‚Äôll know something about computer vision\n65\nLihi Zelnik-Manor, Computer vision",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "And now, who are you?\nÔÅΩ What do you expect to get out of this class? ÔÅΩ Previous experience in vision, learning, graphics? ÔÅΩ Research agenda? ÔÅΩ (Project topics?)\n66\nLihi Zelnik-Manor, Computer vision",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670/5670: Intro to Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Reading\nSzeliski, Chapter 3.1-3.2",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nWe‚Äôll focus on these in this class\n(More on this process later)\nDigital Camera\nThe Eye\nSource: A. Efros",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nA grid (matrix) of intensity values\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255\n20\n0 255 255 255 255 255 255 255\n255 255 255\n75\n75\n75 255 255 255 255 255 255\n=\n255 255\n75\n95\n95\n75 255 255 255 255 255 255\n255 255\n96 127 145 175 255 255 255 255 255 255\n255 255 127 145 175 175 175 255 255 255 255 255\n255 255 127 145 200 200 175 175\n95 255 255 255\n255 255 127 145 200 200 175 175\n95\n47 255 255\n255 255 127 145 145 175 127 127\n95\n47 255 255\n255 255\n74 127 127 127\n95\n95\n95\n47 255 255\n255 255 255\n74\n74\n74\n74\n74\n74 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n(common to use one byte per value: 0 = black, 255 = white)",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nWe can think of a (grayscale) image as a function, f, from R2 to R: ‚Äì f (x,y) gives the intensity at position (x,y)\nf (x, y)\nx\ny\n‚Äì A digital image is a discrete (sampled, quantized)\nversion of this function",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image transformations\nAs with any function, we can apply operators to an image\ng (x,y) = f (x,y) + 20\ng (x,y) = f (-x,y)\nWe‚Äôll talk about a special kind of operator, convolution (linear filtering)",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Question: Noise reduction ‚Ä¢ Given a camera and a still scene, how can you\nreduce noise?\nTake lots of images and average them! What‚Äôs the next best thing?\nSource: S. Seitz",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image filtering\nModify the pixels in an image based on some function of a local neighborhood of each pixel\n10\n5\n3\nSome function\n4\n5\n1\n7\n1\n1\n7\nLocal image data\nModified image data\nSource: L. Zhang",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Linear filtering\nOne simple version: linear filtering (cross-correlation, convolution)\n‚Äì Replace each pixel by a linear combination (a weighted\nsum) of its neighbors\nThe prescription for the linear combination is called the ‚Äúkernel‚Äù (or ‚Äúmask‚Äù, ‚Äúfilter‚Äù)\n10\n5\n3\n0\n0\n0\n4\n6\n1\n0\n0.5 0\n8\n1\n1\n8\n0\n1\n0.5\nLocal image data\nkernel\nModified image data\nSource: L. Zhang",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Cross-correlation\nLet be the image, be the kernel (of size 2k+1 x 2k+1), and be the output image. The cross-correlation operation is defined as:\nCan think of as a ‚Äúdot product‚Äù between local neighborhood and kernel for each pixel\nShort notation:",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Convolution\nSame as cross-correlation, except that the kernel is ‚Äúflipped‚Äù (horizontally and vertically)\nThis is called a convolution operation:\nConvolution is commutative and associative",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Convolution\nAdapted from F. Durand",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n1\n1\n1\n1\n1\n1\n1 *\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nMean filtering\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n90\n90\n90\n90\n90\n0\n90\n90\n90\n90\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n0\n=\n0\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n90\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n10 20 30 30 30 20 10\n0\n20 40 60 60 60 40 20\n0\n30 60 90 90 90 60 30\n0\n30 50 80 80 90 60 30\n0\n30 50 80 80 90 60 30\n0\n20 30 50 50 60 40 20\n10 20 30 30 30 30 20 10\n10 10 10\n0\n0\n0\n0\n0",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n1\n0\n0\n0\n0\n=\nIdentical image\nSource: D. Lowe",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n0\n0\n0\n1\n0\n=\nShifted left By 1 pixel\nSource: D. Lowe",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Linear filters: examples\n1\n1\n1\n1\n1\n1\n1\n1\n1\n=\nOriginal\nBlur (with a mean filter)\nSource: D. Lowe",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n2\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n=\nSharpening filter (accentuates edges)\nSource: D. Lowe",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sharpening\nSource: D. Lowe",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smoothing with box filter revisited\nSource: D. Forsyth",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian Kernel\nSource: C. Rasmussen",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian filters\n= 1 pixel\n= 5 pixels\n= 10 pixels\n= 30 pixels",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean vs. Gaussian filtering",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian filter\nRemoves ‚Äúhigh-frequency‚Äù components from the image (low-pass filter)\nConvolution with self is another Gaussian\n=\n‚Äì Convolving twice with Gaussian kernel of width\n= convolving once with kernel of width\nSource: K. Grauman",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sharpening revisited\nWhat does blurring take away?\n‚Äì\n=\noriginal\nsmoothed (5x5)\nLet‚Äôs add it back:\n+ Œ±\n=\noriginal\ndetail\ndetail\nsharpened\nSource: S. Lazebnik",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "image\nblurred image\nscaled impulse\nSharpen filter\nGaussian\nunit impulse (identity)\nLaplacian of Gaussian (LoG)",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "unfiltered\nfiltered\nSharpen filter",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "no"
  },
  {
    "filetype": "application/pdf",
    "text": "‚ÄúOptical‚Äù Convolution\nCamera shake\n=\nSource: Fergus, et al. ‚ÄúRemoving Camera Shake from a Single Photograph‚Äù, SIGGRAPH 2006\nBokeh: Blur in out-of-focus regions of an image.\nSource: http://www.diyphotography.net/diy_create_your_own_bokeh/",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?\nFor next time:\n‚Äì Read Szeliski, Chapter 3.1-3.2",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computer Vision\nLihi Zelnik-Manor lihi@ee.technion.ac.il",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Color\nColor\n`\nReadings:\n‚Äì Forsyth and Ponce, Chapter 6 ‚Äì Szeliski, 2.3.2",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\nTrevor Darrell ‚Ä¢ Kristen Grauman: 3-48, 50-75, 79-86 ‚Ä¢ Bob Woodham: 49, 87-90 ‚Ä¢ and others, indirectly (Steve Palmer, Brian Wandell, etc!)",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n‚Äì Spectral power distributions ‚Äì Color mixing ‚Äì Color matching experiments ‚Äì Color spaces\nUniform color spaces\nPerception of color\n‚Äì Human photoreceptors ‚Äì Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color and light\nColor of light arriving at camera depends on\n‚Äì Spectral reflectance of the surface light is leaving ‚Äì Spectral radiance of light falling on that patch\nColor perceived depends on\n‚Äì Physics of light ‚Äì Visual system receptors ‚Äì Brain processing, environment",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color and light\nWhite light: composed of about equal energy in all wavelengths of the visible spectrum\nNewton 1665\nImage from http://micro.magnet.fsu.edu/",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Electromagnetic spectrum\nHuman Luminance Sensitivity Function\nImage credit: nasa.gov",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Measuring spectra\nSpectroradiometer: separate input light into its different wavelengths, and measure the energy at each.\nFoundations of Vision, B. Wandell",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Spectral power distribution\nThe power per unit area at each wavelength of a radiant object\n# Photons(per ms.)\n400 500 600 700Wavelength (nm.)\nFigure ¬© Stephen E. Palmer, 2002",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Spectral power distributions\nSome examples of the spectra of light sources\n# PhotonsD. Normal DaylightWavelength (nm.)B. Gallium Phosphide Crystal400 500 600 700# PhotonsWavelength (nm.)A. Ruby Laser\n# PhotonsC. Tungsten Lightbulb400 500 600 700\n.\n400 500 600 700400 500 600 700\n# Photons\n¬© Stephen E. Palmer, 2002",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The color viewed is also affected by the surface‚Äôs spectral reflectance properties.\nSpectral reflectances for some natural objects: how much of each wavelength is reflected for that surface\nForsyth & Ponce, measurements by E. Koivisto",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "d e\nt c e\nl f\ne R s n o\nt\no h P %\nSurface reflectance spectra\nSome examples of the reflectance spectra of surfaces\nRed\nYellow\nBlue\nPurple\n400 700\n400 700\n400 700\n400 700\nWavelength (nm)\n¬© Stephen E. Palmer, 2002",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nThere is no simple functional description for the perceived color of all lights under all viewing conditions, but ‚Ä¶...\nA helpful constraint:\nConsider only physical spectra with normal distributions\nmean\nWavelength (nm.)# Photons400700\n500600\narea\nvariance\n¬© Stephen E. Palmer, 2002",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nMean\nHue\ns n o\nt\no h P #\nyellowgreenblue\nWavelength\n¬© Stephen E. Palmer, 2002",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nVariance\nSaturation\nhighmediumlow\nhi.med.low\ns n o\nt\no h P #\nWavelength\n¬© Stephen E. Palmer, 2002",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nArea\nBrightness\ns n o\nt\no h P #\nbrightdark\nB. Area Lightness\nWavelength\n¬© Stephen E. Palmer, 2002",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color mixing\nCartoon spectra for color names:\nSource: W. Freeman",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Additive color mixing\nColors combine by adding color spectra\nLight adds to black.\nSource: W. Freeman",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Examples of additive color systems\nCRT phosphors\nmultiple projectors\nhttp://www.jegsworks.com\nhttp://www.crtprojectors.co.uk/",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Subtractive color mixing\nColors combine by multiplying color spectra.\nPigments remove color from incident light (white).\nSource: W. Freeman",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Examples of subtractive color systems\nPrinting on paper ‚Ä¢ Most photographic film",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n‚Äì Spectral power distributions ‚Äì Color mixing ‚Äì Color matching experiments ‚Äì Color spaces\nUniform color spaces\nPerception of color\n‚Äì Human photoreceptors ‚Äì Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why specify color numerically?\nAccurate color reproduction is commercially valuable ‚Äì Many products are identified by color\nFew color names are widely recognized by English speakers ‚Äì 11: black, blue, brown, grey, green, orange, pink, purple, red, white, and\nyellow.\n‚Äì Other languages have fewer/more. ‚Äì Common to disagree on appropriate color names.\nColor reproduction problems increased by prevalence of digital imaging ‚Äì e.g. digital libraries of art. ‚Äì How to ensure that everyone perceives the same color? ‚Äì What spectral radiances produce the same response from people under\nsimple viewing conditions?\nForsyth & Ponce",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nGoal:\nWhat spectral radiances produce same response in human observers?",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nObserver adjusts weight (intensity) for primary lights (fixed SPD‚Äôs) to match appearance of test light.\nFoundations of Vision, by Brian Wandell, Sinauer Assoc., 1995\nAfter Judd & Wyszecki.",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nGoal:\nWhat spectral radiances produce same response in human observers?\nAssumption:\nUnder simple viewing conditions only ‚Äútest light‚Äù affects perception ‚Äì Ignoring additional factors for now like adaptation,\ncomplex surrounding scenes, etc.",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\nThe primary color amounts needed for a match\np1 p2 p3",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiment 2\nWe say a ‚Äúnegative‚Äù amount of p2 was needed to make the match, because we added it to the test color‚Äôs side.\nTest light\nPrimary lights\nThe primary color amounts needed for a match:\np1 p2 p3\np1 p2 p3\np1 p2 p3",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching\nWhat must we require of the primary lights chosen? ‚Ä¢ How are three numbers enough to represent entire spectrum?\nWhat must we require of the primary lights chosen? ‚Ä¢ How are three numbers enough to represent entire 121233ecolorePPPeÔÉ©ÔÉπÔÉ™ÔÉ∫ÔÉ©ÔÉπÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÇÆÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ´ÔÉªÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ´ÔÉª\nweights",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Metamers\nLights forming a perceptual match still may be physically different\n‚Äì Match light: a combination of primaries ‚Äì Test light: any light\nMetamers: pairs of lights that match perceptually but not physically\nDifferent spectrum\nSame primary mixture weights",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "How to compute the weights of the primaries to match any new spectral signal?\nGiven: a choice of three primaries and a target color signal\nFind: weights of the primaries needed to match the color signal\n?\np1 p2 p3\ne1\ne2 e3\nChallenge: we cannot use manual tuning for all colors in the world",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\n1.\nSelect primaries\n2. Collect weights for all monochromatic lights:\nÔÄ®ÔÄ©ÔÄ®ÔÄ©ÔÄ®ÔÄ©112131cccÔÅ¨ÔÅ¨ÔÅ¨ÔÉ©ÔÉπÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ´ÔÉª\nPut them in a big matrix:\n111212313()()()()()()NNNccccccÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÉ¶ÔÉ∂ÔÉßÔÉ∑ÔÉûÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉ®ÔÉ∏",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\n1.\nSelect primaries\n2. Collect weights for all monochromatic lights:\nÔÄ®ÔÄ©ÔÄ®ÔÄ©ÔÄ®ÔÄ©112131cccÔÅ¨ÔÅ¨ÔÅ¨ÔÉ©ÔÉπÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ™ÔÉ∫ÔÉ´ÔÉª\n3. Compute the weights of any color by:\nÔÄ®ÔÄ©ÔÄ®ÔÄ©1111121223133()()()()()()NNNNtccecceccetÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÉ¶ÔÉ∂ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉ¶ÔÉ∂ÔÉ¶ÔÉ∂ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÇÆÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉ®ÔÉ∏ÔÉ®ÔÉ∏ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉßÔÉ∑ÔÉ®ÔÉ∏",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\nArbitrary new spectral signal is linear combination of the monochromatic sources.\nÔÉ∑ÔÉ∑ÔÉ∑ÔÉ∏ÔÉ∂ÔÉßÔÉßÔÉßÔÉ®ÔÉ¶ÔÄΩ)()(1NtttÔÅ¨ÔÅ¨ÔÅçÔÅ≤\nt\n‚Ä¶\nColor matching functions specify how to match a unit of each wavelength, so:\nÔÉ∫ÔÉ∫ÔÉ∫ÔÉ∫ÔÉªÔÉπÔÉ™ÔÉ™ÔÉ™ÔÉ™ÔÉ´ÔÉ©ÔÉ∑ÔÉ∑ÔÉ∑ÔÉ∏ÔÉ∂ÔÉßÔÉßÔÉßÔÉ®ÔÉ¶ÔÄΩÔÉ∫ÔÉ∫ÔÉ∫ÔÉªÔÉπÔÉ™ÔÉ™ÔÉ™ÔÉ´ÔÉ©)()()()()()()()()(21313212111321NNNNtttcccccceeeÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅ¨ÔÅçÔÅåÔÅåÔÅå\nCteÔÄΩ\nKristen Grauman",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\nWhy is computing the color\nmatch for any color signal for a given set of primaries useful? ‚Äì Want to paint a carton of Kodak film\nwith the Kodak yellow color. ‚Äì Want to match skin color of a\nperson in a photograph printed on an ink jet printer to their true skin color.\n‚Äì Want the colors in the world, on a monitor, and in a print format to all look the same.\nAdapted from W. Freeman\nImage credit: pbs.org",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n‚Äì Spectral power distributions ‚Äì Color mixing ‚Äì Color matching experiments ‚Äì Color spaces\nUniform color spaces\nPerception of color\n‚Äì Human photoreceptors ‚Äì Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Standard color spaces\nUse a common set of primaries/color matching functions\nLinear color space examples\n‚Äì RGB ‚Äì CIE XYZ\nNon-linear color space\n‚Äì HSV ‚Äì CIE LAB",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RGB color space\nSingle wavelength primaries ‚Ä¢ Good for devices (e.g., phosphors for monitor), but not for perception\nRGB color matching functions",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE XYZ color space\nEstablished by the commission international d‚Äôeclairage (CIE), 1931\nUsually projected to display: (x,y) = (X/(X+Y+Z), Y/(X+Y+Z))\nCIE XYZ Color matching functions",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Distances in color space\nAre distances between points in a color space perceptually meaningful?",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Distances in color space\nNot necessarily: CIE XYZ is not a uniform color space, so magnitude of differences in coordinates are poor indicator of color ‚Äúdistance‚Äù.\nMcAdam ellipses: Just noticeable differences in color",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE XYZ\nUniform color spaces\nCIE Lu‚Äôv‚Äô\nCIE Lab",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE LAB color space\nEstablished by the CIE in 1948 and then 1976 ‚Ä¢ Goal: perceptually uniform",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "HSV color space\nHue, Saturation, Value (Brightness) ‚Ä¢ Nonlinear ‚Äì reflects topology of colors by coding hue as an angle\nIntuitive for color picking\nImage from mathworks.com",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n‚Äì Spectral power distributions ‚Äì Color mixing ‚Äì Color matching experiments ‚Äì Color spaces\nUniform color spaces\nPerception of color\n‚Äì Human photoreceptors ‚Äì Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color\nColor of light arriving at camera depends on\n‚Äì Spectral reflectance of the surface light is leaving ‚Äì Spectral radiance of light falling on that patch\nColor perceived depends on\n‚Äì Physics of light ‚Äì Visual system receptors ‚Äì Brain processing, environment",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nRods responsible for intensity -Cones responsible for color -Fovea: small region (1 or 2¬∞) at the center of the visual field containing the highest density of cones (and no rods). ‚Äì Less visual acuity in the periphery\nAdapted from Seitz, Duygulu",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Two types of light-sensitive receptors\nCones\ncone-shaped less sensitive operate in high light color vision\nRods\nrod-shaped highly sensitive operate at night gray-scale vision\n¬© Stephen E. Palmer, 2002\nSlide credit: Alyosha Efros",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nReact only to some\nwavelengths, with different sensitivity (light fraction absorbed)\nThree kinds of cones\nBrain fuses responses from local neighborhood of several cones for perceived color\nSensitivities vary from person to person, and with age\ny t i v i t i s n e S\nColor blindness: deficiency in at least one type of cone\nWavelength (nm)",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nPossible evolutionary pressure for developing receptors for different wavelengths in primates\nOsorio & Vorobyev, 1996",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Trichromacy\nExperimental facts:\n‚Äì Three primaries will work for most people if we\nallow subtractive matching; ‚Äútrichromatic‚Äù nature of the human visual system\n‚Äì Most people make the same matches for a given set of primaries (i.e., select the same mixtures)",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Environmental effects & adaptation\nChromatic adaptation: we adapt to a particular illuminant\nAssimilation, contrast effects, chromatic induction: nearby colors affect what is perceived; receptor excitations interact across image and time\nAfterimages\nColor matching ~= color appearance\nPhysics of light ~= perception of light",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nIf the visual system is exposed to a certain illuminant for a while, color system starts to adapt / skew.",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent ¬© 2008 R.Beau Lotto ‚Ä¢ http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent ¬© 2008 R.Beau Lotto ‚Ä¢ http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page67",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent ¬© 2008 R.Beau Lotto ‚Ä¢ http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page68",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Content ¬© 2008 R.Beau Lotto ‚Ä¢ http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page69",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Content ¬© 2008 R.Beau Lotto ‚Ä¢ http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page70",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Content ¬© 2008 R.Beau Lotto ‚Ä¢ http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page71",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Content ¬© 2008 R.Beau Lotto ‚Ä¢ http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page72",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "After images\nTired photoreceptors send out negative response after a strong stimulus\nhttp://www.sandlotscience.com/Aftereffects/Andrus_Spiral.htm\nSource: Steve Seitz",
    "offset": "page73",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "After images\nTired photoreceptors send out negative response after a strong stimulus\nhttp://www.sandlotscience.com/Aftereffects/Andrus_Spiral.htm\nSource: Steve Seitz",
    "offset": "page74",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Name that color\nHigh level interactions affect perception and processing.",
    "offset": "page75",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n‚Äì Spectral power distributions ‚Äì Color mixing ‚Äì Color matching experiments ‚Äì Color spaces\nUniform color spaces\nPerception of color\n‚Äì Human photoreceptors ‚Äì Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page76",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\nBlobworld system, Carson et al, 1999",
    "offset": "page77",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\ns t n u o c\nl\ne x i P\nR\nG\nColor intensity\nB\nColor histograms: Use distribution of colors to describe image\nNo spatial info ‚Äì invariant to translation, rotation, scale",
    "offset": "page78",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\nCompute distance between histograms:\nIntersection\nSimilar\nDifferent",
    "offset": "page79",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nGiven a collection (database) of images:\n‚Äì Extract and store one color histogram per image\nGiven new query image:\n‚Äì Extract its color histogram ‚Äì For each database image:\nCompute intersection between query histogram and database histogram\n‚Äì Sort intersection values (highest score = most similar) ‚Äì Rank database items relative to query based on this sorted\norder",
    "offset": "page80",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample database",
    "offset": "page81",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample retrievals",
    "offset": "page82",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample retrievals",
    "offset": "page83",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "http://images.google.com/\nSearch for similar images. Try:\nBuildings ‚Ä¢ Dogs ‚Ä¢ Concert",
    "offset": "page84",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Shazam for Fashion\nThere are several products doing that. ‚Ä¢ They have to deal with color similarity: ‚Äì E.g.: http://www.spylight.com/",
    "offset": "page85",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Shazam for Fashion\nThere are several products doing that. ‚Ä¢ They have to deal with color similarity: ‚Äì E.g.: http://www.asap54.com/",
    "offset": "page86",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nM. Jones and J. Rehg, Statistical Color Models with Application to Skin Detection, IJCV 2002.",
    "offset": "page87",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection",
    "offset": "page88",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nhttp://www.ghvandoorn.nl/skindetection.html",
    "offset": "page89",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nOpenCV\nhttps://www.youtube.com/watch?v=vZk9k9azonw",
    "offset": "page90",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based tracking\nD. Ramanan, D. Forsyth, and A. Zisserman. Tracking People by Learning their Appearance. PAMI 2007.\nSlide credit: L. Lazebnik",
    "offset": "page91",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based tracking\nhttp://www.roborealm.com/tutorial/color_obj ect_tracking_2/slide010.php\nhttps://www.youtube.com/watch?v=WPnWD Gl3XZc",
    "offset": "page92",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Viewing Colored Objects",
    "offset": "page93",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\nTrevor Darrell ‚Ä¢ Kristen Grauman: 3-48, 50-75, 79-86 ‚Ä¢ Bob Woodham: 49, 87-90 ‚Ä¢ and others, indirectly (Steve Palmer, Brian Wandell, etc!)",
    "offset": "page94",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n‚Äì Spectral power distributions ‚Äì Color mixing ‚Äì Color matching experiments ‚Äì Color spaces\nUniform color spaces\nPerception of color\n‚Äì Human photoreceptors ‚Äì Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page95",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  }
]

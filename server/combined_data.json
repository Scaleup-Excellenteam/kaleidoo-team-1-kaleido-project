[
  {
    "filetype": "application/pdf",
    "text": "1\nFeature descriptors\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local descriptors\n Selecting invariant regions  Feature descriptors:  SIFT and others\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local descriptors\n Selecting invariant regions  Feature descriptors:  SIFT and others\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The naïve descriptor – intensities vector\n The Simplest descriptor is a vector of the intensities\nwithin the patch.\nreshape\nWhat is this going to be invariant to?\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The naïve descriptor – intensities vector\n Disadvantage of the intensities vector 1. Changes significantly with illumination 2. Changes significantly with small shifts in position\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Another naïve descriptor\n Disadvantage of the intensities vector 1. Changes significantly with illumination 2. Changes significantly with small shifts in position\n Solutions\n1. Use gradients instead of intensities 2. Histograms\n0\n6\nLihi Zelnik-Manor, Computer Vision\n2p",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "A good feature descriptor: SIFT\n Scale Invariant Feature Transform  Descriptor computation:\n Divide patch into 4x4 sub-patches: 16 cells  Compute histogram of gradient orientations (8 reference\nangles) for all pixels inside each sub-patch  Resulting descriptor: 4x4x8 = 128 dimensions\nDavid G. Lowe. \"Distinctive image features from scale-invariant keypoints.” IJCV’2004. 7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "SIFT overview\n Extraordinarily robust matching technique\n Can handle changes in viewpoint up to about 60 degree out of plane rotation  Can handle significant changes in illumination\n Sometimes even day vs. night (below)  Fast and efficient—can run in real time  Lots of code available\n\nhttp://people.csail.mit.edu/albert/ladypack/wiki/index.php/Known_implementations_of_SIFT\n8\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Working with SIFT descriptors\n One image yields:\n n 128-dimensional descriptors: each one is a histogram of the gradient orientations within a patch  [n x 128 matrix]\n n scale parameters specifying the size of\neach patch  [n x 1 vector]\n n orientation parameters specifying the\nangle of the patch  [n x 1 vector]\n n 2d points giving positions of the patches\n [n x 2 matrix]\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "SURF descriptor\n Fast approximation of SIFT  Efficient computation by 2D box filters & integral images  6 times faster than SIFT  Equivalent quality for object\nidentification\nGPU implementation available Feature extraction @ 200Hz (detector + descriptor, 640×480 img) http://www.vision.ee.ethz.ch/~surf\n[Bay, ECCV’06], [Cornelis, CVGPU’08]\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Local Descriptors: Shape Context\nCount the number of points inside each bin, e.g.:\nCount = 4\n. . .\nCount = 10\nLog-polar binning: more precision for nearby points, more flexibility for farther points.\nBelongie & Malik, ICCV 2001\nK. Grauman, B. Leibe",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Local Descriptors: Geometric Blur\n~\nExample descriptor\n(Idealized signal)\nBerg & Malik, CVPR 2001\nK. Grauman, B. Leibe\nCompute edges at four orientations\nExtract a patch in each channel\nApply spatially varying blur and sub-sample",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "GLOH\n Gradient Location and Orientation Histogram\n Very similar to SIFT  Log-polar location grid  3 bins in radial direction  8 bins in angular direction  Gradient orientation quantized to 16 bins\n Total dimension\n (2x8+1)*16=272 bins  PCA for dimension reduction\n13\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "More on feature detection/description\nhttp://www.robots.ox.ac.uk/~vgg/research/affine/detectors.html#binaries\n14\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Self-similarity descriptor\n All the descriptors so far captured same appearance  What can we do if the objects have the same shape but\ndifferent appearance?\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Self-similarity descriptor\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Self-similarity descriptor\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Self-similarity descriptor\ntemplate\nresults\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Self-similarity descriptor\ntemplate\nresults\n19\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Self-similarity descriptor\n20\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Advantages of local features  Useful\n It is critical to find distinctive and repeatable local regions for\nmulti‐view matching  Complexity reduction\n Selection of distinctive points reduces number of regions to\nprocess\n Compact description\n Describe images, objects, parts without requiring segmentation;\n Robustness\n To clutter & occlusion  Similar descriptors in spite of moderate view changes, noise,\nblur, etc.\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "22\nEnd – Feature descriptors\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/11-descriptors-SIFT-SURF-GLOH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nFeature detectors\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Stereo-view geometry\n Correspondence:\nGiven a point in one image, how can I find the corresponding point in another image?\n Camera geometry:\nGiven corresponding points in two images, find camera intrinsic and extrinsic parameters\n Scene geometry:\nFind coordinates of 3D point from its projection into two or multiple images.\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local invariant features\n Motivation  Requirements, invariances\n Keypoint localization\n Harris corner detector  Hessian detector\n Scale invariant region selection\n Automatic scale selection  Laplacian-of-Gaussian detector  Difference-of-Gaussian detector\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local invariant features\n Motivation  Requirements, invariances\n Keypoint localization\n Harris corner detector  Hessian detector\n Scale invariant region selection\n Automatic scale selection  Laplacian-of-Gaussian detector  Difference-of-Gaussian detector\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Motivation\n Global representations have major limitations  Instead, describe and match only local regions  Increased robustness to\n Occlusions\nArticulation\nIntra-category variations\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Application: Image matching\nby Diva Sian\n6\nLihi Zelnik-Manor, Computer Vision\nby swashford",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harder case\nby Diva Sian\n7\nLihi Zelnik-Manor, Computer Vision\nby scgbt",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harder still?\n8\nNASA Mars Rover images\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Answer below (look for tiny colored squares…)\nNASA Mars Rover images with SIFT feature matches. Figure by Noah Snavely\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Application: Image stitching\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Application: Image stitching\n Procedure:\n Detect feature points in both images\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Application: Image stitching\n Procedure:\n Detect feature points in both images  Find corresponding pairs\n12\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Application: Image stitching\n Procedure:\n Detect feature points in both images  Find corresponding pairs  Use these pairs to align images\n13\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "General approach  Find a set of distinctive\nkey-points\n Define a region around\neach keypoint\n Extract and normalize the region content\n Compute a local\ndescriptor from the normalized regions\n Match local descriptors\n14\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Requirements\n Problem 1:\n Detect the same point independently in both images\nno chance to match!\nWe need a repeatable detector\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Requirements\n Problem 1:\n Detect the same point independently in both images\n Problem 2:\n For each point correctly recognize the corresponding one\n?\nWe need a repeatable and distinctive detector\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Invariance 1: Geometric transformations\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Invariance 2: Photometric transformations\nOften modeled as a linear transformation:\nscaling + offset of colors\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "And other nuisances…\n Noise  Blur  Compression artifacts  …\n19\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Requirements summary\n Region extraction needs to be repeatable and accurate\n Invariant to translation, rotation, scale changes  Robust or covariant to out‐of‐plane (~affine) transformations  Robust to lighting variations, noise, blur, quantization\n Locality: Features are local, therefore robust to occlusion\nand clutter.\n Quantity: We need a sufficient number of regions to cover\nthe object.\n Distinctiveness: The regions should contain “interesting”\nstructure.\n Efficiency: Close to real‐time performance.\n20\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Many existing detectors are available  Hessian & Harris  Laplacian, DoG [Lindeberg ‘98], [Lowe ‘99]  Harris‐/Hessian‐Laplace [Mikolajczyk & Schmid ‘01]  Harris‐/Hessian‐Affine  EBR and IBR  MSER  Salient Regions  Others…\n[Beaudet ‘78], [Harris ‘88]\n[Mikolajczyk & Schmid ‘04]\n[Tuytelaars & Van Gool ‘04]\n[Matas ‘02]\n[Kadir & Brady ‘01]\n Those detectors have become a basic building block for many\nrecent applications in Computer Vision.\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local invariant features\n Motivation  Requirements, invariances\n Keypoint localization\n Harris corner detector  Hessian detector\n Scale invariant region selection\n Automatic scale selection  Laplacian-of-Gaussian detector  Difference-of-Gaussian detector\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Keypoint localization\n Goals:\n Repeatable detection  Precise localization  Interesting content\n Look for image regions\nthat are unusual  Lead to unambiguous\nmatches in other images\nHow to define “unusual”?\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Finding Corners\n Key property:\n In the region around a corner, image gradient has two or more\ndominant directions\n Corners are repeatable and distinctive\n[Harris et al. \"A Combined Corner and Edge Detector.“ 1988]\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Corners as distinctive interest points\n Design criteria:\n We should easily recognize the point by looking through a\nsmall window (locality)\n Shifting the window in any direction should give a large change in\nintensity (good localization)\n“flat” region: no change in all directions\n25\n“edge”: no change along the edge direction Lihi Zelnik-Manor, Computer Vision\n“corner”: significant change in all directions",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector formulation\n Change of intensity for the shift [u,v]\n2,(,)(,)(,)(,)xyEuvwxyIxuyvIxy\nWindow function\nShifted intensity\nIntensity\nWindow function w(x,y) =\nor\n1 in window, 0 outside\nGaussian\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector formulation This measure of change can be approximated by (Taylor expansion):\nvuMvuvuE][),(\nwhere M is a 22 matrix computed from image derivatives:\n22,(,)xxyxyxyyIIIMwxyIII\nGradient with respect to x, times gradient with respect to y\nSum over image region – area we are checking for corner\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector formulation\n What will M look like for each case?\n (On the board)\n“flat” region: no change in all directions\n28\n“edge”: no change along the edge direction Lihi Zelnik-Manor, Computer Vision\n“corner”: significant change in all directions",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Interpreting the eigenvalues Classification of image points using eigenvalues of M:\n2\n“Edge” 2 >> 1\n“Corner” 1 and 2 are large, 1 ~ 2; E increases in all directions\n1 and 2 are small; E is almost constant in all directions\n“Flat” region\n“Edge” 1 >> 2\n29\nLihi Zelnik-Manor, Computer Vision\n1",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Corner response function\n221212)()(trace)det(MMR\n“Edge” R < 0\n“Corner” R > 0\nFast approximation: • Avoid computing the\neigenvalues\nα: constant (0.04 to 0.15)\n|R| small\n“Flat” region\n“Edge” R < 0\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Rotation invariance\n Eigenvalues are of the same nature as before\n“flat” region: no change in all directions\n31\n“edge”: no change along the edge direction Lihi Zelnik-Manor, Computer Vision\n“corner”: significant change in all directions",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Summary: Harris Corner Detector\n Compute second moment matrix M\n1. Compute derivatives\n,xyII\n2.\nSquare of derivatives\n22,,xyxyIIII\n2xI\n3. Gaussian filter\n()g\n2()xgI\n4. Compute R scores\n Find points with large corner response\nR > threshold\n5. Perform non-maximum supression\n32\nLihi Zelnik-Manor, Computer Vision\nxI\n2yI\n2()ygI\nyI\nxyII\n()xygII\nR",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Workflow\n33\nLihi Zelnik-Manor, Computer Vision Slide adapted form Darya Frolova, Denis Simakov, Weizmann Institute.",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Workflow Compute corner response R\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Workflow\nFind points with large corner response: R>threshold\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Workflow\nTake only the points of local maxima of R\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Workflow Resulting Harris points\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris detector – example result\nA very accurate corner detector\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris detector – example result\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris detector – example result\nResults are usually good for stereo correspondences\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Properties  Is it rotation invariant?\nEllipse rotates but its shape (i.e. eigenvalues) remains the same\nYes: Corner response R is invariant to image rotation\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Properties\n Is it invariant to image scale?\nAll points will be classified as edges\nNo: Not invariant to image scale!\n42\nLihi Zelnik-Manor, Computer Vision\nCorner !",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local invariant features\n Motivation  Requirements, invariances\n Keypoint localization\n Harris corner detector  Hessian detector\n Scale invariant region selection\n Automatic scale selection  Laplacian-of-Gaussian detector  Difference-of-Gaussian detector\n43\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hessian detector [Beaudet 78]\n Hessian determinant\n Determined by second derivatives\n()xxxyxyyyIIHessianIII\n Key idea:\n Search for strong derivatives in\ntwo orthogonal directions\n44\nLihi Zelnik-Manor, Computer Vision\nxxI\nxyI\nyyI",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hessian detector [Beaudet 78]\n Hessian determinant\n Determined by second derivatives\n()xxxyxyyyIIHessianIII\n Key idea:\n Search for strong derivatives in\ntwo orthogonal directions\n2det()xxyyxyHessianIIII\n45\nLihi Zelnik-Manor, Computer Vision\nxxI\nxyI\nyyI",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hessian detector – example result\nResponses mainly on corners and strongly textured areas\n46\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hessian detector – example result\n47\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "48\nEnd – Feature detectors\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/09-feature-detectors-HarrisHassian.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670/5670: Intro to Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Reading\nSzeliski, Chapter 3.1-3.2",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nWe’ll focus on these in this class\n(More on this process later)\nDigital Camera\nThe Eye\nSource: A. Efros",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nA grid (matrix) of intensity values\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255\n20\n0 255 255 255 255 255 255 255\n255 255 255\n75\n75\n75 255 255 255 255 255 255\n=\n255 255\n75\n95\n95\n75 255 255 255 255 255 255\n255 255\n96 127 145 175 255 255 255 255 255 255\n255 255 127 145 175 175 175 255 255 255 255 255\n255 255 127 145 200 200 175 175\n95 255 255 255\n255 255 127 145 200 200 175 175\n95\n47 255 255\n255 255 127 145 145 175 127 127\n95\n47 255 255\n255 255\n74 127 127 127\n95\n95\n95\n47 255 255\n255 255 255\n74\n74\n74\n74\n74\n74 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n(common to use one byte per value: 0 = black, 255 = white)",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nWe can think of a (grayscale) image as a function, f, from R2 to R: – f (x,y) gives the intensity at position (x,y)\nf (x, y)\nx\ny\n– A digital image is a discrete (sampled, quantized)\nversion of this function",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image transformations\nAs with any function, we can apply operators to an image\ng (x,y) = f (x,y) + 20\ng (x,y) = f (-x,y)\nWe’ll talk about a special kind of operator, convolution (linear filtering)",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Question: Noise reduction • Given a camera and a still scene, how can you\nreduce noise?\nTake lots of images and average them! What’s the next best thing?\nSource: S. Seitz",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image filtering\nModify the pixels in an image based on some function of a local neighborhood of each pixel\n10\n5\n3\nSome function\n4\n5\n1\n7\n1\n1\n7\nLocal image data\nModified image data\nSource: L. Zhang",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Linear filtering\nOne simple version: linear filtering (cross-correlation, convolution)\n– Replace each pixel by a linear combination (a weighted\nsum) of its neighbors\nThe prescription for the linear combination is called the “kernel” (or “mask”, “filter”)\n10\n5\n3\n0\n0\n0\n4\n6\n1\n0\n0.5 0\n8\n1\n1\n8\n0\n1\n0.5\nLocal image data\nkernel\nModified image data\nSource: L. Zhang",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Cross-correlation\nLet be the image, be the kernel (of size 2k+1 x 2k+1), and be the output image. The cross-correlation operation is defined as:\nCan think of as a “dot product” between local neighborhood and kernel for each pixel\nShort notation:",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Convolution\nSame as cross-correlation, except that the kernel is “flipped” (horizontally and vertically)\nThis is called a convolution operation:\nConvolution is commutative and associative",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Convolution\nAdapted from F. Durand",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n1\n1\n1\n1\n1\n1\n1 *\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nMean filtering\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n90\n90\n90\n90\n90\n0\n90\n90\n90\n90\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n0\n=\n0\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n90\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n10 20 30 30 30 20 10\n0\n20 40 60 60 60 40 20\n0\n30 60 90 90 90 60 30\n0\n30 50 80 80 90 60 30\n0\n30 50 80 80 90 60 30\n0\n20 30 50 50 60 40 20\n10 20 30 30 30 30 20 10\n10 10 10\n0\n0\n0\n0\n0",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n1\n0\n0\n0\n0\n=\nIdentical image\nSource: D. Lowe",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n0\n0\n0\n1\n0\n=\nShifted left By 1 pixel\nSource: D. Lowe",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Linear filters: examples\n1\n1\n1\n1\n1\n1\n1\n1\n1\n=\nOriginal\nBlur (with a mean filter)\nSource: D. Lowe",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n2\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n=\nSharpening filter (accentuates edges)\nSource: D. Lowe",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sharpening\nSource: D. Lowe",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smoothing with box filter revisited\nSource: D. Forsyth",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian Kernel\nSource: C. Rasmussen",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian filters\n= 1 pixel\n= 5 pixels\n= 10 pixels\n= 30 pixels",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean vs. Gaussian filtering",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian filter\nRemoves “high-frequency” components from the image (low-pass filter)\nConvolution with self is another Gaussian\n=\n– Convolving twice with Gaussian kernel of width\n= convolving once with kernel of width\nSource: K. Grauman",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sharpening revisited\nWhat does blurring take away?\n–\n=\noriginal\nsmoothed (5x5)\nLet’s add it back:\n+ α\n=\noriginal\ndetail\ndetail\nsharpened\nSource: S. Lazebnik",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "image\nblurred image\nscaled impulse\nSharpen filter\nGaussian\nunit impulse (identity)\nLaplacian of Gaussian (LoG)",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "unfiltered\nfiltered\nSharpen filter",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "no"
  },
  {
    "filetype": "application/pdf",
    "text": "“Optical” Convolution\nCamera shake\n=\nSource: Fergus, et al. “Removing Camera Shake from a Single Photograph”, SIGGRAPH 2006\nBokeh: Blur in out-of-focus regions of an image.\nSource: http://www.diyphotography.net/diy_create_your_own_bokeh/",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?\nFor next time:\n– Read Szeliski, Chapter 3.1-3.2",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nImage Resampling",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image Scaling\nThis image is too big to fit on the screen. How can we generate a half-sized version?\nSource: S. Seitz",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\n1/4\nThrow away every other row and column to create a 1/2 size image - called image sub-sampling\n1/8\nSource: S. Seitz",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\n1/2\n1/4 (2x zoom)\nWhy does this look so crufty?\n1/8 (4x zoom)\nSource: S. Seitz",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\nSource: F. Durand",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Even worse for synthetic images\nSource: L. Zhang",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Aliasing\nOccurs when your sampling rate is not high enough to capture the amount of detail in your image • Can give you the wrong signal/image—an alias\nTo do sampling right, need to understand the structure of your signal/image\nEnter Monsieur Fourier…\nTo avoid aliasing:\n– sampling rate ≥ 2 * max frequency in the image • said another way: ≥ two samples per cycle\n– This minimum sampling rate is called the Nyquist rate\nSource: L. Zhang",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Wagon-wheel effect\n(See http://www.michaelbach.de/ot/mot_wagonWheel/index.html)\nSource: L. Zhang",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Nyquist limit – 2D example\nGood sampling\nBad sampling",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "tl"
  },
  {
    "filetype": "application/pdf",
    "text": "Aliasing\nWhen downsampling by a factor of two\n– Original image has frequencies that are too high\nHow can we fix this?",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pre-filtering\nG 1/4\nGaussian 1/2\nSolution: filter the image, then subsample\nG 1/8\nSource: S. Seitz",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Subsampling with Gaussian pre-filtering\nGaussian 1/2\nG 1/4\nSolution: filter the image, then subsample\nG 1/8\nSource: S. Seitz",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1/2\nCompare with...\n1/4 (2x zoom)\n1/8 (4x zoom)\nSource: S. Seitz",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pre-filtering • Solution: filter the image, then subsample\nblur\nF0\nsubsample\nF0 H*\nblur\nF1 subsample …\nF2\nF1 H*",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramid\nblur\nF0\nsubsample\nF0 H*\nblur\nF1 subsample …\nF2\nF1 H*",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramids [Burt and Adelson, 1983]\nIn computer graphics, a mip map [Williams, 1983] • A precursor to wavelet transform\nGaussian Pyramids have all sorts of applications in computer vision\nSource: S. Seitz",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramids [Burt and Adelson, 1983]\nHow much space does a Gaussian pyramid take compared to the original image?\nSource: S. Seitz",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian Pyramid",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fi"
  },
  {
    "filetype": "application/pdf",
    "text": "0G\nThe Laplacian Pyramid\n)expand(1iiiGGL\nGaussian Pyramid\n)expand(1iiiGLG\nnG\n2G\n=\n1G\n=\n=\nLaplacian Pyramid\nnnGL\n2L\n1L\n0L",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nImage Interpolation",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image Scaling\nLast time:\nThis image is too big to fit on the screen. How can we generate a half-sized version?\nSource: S. Seitz",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Upsampling\nThis image is too small for this screen: • How can we make it 10 times as big? • Simplest approach: repeat each row and column 10 times\n(“Nearest neighbor interpolation”)",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nd = 1 in this example\n1\n2\n3\n4\n5\nRecall how a digital image is formed\nIt is a discrete point-sampling of a continuous function • If we could somehow reconstruct the original function, any new image could be generated, at any resolution and scale\nAdapted from: S. Seitz",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nd = 1 in this example\n1\n2\n3\n4\n5\nRecall how a digital image is formed\nIt is a discrete point-sampling of a continuous function • If we could somehow reconstruct the original function, any new image could be generated, at any resolution and scale\nAdapted from: S. Seitz",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\n1\n1\n2\n2.5\n3\n4\n5\nWhat if we don’t know ?\nGuess an approximation: • Can be done in a principled way: filtering • Convert to a continuous function:\nReconstruct by convolution with a reconstruction filter, h\nd = 1 in this example\nAdapted from: S. Seitz",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\n“Ideal” reconstruction\nNearest-neighbor interpolation\nLinear interpolation\nGaussian reconstruction\nSource: B. Curless",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Reconstruction filters • What does the 2D version of this hat function look like?\nperforms linear interpolation\n(tent function) performs bilinear interpolation\nOften implemented without cross-correlation\nE.g., http://en.wikipedia.org/wiki/Bilinear_interpolation\nBetter filters give better resampled images\nBicubic is common choice\nCubic reconstruction filter",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nOriginal image: x 10\nNearest-neighbor interpolation\nBilinear interpolation\nBicubic interpolation",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nAlso used for resampling",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Raster to Vector Graphics",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Depixelating Pixel Art",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nAlgorithms and Applications in Computer Vision\nLihi Zelnik-Manor lihi@ee.technion.ac.il\nLihi Zelnik-Manor, Computer vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n “What is computer vision?”  Administration\n2\nLihi Zelnik-Manor, Computer vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is computer vision?\nDone?\n3\nLihi Zelnik-Manor, Computer vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The goal of computer vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is computer vision?\n Automatic understanding of images and video\n Measurement: Computing properties of the 3D world from\nvisual data\n Perception and interpretation: Algorithms and representations to allow a machine to recognize objects, people, scenes, and activities.\n Image enhancement: super-resolution, synthesis, deblur\n(computational photography).\n5\nLihi Zelnik-Manor, Computer vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision for measurement\nReal-time stereo\nStructure from motion\nMulti-view stereo for community photo collections\nNASA Mars Rover\nPollefeys et al.\nGoesele et al.\n6\nLihi Zelnik-Manor, Computer vision\nSlide credit: L. Lazebnik",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision for perception, interpretation\nThe Wicked Twister\nride\nsky\namusement park\nCedar Point\nFerris wheel\nride\nObjects Activities Scenes Locations Text / writing Faces Gestures Motions Emotions…\n12 E\nLake Erie\nwater\nride\ntree\ntree\npeople waiting in line\npeople sitting on ride\numbrellas\n7\ndeck\ntree\nbench\ncarousel\ntree\npedestrians\nLihi Zelnik-Manor, Computer vision\nmaxair",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "“Enhancing” images (c.f. Computational Photography)\nTexture synthesis / increased field of view (uncropping) (image credit: Efros and Leung)\nSuper-resolution / denoising (source: 2d3)\nInpainting / image completion (image credit: Hays and Efros)",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Related disciplines\nGraphics\nArtificial intelligence\nMachine learning\nImage processing\nComputer vision\nCognitive science\nAlgorithms\n9\nLihi Zelnik-Manor, Computer vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision and graphics\nImages\nVision\nModel\nGraphics\nInverse problems: analysis and synthesis.\n10\nLihi Zelnik-Manor, Computer vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why study computer vision?\n Vision is useful\n Vision is interesting\n Vision is difficult\n Half of primate cerebral cortex is devoted to visual processing  Achieving human-level visual perception is probably\n“AI-complete” (is this really true??)\n11\nLihi Zelnik-Manor, Computer vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is vision useful?\n As image sources multiply, so do applications\n Relieve humans of boring, easy tasks\n Enhance human abilities: human-computer interaction,\nvisualization\n Perception for robotics / autonomous agents\n Organize and give access to visual content\n12\nLihi Zelnik-Manor, Computer vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is it interesting?  Images and videos are everywhere!\nPersonal photo albums\nMovies, news, sports\nSurveillance and security\nMedical and scientific images\n13\nLihi Zelnik-Manor, Computer vision\nSlide credit; L. Lazebnik",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is it difficult?\n14\nLihi Zelnik-Manor, Computer vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Viewing angle\n15\nLihi Zelnik-Manor, Computer vision\nMichelangelo, David",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Lighting\n16\nLihi Zelnik-Manor, Computer vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Size\n17\nLihi Zelnik-Manor, Computer vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Occlusions\n18\nLihi Zelnik-Manor, Computer vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Deformation\n19\nLihi Zelnik-Manor, Computer vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Deformation\n20\nLihi Zelnik-Manor, Computer vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Camera limitations (e.g. saturation)\n21\nLihi Zelnik-Manor, Computer vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Motion blur\n22\nLihi Zelnik-Manor, Computer vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Intra-class variability\n23\nLihi Zelnik-Manor, Computer vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "But there are lots of cues we can exploit…\nSource: S. Lazebnik",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Bottom line  Perception is an inherently ambiguous problem\n Many different 3D scenes could have given rise to a particular\n2D picture\n We often need to use prior knowledge about the structure of\nthe world\nImage source: F. Durand",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computer vision in practice\n26\nLihi Zelnik-Manor, Computer vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision Demo?\nTerminator 2\n27\nwe’re not quite there yet….\nLihi Zelnik-Manor, Computer vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Earth viewers (3D modeling)\nImage from Microsoft’s Virtual Earth (see also: Google Earth)\n28\nLihi Zelnik-Manor, Computer vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photosynth\nhttp://labs.live.com/photosynth/\nBased on Photo Tourism technology developed by Noah Snavely, Steve Seitz, and Rick Szeliski\n29\nLihi Zelnik-Manor, Computer vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photo Tourism overview\nScene reconstruction\nPhoto Explorer\nInput photographs\nRelative camera positions and orientations\nPoint cloud\nSparse correspondence\nSystem for interactive browsing and exploring large collections of photos of a scene. Computes viewpoint of each photo as well as a sparse 3d model of the scene.\n30\nLihi Zelnik-Manor, Computer vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photo Tourism overview\n31\nLihi Zelnik-Manor, Computer vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Optical character recognition (OCR)\n Technology to convert scanned docs to text  If you have a scanner, it probably came with OCR\nsoftware\nDigit recognition, AT&T labs http://www.research.att.com/~yann/\nLicense plate readers http://en.wikipedia.org/wiki/Automatic_number_plate_recognition\n32\nLihi Zelnik-Manor, Computer vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Face detection\n Most digital cameras now detect faces in realtime\n33\nLihi Zelnik-Manor, Computer vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smile detection?\nSony Cyber-shot® T70 Digital Still Camera\n34\nLihi Zelnik-Manor, Computer vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Face Recognition\nhttp://developers.face.com/tools/",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Object recognition (in supermarkets)\nLaneHawk by EvolutionRobotics “A smart camera is flush-mounted in the checkout lane, continuously watching for items. When an item is detected and recognized, the cashier verifies the quantity of items that were found under the basket, and continues to close the transaction. The item can remain under the basket, and with LaneHawk,you are assured to get paid for it… “\n36\nLihi Zelnik-Manor, Computer vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Biometrics\nWho is she?\n37\nLihi Zelnik-Manor, Computer vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision-based biometrics\n“How the Afghan Girl was Identified by Her Iris Patterns” Read the story\n38\nLihi Zelnik-Manor, Computer vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Login without a password…\nFingerprint scanners on many new laptops, other devices\nFace recognition systems now beginning to appear more widely http://www.sensiblevision.com/\n39\nLihi Zelnik-Manor, Computer vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Object recognition (in mobile phones)\n40\nLihi Zelnik-Manor, Computer vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Google Goggles",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "da"
  },
  {
    "filetype": "application/pdf",
    "text": "Google Search by Image",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Leaf Recognition",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Special effects: shape capture\nThe Matrix movies, ESC Entertainment, XYZRGB, NRC\n44\nLihi Zelnik-Manor, Computer vision",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Special effects: motion capture\nPirates of the Carribean, Industrial Light and Magic\n45\nLihi Zelnik-Manor, Computer vision",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sports\nSportvision first down line Nice explanation on www.howstuffworks.com\n46\nLihi Zelnik-Manor, Computer vision",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smart cars\n Mobileye https://www.youtube.com/watch?v=HXpiyLUEOOY  Tesla https://www.youtube.com/watch?v=4CZe5DXeYzw\n47\nLihi Zelnik-Manor, Computer vision\nSource: Amnon Shashua",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision-based interaction (and games)\nDigimask: put your face on a 3D avatar.\nNintendo Wii has camera-based IR tracking built in. See Lee’s work at CMU on clever tricks on using it to create a multi-touch display!\n“Game turns moviegoers into Human Joysticks”, CNET Camera tracking a crowd, based on this work.\n48\nLihi Zelnik-Manor, Computer vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Kinect",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision in space\nNASA'S Mars Exploration Rover Spirit captured this westward view from atop a low plateau where Spirit spent the closing months of 2007. Vision systems (JPL) used for several tasks\nPanorama stitching • 3D terrain modeling • Obstacle detection, position tracking • For more, read “Computer Vision on Mars” by Matthies et al. Lihi Zelnik-Manor, Computer vision\nPanorama stitching • 3D terrain modeling • Obstacle detection, position tracking • For more, read “Computer Vision on Mars” by Matthies et al. Lihi Zelnik-Manor, Computer vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Robotics\nNASA’s Mars Spirit Rover http://en.wikipedia.org/wiki/Spirit_rover\nhttp://www.robocup.org/\n51\nLihi Zelnik-Manor, Computer vision",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Medical imaging\n3D imaging MRI, CT\n52\nImage guided surgery Grimson et al., MIT\nLihi Zelnik-Manor, Computer vision",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Current state of the art\n You just saw examples of current systems.  Many of these are less than 5 years old\n This is a very active research area, and rapidly changing\n Many new apps in the next 5 years\n To learn more about vision applications and companies\n David Lowe maintains an excellent overview of vision\ncompanies  http://www.cs.ubc.ca/spider/lowe/vision.html\n53\nLihi Zelnik-Manor, Computer vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "AI has come\n https://openai.com/blog/introducing-openai/\n Toyota Invests $1 Billion in Artificial Intelligence in U.S.\nhttp://www.nytimes.com/2015/11/06/technology/toyota- silicon-valley-artificial-intelligence-research- center.html?_r=0\n Facebook AI Research (FAIR)\nhttps://research.facebook.com/ai\n54\nLihi Zelnik-Manor, Computer vision",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Again, what is computer vision?\n Mathematics of geometry of image formation?  Statistics of the natural world?  Models for neuroscience?  Engineering methods for matching images?  Science Fiction?\n55\nLihi Zelnik-Manor, Computer vision",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n “What is computer vision?”  Administration\n56\nLihi Zelnik-Manor, Computer vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Course overview (tentative)\n1.\nLow-level vision\n2.\n\nimage processing, edge detection, feature detection, cameras, image formation Basic Geometry\n\nprojective geometry, Optical flow, panoramas\n3.\nRecognition\n\nface detection / recognition, category recognition, segmentation\n4.\nIntroduction to Deep Learning",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Prerequisites\n : What I expect you to already know  A good working knowledge of Python programming\n(or willingness and time to pick it up quickly!)\n Linear algebra\n58\nLihi Zelnik-Manor, Computer vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Books\n Rick Szeliski’s book:\nComputer Vision: Algorithms and applications\n Forsyth and Ponce,\nComputer Vision: A Modern Approach.\n59\nLihi Zelnik-Manor, Computer vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Szeliski Book\n60\nLihi Zelnik-Manor, Computer vision",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "sl"
  },
  {
    "filetype": "application/pdf",
    "text": "Forsyth & Ponce Book\n61\nLihi Zelnik-Manor, Computer vision",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Programming\n Problem sets and projects will involve Python programming (you are\nfree to use alternative packages).a\n62\nLihi Zelnik-Manor, Computer vision",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Grading\n There will be three components to the course grade\n HW assignments, 2-3, including programming projects\n Final Project\n Class attendance, class participation, short quizes?a\n63\nLihi Zelnik-Manor, Computer vision",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Problem sets – still not finalized\n\n\n\n\nPset1 – Edge detection and voting techniques Pset2 – Image segmentation Pset3 – Feature tracking and alignment Pset4 – Recognition\n\n\nCan discuss, but must have your own code. Submit work in singles.a\n64\nLihi Zelnik-Manor, Computer vision",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Course goals….\n You’ll know something about computer vision\n65\nLihi Zelnik-Manor, Computer vision",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "And now, who are you?\n What do you expect to get out of this class?  Previous experience in vision, learning, graphics?  Research agenda?  (Project topics?)\n66\nLihi Zelnik-Manor, Computer vision",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nAlignment\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations  Panoramas\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations  Panoramas\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Feature matching\nWe know how to detect and describe good points Next question: How to match them?\n?\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Feature matching\nGiven a feature in Image1, how to find the best match in Image2\n1. Define distance function that compares two descriptors 2. Compute distances between all pairs features and find the ones with min distance\nf1\n5\nLihi Zelnik-Manor, Computer Vision\nf2",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Feature matching - better\nGiven a feature in Image1, how to find the best match in Image2\n1. Define distance function that compares two descriptors 2. Compute distances between all pairs features and find matches that dist(f1,best match) / dist(f1,second-best match) > threshold\nf1\nf2\n'\n6\nLihi Zelnik-Manor, Computer Vision\nf2",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Typical feature matching results\n Some matches are correct  Some matches are incorrect\n Solution: search for a set of geometrically consistent matches\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What we need to solve\n Given source and target images, how do we compute the\ntransformation between them?\n8\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations  Panoramas\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image alignment\n Turns out that in many cases there’s a global transformation relating points in two images:\n𝑝′ = 𝐻𝑝\n11''yxHyx\n𝑝\n𝑝′\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Parametric (global) warping\n Examples of parametric transformations:\ntranslation\nIn-plane rotation\naffine\nperspective\n11\nLihi Zelnik-Manor, Computer Vision\noriginal\nAspect ratio",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scaling  Scaling a coordinate means multiplying each of its components by a scalar  Uniform scaling means this scalar is the same for all components:\n 2",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scaling  Non-uniform scaling: different scalars per component:\nX  2, Y  0.5",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scaling\n Scaling operation:\n Or, in matrix form:\nbyyaxx''\n110000001''yxbayx\nscaling matrix S",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "2-D Rotation\n(x’, y’)\n\n(x, y)\nx’ = x cos() - y sin() y’ = x sin() + y cos()",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "2-D Rotation\n(x’, y’)\n(x, y)\n\nf\nPolar coordinates… x = r cos (f) y = r sin (f) x’ = r cos (f + ) y’ = r sin (f + )\nTrig Identity… x’ = r cos(f) cos() – r sin(f) sin() y’ = r sin(f) cos() + r cos(f) sin()\nSubstitute… x’ = x cos() - y sin() y’ = x sin() + y cos()",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "2-D Rotation This is easy to capture in matrix form:\n11000cossin0sincos1''yxyx\nR\nEven though sin() and cos() are nonlinear functions of ,\n x’ is a linear combination of x and y  y’ is a linear combination of x and y\nWhat is the inverse transformation?\n Rotation by –  For rotation matrices 𝑅−1 = 𝑅𝑇",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Basic 2D2D Transformations\n110010011''yxttyxyx\n11000cossin0sincos1''yxyx\nTranslation\nRotate in-plane\n''10011xabcxydefy\nAffine Combination of translation, scale, rotation, shear\n18\nLihi Zelnik-Manor, Computer Vision\n110000001''yxbayx\nScale/Aspect ratio\n110001011''yxbayx\nShear",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine Transformations  Affine transformations are combinations of …\n Linear transformations, and  Translations\nwyxfedcbawyx100''\n Properties of affine transformations:\n Origin does not necessarily map to origin  Lines map to lines  Parallel lines remain parallel  Ratios are preserved  Closed under composition",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Projective Transformations\n Projective transformations …\n Affine transformations, and  Projective warps\nwyxihgfedcbawyx'''\n Properties of projective transformations:\n Lines map to lines  Parallel lines do not necessarily remain parallel  Ratios are not preserved  Closed under composition  Projective matrix is defined up to a scale (8 DOF)",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Basic 2D2D Transformations\n110010011''yxttyxyx\n11000cossin0sincos1''yxyx\n110000001''yxbayx\nTranslation\nRotate in-plane\nScale/Aspect ratio\n''10011xabcxydefy\n''11xabcxydefywgh\nAffine\nProjective (Homography)\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "2D image transformations (reference table)",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "When do we get affine or homography?\n Camera does not translate (only rotation and scale)\nTransformation between coordinates in 3D:\n𝑃′ = 𝑅𝑃 + 𝑇\n𝑃′ = [𝑋′, 𝑌′, 𝑍′]\n𝑃 = [𝑋, 𝑌, 𝑍]\nWithout translation:\n𝑝′ → 𝑀′𝑃′\n𝑝 → 𝑀𝑃\n𝑃′ = 𝑅𝑃\nAnd the projections:\n𝑝′ = 𝐻𝑝\n𝑂2\n𝑂1\n𝑅, 𝑇\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "When do we get affine or homography?\n Camera does not translate (only rotation and scale)\n Object is planar  Works fine for small viewpoint changes\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Homographies == Planar Perspective Maps\nCalled a homography (or planar perspective map)",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting an affine transformation\nAffine model approximates perspective projection of planar objects.\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations\n Least-squares  RANSAC  Panoramas\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting an affine transformation\nAssuming we know the correspondences, how do we get the transformation?\n),(iiyx\n),(iiyx\n00111iiiixabcxydefy\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting an affine transformation\nAssuming we know the correspondences, how do we get the transformation?\n),(iiyx\n),(iiyx\n00100001iiiiiiabxycxxydyef\n00111iiiixabcxydefy\n29\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting an affine transformation\n Solve with Least-squares\n00100001iiiiiiabxycxxydyef\n How many matches (correspondence pairs) do we need to solve for the\ntransformation parameters?\n Once we have solved for the parameters, how do we compute the coordinates of the corresponding point for any pixel ?\n),(newnewyx\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting a projective transformation  Recall working with homogenous coordinates\n1'1iiiiixabcxydefyghw\n The equations we get are\niiiiiiiiiiiaxbycxgxhyadxeyfygxhya\n Solve with SVD\n''iiiiiixxwyyw\n00010000011iiiiabcdxyexyfgh\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations\n Least-squares  RANSAC  Panoramas\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC\n1. Randomly select a seed group of matches\n2. Compute transformation (using Least-squares) from seed group\n3.\nFind inliers to this transformation\n4.\nIf the number of inliers is sufficiently large, re-compute least- squares estimate of transformation on all of the inliers\n5. Keep the transformation with the largest number of inliers\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: Translation\nAll given matches\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: Translation\nSelect one match\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: Translation\ncount inliers\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: Translation\nSelect one match\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: Translation\ncount inliers\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: Translation\nKeep the best transformation\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: Translation\nFind “average” translation of “good” matches\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: homography\nAll matches\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: homography\nAfter RANSAC\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC example: homography\nApplying the homography\n43\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations\n Least-squares  RANSAC  Panoramas\n Multi-frame estimation  Warping  Blending\n44\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Panoramas\nObtain a wider angle view by combining multiple images.\n45\nLihi Zelnik-Manor, Computer Vision\ni\nm a g e\nf r o m S\n.\nS e i t z\n. . .",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Panoramas\n46\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Panoramas\n47\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "id"
  },
  {
    "filetype": "application/pdf",
    "text": "Panoramas\n48\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "id"
  },
  {
    "filetype": "application/pdf",
    "text": "Problem: Drift\n Error accumulation\n small (vertical) errors accumulate over time  apply correction so that sum = 0 (for 360° pan.)\n49\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Aligning multiple images\n Bundle adjustment\nijx\nijr\nwarp\n'ijx\ni’th image pair\n11allpairsmatchesiniijijEfe\nijr\nf , xmax let us bound the effect of outliers\n50\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gradient descent\n51\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Newton’s method\n52\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Newton in N dimensions\n53\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Minimizing sum of residuals\n54\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Levenberg-Marquardt\n55\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Levenberg-Marquardt\nAll unknowns\nCompute analytically\nrJ\nJacobian\nPrior parameter Covariance matrix\npC\nStep size\n\n56\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Multi-frame optimization\nRotation matrix\nCalibration matrix\nUnknown parameters for image i\n123Tiiiiif\n57\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Bundle adjustment formulations\nAll pairs optimization:\nConfidence / uncertainty of point i in image j\nMap 2D point i in image j to 2D point in image k\nFull bundle adjustment, using 3-D point positions\nMap 3D point i to 2D point in image i\nBundle adjustment using 3-D ray:\n3-D ray from point i\nAll-pairs 3-D ray formulation:\n3-D ray from points i and j\nProjected point\n58\nLihi Zelnik-Manor, Computer Vision\n3-D ray from point",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations\n Least-squares  RANSAC  Panoramas\n Multi-frame estimation  Warping  Blending\n59\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What we need to solve\n Given source and target images, and the transformation\nbetween them, how do we align them?\n Send each pixel x in image1 to its corresponding location x’ in\nimage 2\nx\nimage1\nx’\nimage 2\n60\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forward Warping\n What if pixel lands “between” two pixels?\n Answer: add “contribution” to several pixels and normalize\n(splatting)\nx\nImage 1\nx’\nImage 2\n61\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forward Warping\n What if pixel lands “between” two pixels?\n Answer: add “contribution” to several pixels and normalize\n(splatting)\n Limitation: Holes (some pixels are never visited)\n“Hole”\nx\nImage 1\nx’\nImage 2\n62\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Inverse Warping\n For each pixel x’ in image 2 find its origin x in image 1\n Problem: What if pixel comes from “between” two pixels?\nx\nImage 1\nx’\nImage 2\n63\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Inverse Warping\n For each pixel x’ in image 2 find its origin x in image 1\n Problem: What if pixel comes from “between” two pixels?  Answer: interpolate color value from neighbors\nx\nImage 1\nx’\nImage 2\n64\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Bilinear interpolation\nSampling at f(x,y):\n65\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Interpolation\n Possible interpolation filters:\n nearest neighbor  Bilinear interpolation  bicubic interpolation  sinc / FIR\n Needed to prevent “jaggies”\nand “texture crawl”\n66\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Matching local features  Parametric transformations  Computing parametric transformations\n Least-squares  RANSAC  Panoramas\n Multi-frame estimation  Warping  Blending\n67\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page67",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image feathering\n Weight each image proportional to its distance from the edge\n(distance map [Danielsson, CVGIP 1980]\n 1. Generate weight map for each image  2. Sum up all of the weights and divide by sum:\nweights sum up to 1:\nwi’ = wi / ( ∑i wi)\n68\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page68",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image feathering\n69\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page69",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image feathering\n+\n1 0\n=\n1 0\n70\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page70",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Panoramas – summary\n Detect features  Compute transformations between pairs of frames  Refine transformations using bundle-adjustment  Warp all images onto a single coordinate system  Blend\n71\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page71",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "72\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page72",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "73\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page73",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "74\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page74",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "75\nEnd – Alignment\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page75",
    "ref": "/home/ameer/Kaleidoo/server/uploads/12-alignment-panorama.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computer Vision\nLihi Zelnik-Manor lihi@ee.technion.ac.il",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Color\nColor\n`\nReadings:\n– Forsyth and Ponce, Chapter 6 – Szeliski, 2.3.2",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\nTrevor Darrell • Kristen Grauman: 3-48, 50-75, 79-86 • Bob Woodham: 49, 87-90 • and others, indirectly (Steve Palmer, Brian Wandell, etc!)",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color and light\nColor of light arriving at camera depends on\n– Spectral reflectance of the surface light is leaving – Spectral radiance of light falling on that patch\nColor perceived depends on\n– Physics of light – Visual system receptors – Brain processing, environment",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color and light\nWhite light: composed of about equal energy in all wavelengths of the visible spectrum\nNewton 1665\nImage from http://micro.magnet.fsu.edu/",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Electromagnetic spectrum\nHuman Luminance Sensitivity Function\nImage credit: nasa.gov",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Measuring spectra\nSpectroradiometer: separate input light into its different wavelengths, and measure the energy at each.\nFoundations of Vision, B. Wandell",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Spectral power distribution\nThe power per unit area at each wavelength of a radiant object\n# Photons(per ms.)\n400 500 600 700Wavelength (nm.)\nFigure © Stephen E. Palmer, 2002",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Spectral power distributions\nSome examples of the spectra of light sources\n.\n# PhotonsD. Normal DaylightWavelength (nm.)B. Gallium Phosphide Crystal400 500 600 700# PhotonsWavelength (nm.)A. Ruby Laser\n400 500 600 700400 500 600 700\n# Photons\n# PhotonsC. Tungsten Lightbulb400 500 600 700\n© Stephen E. Palmer, 2002",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The color viewed is also affected by the surface’s spectral reflectance properties.\nSpectral reflectances for some natural objects: how much of each wavelength is reflected for that surface\nForsyth & Ponce, measurements by E. Koivisto",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "d e\nt c e\nl f\ne R s n o\nt\no h P %\nSurface reflectance spectra\nSome examples of the reflectance spectra of surfaces\nRed\nYellow\nBlue\nPurple\n400 700\n400 700\n400 700\n400 700\nWavelength (nm)\n© Stephen E. Palmer, 2002",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nThere is no simple functional description for the perceived color of all lights under all viewing conditions, but …...\nA helpful constraint:\nConsider only physical spectra with normal distributions\nmean\nWavelength (nm.)# Photons400700\n500600\narea\nvariance\n© Stephen E. Palmer, 2002",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nMean\nHue\ns n o\nt\no h P #\nyellowgreenblue\nWavelength\n© Stephen E. Palmer, 2002",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nVariance\nSaturation\nhighmediumlow\nhi.med.low\ns n o\nt\no h P #\nWavelength\n© Stephen E. Palmer, 2002",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nArea\nBrightness\ns n o\nt\no h P #\nbrightdark\nB. Area Lightness\nWavelength\n© Stephen E. Palmer, 2002",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color mixing\nCartoon spectra for color names:\nSource: W. Freeman",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Additive color mixing\nColors combine by adding color spectra\nLight adds to black.\nSource: W. Freeman",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Examples of additive color systems\nCRT phosphors\nmultiple projectors\nhttp://www.jegsworks.com\nhttp://www.crtprojectors.co.uk/",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Subtractive color mixing\nColors combine by multiplying color spectra.\nPigments remove color from incident light (white).\nSource: W. Freeman",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Examples of subtractive color systems\nPrinting on paper • Most photographic film",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why specify color numerically?\nAccurate color reproduction is commercially valuable – Many products are identified by color\nFew color names are widely recognized by English speakers – 11: black, blue, brown, grey, green, orange, pink, purple, red, white, and\nyellow.\n– Other languages have fewer/more. – Common to disagree on appropriate color names.\nColor reproduction problems increased by prevalence of digital imaging – e.g. digital libraries of art. – How to ensure that everyone perceives the same color? – What spectral radiances produce the same response from people under\nsimple viewing conditions?\nForsyth & Ponce",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nGoal:\nWhat spectral radiances produce same response in human observers?",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nObserver adjusts weight (intensity) for primary lights (fixed SPD’s) to match appearance of test light.\nFoundations of Vision, by Brian Wandell, Sinauer Assoc., 1995\nAfter Judd & Wyszecki.",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nGoal:\nWhat spectral radiances produce same response in human observers?\nAssumption:\nUnder simple viewing conditions only “test light” affects perception – Ignoring additional factors for now like adaptation,\ncomplex surrounding scenes, etc.",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\nThe primary color amounts needed for a match\np1 p2 p3",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiment 2\nWe say a “negative” amount of p2 was needed to make the match, because we added it to the test color’s side.\nTest light\nPrimary lights\nThe primary color amounts needed for a match:\np1 p2 p3\np1 p2 p3\np1 p2 p3",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching\nWhat must we require of the primary lights chosen? • How are three numbers enough to represent entire 121233ecolorePPPe\nWhat must we require of the primary lights chosen? • How are three numbers enough to represent entire spectrum?\nweights",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Metamers\nLights forming a perceptual match still may be physically different\n– Match light: a combination of primaries – Test light: any light\nMetamers: pairs of lights that match perceptually but not physically\nDifferent spectrum\nSame primary mixture weights",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "How to compute the weights of the primaries to match any new spectral signal?\nGiven: a choice of three primaries and a target color signal\nFind: weights of the primaries needed to match the color signal\n?\np1 p2 p3\ne1\ne2 e3\nChallenge: we cannot use manual tuning for all colors in the world",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\n1.\nSelect primaries\n2. Collect weights for all monochromatic lights:\n112131ccc\nPut them in a big matrix:\n111212313()()()()()()NNNcccccc",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\n1.\nSelect primaries\n2. Collect weights for all monochromatic lights:\n112131ccc\n3. Compute the weights of any color by:\n1111121223133()()()()()()NNNNtccecceccet",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\nArbitrary new spectral signal is linear combination of the monochromatic sources.\n)()(1Nttt\nt\n…\nColor matching functions specify how to match a unit of each wavelength, so:\n)()()()()()()()()(21313212111321NNNNtttcccccceee\nCte\nKristen Grauman",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\nWhy is computing the color\nmatch for any color signal for a given set of primaries useful? – Want to paint a carton of Kodak film\nwith the Kodak yellow color. – Want to match skin color of a\nperson in a photograph printed on an ink jet printer to their true skin color.\n– Want the colors in the world, on a monitor, and in a print format to all look the same.\nAdapted from W. Freeman\nImage credit: pbs.org",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Standard color spaces\nUse a common set of primaries/color matching functions\nLinear color space examples\n– RGB – CIE XYZ\nNon-linear color space\n– HSV – CIE LAB",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RGB color space\nSingle wavelength primaries • Good for devices (e.g., phosphors for monitor), but not for perception\nRGB color matching functions",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE XYZ color space\nEstablished by the commission international d’eclairage (CIE), 1931\nUsually projected to display: (x,y) = (X/(X+Y+Z), Y/(X+Y+Z))\nCIE XYZ Color matching functions",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Distances in color space\nAre distances between points in a color space perceptually meaningful?",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Distances in color space\nNot necessarily: CIE XYZ is not a uniform color space, so magnitude of differences in coordinates are poor indicator of color “distance”.\nMcAdam ellipses: Just noticeable differences in color",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE XYZ\nUniform color spaces\nCIE Lu’v’\nCIE Lab",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE LAB color space\nEstablished by the CIE in 1948 and then 1976 • Goal: perceptually uniform",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "HSV color space\nHue, Saturation, Value (Brightness) • Nonlinear – reflects topology of colors by coding hue as an angle\nIntuitive for color picking\nImage from mathworks.com",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color\nColor of light arriving at camera depends on\n– Spectral reflectance of the surface light is leaving – Spectral radiance of light falling on that patch\nColor perceived depends on\n– Physics of light – Visual system receptors – Brain processing, environment",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nRods responsible for intensity -Cones responsible for color -Fovea: small region (1 or 2°) at the center of the visual field containing the highest density of cones (and no rods). – Less visual acuity in the periphery\nAdapted from Seitz, Duygulu",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Two types of light-sensitive receptors\nCones\ncone-shaped less sensitive operate in high light color vision\nRods\nrod-shaped highly sensitive operate at night gray-scale vision\n© Stephen E. Palmer, 2002\nSlide credit: Alyosha Efros",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nReact only to some\nwavelengths, with different sensitivity (light fraction absorbed)\nThree kinds of cones\nBrain fuses responses from local neighborhood of several cones for perceived color\nSensitivities vary from person to person, and with age\ny t i v i t i s n e S\nColor blindness: deficiency in at least one type of cone\nWavelength (nm)",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nPossible evolutionary pressure for developing receptors for different wavelengths in primates\nOsorio & Vorobyev, 1996",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Trichromacy\nExperimental facts:\n– Three primaries will work for most people if we\nallow subtractive matching; “trichromatic” nature of the human visual system\n– Most people make the same matches for a given set of primaries (i.e., select the same mixtures)",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Environmental effects & adaptation\nChromatic adaptation: we adapt to a particular illuminant\nAssimilation, contrast effects, chromatic induction: nearby colors affect what is perceived; receptor excitations interact across image and time\nAfterimages\nColor matching ~= color appearance\nPhysics of light ~= perception of light",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nIf the visual system is exposed to a certain illuminant for a while, color system starts to adapt / skew.",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page67",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page68",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page69",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page70",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page71",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page72",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "After images\nTired photoreceptors send out negative response after a strong stimulus\nhttp://www.sandlotscience.com/Aftereffects/Andrus_Spiral.htm\nSource: Steve Seitz",
    "offset": "page73",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "After images\nTired photoreceptors send out negative response after a strong stimulus\nhttp://www.sandlotscience.com/Aftereffects/Andrus_Spiral.htm\nSource: Steve Seitz",
    "offset": "page74",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Name that color\nHigh level interactions affect perception and processing.",
    "offset": "page75",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page76",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\nBlobworld system, Carson et al, 1999",
    "offset": "page77",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\ns t n u o c\nl\ne x i P\nR\nG\nColor intensity\nB\nColor histograms: Use distribution of colors to describe image\nNo spatial info – invariant to translation, rotation, scale",
    "offset": "page78",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\nCompute distance between histograms:\nIntersection\nSimilar\nDifferent",
    "offset": "page79",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nGiven a collection (database) of images:\n– Extract and store one color histogram per image\nGiven new query image:\n– Extract its color histogram – For each database image:\nCompute intersection between query histogram and database histogram\n– Sort intersection values (highest score = most similar) – Rank database items relative to query based on this sorted\norder",
    "offset": "page80",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample database",
    "offset": "page81",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample retrievals",
    "offset": "page82",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample retrievals",
    "offset": "page83",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "http://images.google.com/\nSearch for similar images. Try:\nBuildings • Dogs • Concert",
    "offset": "page84",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Shazam for Fashion\nThere are several products doing that. • They have to deal with color similarity: – E.g.: http://www.spylight.com/",
    "offset": "page85",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Shazam for Fashion\nThere are several products doing that. • They have to deal with color similarity: – E.g.: http://www.asap54.com/",
    "offset": "page86",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nM. Jones and J. Rehg, Statistical Color Models with Application to Skin Detection, IJCV 2002.",
    "offset": "page87",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection",
    "offset": "page88",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nhttp://www.ghvandoorn.nl/skindetection.html",
    "offset": "page89",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nOpenCV\nhttps://www.youtube.com/watch?v=vZk9k9azonw",
    "offset": "page90",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based tracking\nD. Ramanan, D. Forsyth, and A. Zisserman. Tracking People by Learning their Appearance. PAMI 2007.\nSlide credit: L. Lazebnik",
    "offset": "page91",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based tracking\nhttp://www.roborealm.com/tutorial/color_obj ect_tracking_2/slide010.php\nhttps://www.youtube.com/watch?v=WPnWD Gl3XZc",
    "offset": "page92",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Viewing Colored Objects",
    "offset": "page93",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\nTrevor Darrell • Kristen Grauman: 3-48, 50-75, 79-86 • Bob Woodham: 49, 87-90 • and others, indirectly (Steve Palmer, Brian Wandell, etc!)",
    "offset": "page94",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page95",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nFinding lines – part 2\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  (Generalized) Hough transform application  RANSAC\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting a parametric model to data\n# parameters 2 parametric equation\ny = mx + b\n3 r2 = (x-x0)2 + (y-y0)2\nparameters m, b\nr, x0, y0\nImage credit Zhaozheng Yin @ wisc.edu\nImage credit Yuan-Liang Tang on Mathworks\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting a parametric model to data\n Design questions:\n What is a good model to represent our data?  Do we plan to fit multiple instances?\n Challenges:\n Which features belong to the model? To which instance?  How many instances are there?  Computational complexity (typically we cannot examine all\npossible models).\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\ndetection of power lines in helicopter navigation systems\nImage credit: Horev et al. SIAM’15\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\nlane detection from car cameras in crashpreventing systems\n6\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\ndetection of long filaments in high-throughput biological imaging\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\nSports\n8\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\n“Interactive 3D Architectural Modeling from Unordered Photo Collections” Sinha et al. 2008\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Challenges of line fitting\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Challenges of line fitting\n Which points on which line?  Noisy edge detection:\n Clutter  Missed parts  Points are only approximately\nalong the line\n Large search space.  How many lines are there?\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Voting\n Problem:\n We cannot try all possible models\n Solution by voting:\n Features (points) vote for models they are compatible with  Search for models with lots of votes\nfeature space\nmodel space\n2\nVoting\nr e e m a r a p\nt\nl\ne d o M\nModel parameter 1\n12\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\n\n14\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\n\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\n\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Finding lines with the Hough transform\n Discretize Hough space  Each edge point votes for all possible parameters in Hough\nspace\n Parameters with lots of votes indicate lines in image space\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Polar representation for lines\n\nd\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough-transform algorithm\n\n19\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example\nFor a given point (x0,y0)\nd(q)=x0cosq+y0sinq\ny\nd\nx\n20\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "Example\nFor a given point (x0,y0)\nd(q)=x0cosq+y0sinq\ny\nd\nx\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: an image with straight lines\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Properties\n Noise and clutter votes are inconsistent, so will not\naccumulate.\n Can handle occlusions if not all points are present as long as\nmodel gets enough votes.\n Efficient.\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: a real image\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: a real image\n25\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Impact of noise on Hough transform\n What difficulties does noise introduce?\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Impact of noise on Hough transform\n Here everything is “noise” but we still see peaks in the\nvote space\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Voting: Practical tips\n Use only trustworthy points\n E.g., edges points with significant gradient magnitude\n(alternatively weight votes)\n Szeliski suggests using edgels instead of points\n Choose a good quantization grid\n Not too coarse – too many lines fall in the same bucket  Not too fine – collinear points vote for different lines\n Smooth the voting (vote also for neighbors)  Non-maxima suppression  Refit line using accumulated votes  Reduce number of parameters, if possible\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hough transform summary\n Pros\n Can handle occlusions  Some robustness to noise  Can detect multiple lines in a single pass over the image\n Cons\n Clutter can produce spurious peaks in parameter space  Hard to select the right quantization\n29\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Generalized Hough Transform\n Can be extended to other parametric models such as:\ncircles, ellipses, rectangles etc.\n Complexity increases exponentially with the number of\nparameters.\n Can be used to detect complex non-parametric models as\ndescribed in Leibe et al. “Combined object categorization and segmentation with an implicit shape model”.\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANdom SAmple Consensus [Fischler & Bolles 1981]\n Key ideas:\n Look for “inliers” and use only them  If we fit a model to “outliers” we will not get a good fitting\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC algorithm\nLoop: 1.Randomly select a group of points 2.Fit a model to the selected group 3.Find the inliers of the computed model 4.If number of inliers is large enough re-compute model using only inliers 5.Compute number of inliers of updated model The winner: model with the largest number of inlier\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Input:\nA set of edge points\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 1:\nSelect two points\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 2:\nFit a line to the selected points\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 3:\nIdentify inliers\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 4:\nFit line to inliers\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 5:\nCount number of new inliers\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC – stopping criteria\n\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC – for multiple models?\n How can we use RANSAC to compute multiple models?\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC - summary\n Pros\n General method that works well for lots of model fitting\nproblems\n Easy to implement\n Cons\n When the percentage of outliers is high too many iterations\nare needed and failure rate increases\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "43\nEnd – finding lines\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nImage segmentation\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today’s class\n Segmentation and grouping\n Gestalt cues  By clustering (mean-shift)  By boundaries (watershed)\n Superpixels and multiple segmentations",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gestalt psychology or gestaltism  German: Gestalt - \"form\" or \"whole”\n Berlin School, early 20th century  Kurt Koffka, Max Wertheimer, and Wolfgang Köhler\n View of brain: • whole is more than the sum of its parts • holistic • parallel • analog •\nself-organizing tendencies\nSlide from S. Saverese",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gestaltism\nThe Muller-Lyer illusion",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "We perceive the interpretation, not the senses",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Principles of perceptual organization\nFrom Steve Lehar: The Constructive Aspect of Visual Perception",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Principles of perceptual organization",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gestaltists do not believe in coincidence",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Emergence",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "nl"
  },
  {
    "filetype": "application/pdf",
    "text": "Grouping by invisible completion\nFrom Steve Lehar: The Constructive Aspect of Visual Perception",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Grouping involves global interpretation\nFrom Steve Lehar: The Constructive Aspect of Visual Perception",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Grouping involves global interpretation\nFrom Steve Lehar: The Constructive Aspect of Visual Perception",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gestalt cues\n Good intuition and basic principles for grouping\n Basis for many ideas in segmentation and occlusion\nreasoning\n Some (e.g., symmetry) are difficult to implement in\npractice",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image segmentation\nGoal: Group pixels into meaningful or perceptually similar regions",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation for efficiency: “superpixels”\n[Felzenszwalb and Huttenlocher 2004]\n[Hoiem et al. 2005, Mori 2005]",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation for feature support\n50x50 Patch\n50x50 Patch",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation for object proposals\n“Selective Search” [Sande, Uijlings et al. ICCV 2011, IJCV 2013]\n[Endres & Hoiem ECCV 2010, IJCV 2014]",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation for image editing\nRother et al. 2004",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Major processes for segmentation\n Bottom-up: group tokens with similar features  Top-down: group tokens that likely belong to the same\nobject\n[Levin and Weiss 2006]",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation using clustering\n Kmeans\n Mean-shift",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Feature Space\nSource: K. Grauman",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "K-means clustering using intensity alone and color alone\nInput image\nClusters on intensity\nClusters on color",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "K-Means pros and cons\nPros\n– Simple and fast – Easy to implement\nCons\n– Need to choose K – Sensitive to outliers\nUsage\n– Rarely used for pixel segmentation",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift segmentation\n D. Comaniciu and P. Meer, Mean Shift: A Robust Approach toward Feature\nSpace Analysis, PAMI 2002.\n Versatile technique for clustering-based segmentation",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift algorithm\n\nTry to find modes of this non-parametric density",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Kernel density estimation\nKernel\nEstimated density\nData (1-D)",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Kernel density estimation\nKernel density estimation function\nGaussian kernel",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift\nSlide by Y. Ukrainitz & B. Sarel\nRegion of interest\nCenter of mass\nMean Shift vector",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift\nSlide by Y. Ukrainitz & B. Sarel\nRegion of interest\nCenter of mass\nMean Shift vector",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift\nSlide by Y. Ukrainitz & B. Sarel\nRegion of interest\nCenter of mass\nMean Shift vector",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift\nSlide by Y. Ukrainitz & B. Sarel\nRegion of interest\nCenter of mass\nMean Shift vector",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift\nSlide by Y. Ukrainitz & B. Sarel\nRegion of interest\nCenter of mass\nMean Shift vector",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift\nSlide by Y. Ukrainitz & B. Sarel\nRegion of interest\nCenter of mass\nMean Shift vector",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift\nSlide by Y. Ukrainitz & B. Sarel\nRegion of interest\nCenter of mass",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing the Mean Shift\nSimple Mean Shift procedure: • Compute mean shift vector\nTranslate the Kernel window by m(x)\n2121()niiiniighghx-xxmxxx-x\nSlide by Y. Ukrainitz & B. Sarel",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Real Modality Analysis",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Attraction basin\n Attraction basin: the region for which all trajectories\nlead to the same mode\n Cluster: all data points in the attraction basin of a\nmode\nSlide by Y. Ukrainitz & B. Sarel",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Attraction basin",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift clustering\n\nThe mean shift algorithm seeks modes of the given set of points 1. Choose kernel and bandwidth\n2.\nFor each point: a) Center a window on that point b) Compute the mean of the data in the search window c) Center the search window at the new mean location d) Repeat (b,c) until convergence\n3. Assign points that lead to nearby modes to the same cluster",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift segmentation results\nhttp://www.caip.rutgers.edu/~comanici/MSPAMI/msPamiResults.html",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "http://www.caip.rutgers.edu/~comanici/MSPAMI/msPamiResults.html",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "unknown"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean-shift: other issues • Speedups\n– Binned estimation – replace points within some “bin” by point\nat center with mass\n– Fast search of neighbors – e.g., k-d tree or approximate NN – Update all windows in each iteration (faster convergence)\nOther tricks\n– Use kNN to determine window sizes adaptively\nLots of theoretical support\nD. Comaniciu and P. Meer, Mean Shift: A Robust Approach toward Feature Space Analysis, PAMI 2002.",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean shift pros and cons  Pros\n Good general-purpose segmentation  Flexible in number and shape of regions  Robust to outliers  General mode-finding algorithm (useful for other problems such as\nfinding most common surface normals)\n Cons\n Have to choose kernel size in advance  Not suitable for high-dimensional features\n When to use it\n Oversegmentation  Multiple segmentations  Tracking, clustering, filtering applications\n D. Comaniciu, V. Ramesh, P. Meer: Real-Time Tracking of Non-Rigid Objects using Mean\nShift, Best Paper Award, IEEE Conf. Computer Vision and Pattern Recognition (CVPR'00), Hilton Head Island, South Carolina, Vol. 2, 142-149, 2000",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean-shift reading\nNicely written mean-shift explanation (with math) http://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift- algorithm/\nIncludes .m code for mean-shift clustering\nMean-shift paper by Comaniciu and Meer http://www.caip.rutgers.edu/~comanici/Papers/MsRobustApproach.pdf\nAdaptive mean shift in higher dimensions http://mis.hevra.haifa.ac.il/~ishimshoni/papers/chap9.pdf",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Superpixel algorithms\n Goal is to divide the image into a large number of regions,\nsuch that each regions lie within object boundaries\n Examples\n Watershed  Felzenszwalb and Huttenlocher graph-based  Turbopixels  SLIC",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Watershed algorithm",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Watershed segmentation\nImage\nGradient\nWatershed boundaries",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Meyer’s watershed segmentation\n1. Choose local minima as region seeds 2. Add neighbors to priority queue, sorted by value 3. Take top priority pixel from queue If all labeled neighbors have same label, assign that label to pixel\n2. Add all non-marked neighbors to queue\n4. Repeat step 3 until finished (all remaining pixels in queue are on the boundary)\nMatlab: seg = watershed(bnd_im)\nMeyer 1991",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Simple trick\n Use Gaussian or median filter to reduce number of\nregions",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Watershed usage\nUse as a starting point for hierarchical segmentation\n– Ultrametric contour map (Arbelaez 2006)\nWorks with any soft boundaries – Pb (w/o non-max suppression) – Canny (w/o non-max suppression) – Etc.",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Watershed pros and cons\nPros\n– Fast (< 1 sec for 512x512 image) – Preserves boundaries\nCons\n– Only as good as the soft boundaries (which may be slow to\ncompute)\n– Not easy to get variety of regions for multiple segmentations\nUsage\n– Good algorithm for superpixels, hierarchical segmentation",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Felzenszwalb and Huttenlocher: Graph- Based Segmentation\nhttp://www.cs.brown.edu/~pff/segment/",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Felzenszwalb and Huttenlocher: Graph- Based Segmentation\nhttp://www.cs.brown.edu/~pff/segment/\n+ Good for thin regions + Fast + Easy to control coarseness of segmentations + Can include both large and small regions - Often creates regions with strange shapes - Sometimes makes very large errors",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "SLIC (Achanta et al. PAMI 2012)\nhttp://infoscience.epfl.ch/record/177415/files/Superpixel_PAMI2011-2.pdf\nInitialize cluster centers on pixel grid in steps S - Features: Lab color, x-y position 2. Move centers to position in 3x3 window with smallest gradient\n1.\n3. Compare each pixel to cluster center within 2S pixel distance and assign to nearest\n4. Recompute cluster centers as mean color/position of pixels belonging to each cluster Stop when residual error is small 5.\n+ Fast 0.36s for 320x240 + Regular superpixels + Superpixels fit boundaries - May miss thin objects - Large number of superpixels",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Choices in segmentation algorithms  Oversegmentation\n Watershed + Pb  my favorite  Felzenszwalb and Huttenlocher 2004  pretty good\nhttp://www.cs.brown.edu/~pff/segment/\n SLIC  also a good option  Turbopixels  Mean-shift\n Larger regions\n Hierarchical segmentation (e.g., from Pb)  Normalized cuts  Mean-shift  Seed + graph cuts (discussed later)",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Multiple segmentations  When creating regions for pixel classification or object detection, don’t commit to one partitioning\n Strategies:\n Hierarchical segmentation\n Occlusion boundaries hierarchy: Hoiem et al. IJCV 2011 (uses trained classifier to\nmerge)\n Pb+watershed hierarchy: Arbeleaz et al. CVPR 2009  Selective search: FH + agglomerative clustering\n Vary segmentation parameters\n E.g., multiple graph-based segmentations or mean-shift segmentations\n Region proposals\n Propose seed superpixel, try to segment out object that contains it (Endres\nHoiem ECCV 2010, Carreira Sminchisescu CVPR 2010)",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Things to remember • Gestalt cues and principles of organization\nUses of segmentation\n– Efficiency – Better features – Propose object regions – Want the segmented object\nMean-shift segmentation\n– Good general-purpose segmentation method – Generally useful clustering, tracking technique\nWatershed segmentation\n– Good for hierarchical segmentation – Use in combination with boundary prediction",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credits\n Slides borrowed from Derek Hoiem\n61\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "62\nEnd – segmentation part 1\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/07-Segmentation_part1-KMeans-Mean_shift-Watershed-Graph-Based-SLIC.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nFinding lines – part 1\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why edges?\n We know edges are special\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge detection - goal\n Goal:\nMap image from 2d array of pixels to a set of curves or line segments or contours.  Most semantic and shape information from the image can be\nencoded in the edges\n A more compact representation than a complete image\n Ideal:\nArtist’s Line drawing (but artists use prior knowledge)\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What can cause an edge?\nSurface normal discontinuity\nDepth discontinuity\nIllumination discontinuity\nSurface color discontinuity\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What can cause an edge?\nReflectance change: appearance information, texture\nChange in surface orientation: shape\n6\nLihi Zelnik-Manor, Computer Vision\nDepth discontinuity: object boundary\nCast shadows",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contrast and invariance\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edges look like steep cliffs\n8\nLihi Zelnik-Manor, Computer Vision\nSource: S. Seitz",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivatives and edges\n An edge is a place of rapid change in the image intensity\nfunction.\nimage\nintensity function (along horizontal scanline)\nfirst derivative\nedges correspond to extrema of derivative\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image gradient\nThe gradient of an image:\nThe gradient points in the direction of most rapid change in intensity\nThe gradient direction (orientation of edge normal) is given by:\nThe edge strength is given by the gradient magnitude\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Differentiation and convolution\nFor 2D function, f(x,y), the partial derivative is:\n),(),(lim),(0yxfyxfxyxf\nFor discrete data, we can approximate using finite differences:\n(,)(1,)(,)fxyfxyfxyxx\nTo implement above as convolution, what would be the associated filter?\n1 1\n12\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Assorted finite difference filters\n>> My = fspecial(‘sobel’); >> outim = imfilter(double(im), My); >> imagesc(outim); >> colormap gray;\n13\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Partial derivatives of an image\nxyxf),(\nWhich shows changes with respect to x? y?\n14\nLihi Zelnik-Manor, Computer Vision\nyyxf),(",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Intensity profile of one row\nIntensity\nGradient\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\nConsider a single row or column of the image\n Plotting intensity as a function of position gives a signal\nWhere is the edge?\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\n Finite difference filters respond strongly to noise\n Image noise results in pixels that look very different from\ntheir neighbors\n Generally, the larger the noise the stronger the response\n What can be done?\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\n Finite difference filters respond strongly to noise\n Image noise results in pixels that look very different from\ntheir neighbors\n Generally, the larger the noise the stronger the response\n What can be done?\n Smoothing the image should help – it forces pixels to look\nmore like their neighbors\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Solution: smooth first\nf\ng\nfg\ndfgdx\nWhere is the edge?\nLook for peaks in\n19\nLihi Zelnik-Manor, Computer Vision\ndfgdx",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative theorem of convolution\nDifferentiation property of convolution:\nf\ndgdx\ndfgdx\n20\nLihi Zelnik-Manor, Computer Vision\n\nddfgfgdxdx",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative of Gaussian filter\n11\nIs this a separable filter?\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative of Gaussian filters\nx-direction\ny-direction\nWhich one finds horizontal/vertical edges?\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smoothing tradeoffs\n1 pixel\n3 pixels\n7 pixels\nSmoothed derivative removes noise, but blurs edge. Also finds edges at different “scales”.\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Laplacian of Gaussian (LoG filter)\nf\n22dgdx\n22dfgdx\nWhere is the edge? Zero-crossings of bottom graph\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "2D edge detection filters\nGaussian\nderivative of Gaussian\ng\ndgdx\n25\nLihi Zelnik-Manor, Computer Vision\nLaplacian of Gaussian\n2222dgdgdxdy",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "DoG = Difference of Gaussians\n Can approximate Laplacian filter\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is a good edge detector?  Good detection:\n Minimize false positives (wrong detections)\n Minimize false negatives (missing real edges)\n Maximize true detections\n Good localization:\n Detected edges should be as close as possible to the\ntrue edges\n Single response:\n Return a single detection for each true edge point\n Connect detections to lines\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is a good edge detector?  Good detection\n Good localization\n Single response\nWhich of these detections is the best?\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What are the parameters?\n Scale  Threshold\n29\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scale selection\n Recall: We first smooth the image with a Gaussian\nkernel to reduce noise.\n The scale of the Gaussian determines how much\nsmoothing we apply\n…\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effect of σ on derivatives\n The apparent structures differ depending on Gaussian’s\nscale parameter.\n Large scale: larger scale edges detected  Small scale: finer features detected\nσ = 1 pixel\nσ = 3 pixels\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "How do we chose the scale?  It depends what we’re looking for:\n Too fine of a scale…can’t see the forest for the trees.  Too coarse of a scale…can’t tell the maple grain from the\ncherry.\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What are the parameters?\n Scale  Threshold\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Thresholding\n Choose a threshold value  Set any pixels less than thresh to zero (off)  Set any pixels greater than or equal to thresh to one (on)\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original image\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Gradient magnitude\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Using a low threshold\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Using a higher threshold\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Canny edge detector\n Probably the most widely used edge detector in computer\nvision\n Key idea:\ndetect step-edges that are corrupted by additive Gaussian noise\n Theorem:\nCanny has shown that the first derivative of the Gaussian closely approximates the operator that optimizes the product of signal-to-noise ratio and localization\nJ. Canny, A Computational Approach To Edge Detection, IEEE Trans. Pattern Analysis and Machine Intelligence, 8:679--‐714, 1986.\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Canny edge detector\n\n\n\n\nFilter image with derivative of Gaussian Find magnitude and orientation of gradient Non-maximum suppression: (Localization)  Thin multi-pixel wide “ridges” down to single pixel width Linking and thresholding (hysteresis): (Linking)  Define two thresholds: low and high  Use the high threshold to start edge curves and the low\nthreshold to continue them\n\nMATLAB: edge(image, ‘canny’);\n\n>>help edge\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example - input\noriginal image (Lena)\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 1\nnorm of the gradient\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 2\nthresholding\n43\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 3\nthresholding\n44\nLihi Zelnik-Manor, Computer Vision\nHow to turn these thick regions of the gradient into curves?",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Non-maximum suppression\nCheck if pixel q is local maximum along gradient direction,\nselect single max across width of the edge  requires checking interpolated pixels p and r\n45\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 3\nThinning (non-maximum supression)\n46\nLihi Zelnik-Manor, Computer Vision\nProblem: pixels along this edge didn’t survive the thresholding",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge linking\n Assume the marked point is an edge point.  Then we construct the tangent to the edge curve (which is normal to the gradient at that point) and use this to predict the next points (here either r or s).\n47\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\n Check that maximum value of gradient value is\nsufficiently large  drop-outs? use hysteresis\n use a high threshold to start edge curves and a low threshold to\ncontinue them.\n48\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\noriginal image\nhigh threshold (strong edges)\nlow threshold (weak edges)\n49\nLihi Zelnik-Manor, Computer Vision\nhysteresis threshold",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nhigh threshold (strong edges)\n50\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nlow threshold (weak edges)\n51\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nhysteresis threshold\n52\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Canny - results\n53\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Object boundaries vs. edges\nBackground 54\nTexture\nLihi Zelnik-Manor, Computer Vision\nShadows",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n55\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "At Berkeley:\n1. Collect Data Set of Human segmented images\n2.\nLearn Local Boundary Model for combining brightness, color and texture\n3. Global framework to capture closure, continuity 4. Detect and localize junctions Integrate low, mid and high-level information for grouping and figure-ground segmentation\nD. Martin, C. Fowlkes, D. Tal, J. Malik. \"A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics\", ICCV, 2001\nhtpp://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/\n56\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Berkeley Segmentation DataSet [BSDS]\nInput\nHuman segmentation\n57\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~1970\n58\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~1990\n59\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~2004\n60\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~2008\nInclude global cues\n61\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Martin, Fowlkes, Malik PAMI 04\nGradient\nCue Combination\nBrightness\nColor\nModel\nTexture\n Goal: learn the posterior probability of a boundary\nPb(x,y,) from local information only\n Challenges:\n computing the cues,  cue combination\n62\nLihi Zelnik-Manor, Computer Vision\nPb",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: gradient cue\nImage\nOE = Oriented Energy\n63\nLihi Zelnik-Manor, Computer Vision\n+",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: brightness and color cues\nImage\nBG = Brightness Gradient\nCG = Color Gradient\n64\nLihi Zelnik-Manor, Computer Vision\nDifference of L* distributions\nBG = χ2(h1(L),h2(L))\nDifference of a* distributions\nCG = χ2(h1(a),h2(a))+ χ2(h1(b),h2(b))",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: texture cue\nImage\nTG = Texture Gradient\n65\nLihi Zelnik-Manor, Computer Vision\nDifference of filter distributions\nTG= 𝑓 χ2(h1(f),h2(f))",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: cue design\nImage\n66\nLihi Zelnik-Manor, Computer Vision\nMultiple orientations\nMultiple disk radii",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Filter banks\norientations\nscales\n“Edges”\n“Bars”\n“Spots”\n What filters to put in the bank?\n Typically we want a combination of scales and\norientations, different types of patterns.\nMatlab code available for these examples: http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html\n67\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page67",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Filter bank\n68\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page68",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "g p\nj .\n2 p a c n\ni t s u a m o c . r e r o p x e s a x e\n/\nl\nt .\nw w w\n/ / :\np\nt t\nh m o r f\ne g a m\nI\n69\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page69",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "70\nShowing magnitude of responses\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page70",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "71\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page71",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "72\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page72",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "73\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page73",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "74\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page74",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "75\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page75",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "76\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page76",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "77\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page77",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "78\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page78",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "79\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page79",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "80\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page80",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "81\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page81",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "82\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page82",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "83\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page83",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "84\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page84",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "85\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page85",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "86\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page86",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "87\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page87",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "88\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page88",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n2\n3\nYou try: Can you match the texture to the response?\nFilters\nA\nB\nC\nMean abs responses\n89\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page89",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n2\n3\nYou try: Can you match the texture to the response?\nFilters\nA\nB\nC\nMean abs responses\n90\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page90",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "91\nLihi Zelnik-Manor, Computer Vision\n[r1, r2, …, r38]\nWe can form a feature vector from the list of responses at each pixel.",
    "offset": "page91",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Martin, Fowlkes, Malik PAMI 04\nGradient OE\nCue Combination\nBrightness BG\nColor CG\nModel\nTexture TG\n Goal: learn the posterior probability of a boundary\nPb(x,y,) from local information only\n Challenges:\n computing the cues,  cue combination\n92\nLihi Zelnik-Manor, Computer Vision\nPb",
    "offset": "page92",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "93\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page93",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "94\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page94",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Parameter tuning (cue optimization)\n Scale  Disk radius  Number of bins in histogram\nTrained on labeled data\n95\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page95",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Cue combination\n Tested many options:\n Logistic regression – the winner!  SVM (support vector machines)  Hierarchical Mixture of Experts  Classification trees\n96\nLihi Zelnik-Manor, Computer Vision\nThe logistic function",
    "offset": "page96",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Various cue combinations\n97\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page97",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example results\n98\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page98",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forty years of contour detection\nRoberts (1965)\nSobel (1968)\nPrewitt (1970)\nMarr Hildreth (1980)\nCanny (1986)\nPerona Malik (1990)\n99\nLihi Zelnik-Manor, Computer Vision\nMartin Fowlkes Malik (2004)\nMaire Arbelaez Fowlkes Malik (2008)\n99",
    "offset": "page99",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Global pB boundary detector\nFigure from Fowlkes",
    "offset": "page100",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests (Dollar Zitnick ICCV 2013)\n Goal: quickly predict whether each pixel is an\nedge\n Insights\n Predictions can be learned from training data  Predictions for nearby pixels should not be\nindependent\n Solution\n Train structured random forests to split data into\npatches with similar boundaries based on features\n Predict boundaries at patch level, rather than pixel level, and aggregate (average votes)\nhttp://research.microsoft.com/pubs/202540/DollarICCV13edges.pdf\nBoundaries in patch",
    "offset": "page101",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests\n Algorithm\n1. Extract overlapping 32x32 patches at three scales\n2.\nFeatures are pixel values and pairwise differences in feature maps (LUV color, gradient magnitude, oriented gradient)\n3. Predict 𝑇 boundary maps in the central 16x16 region using 𝑇 trained decision trees\n4. Average predictions for each pixel across all patches",
    "offset": "page102",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests Results\nBSDS 500\nNYU Depth dataset edges",
    "offset": "page103",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests\nGround truth\nResults (multiscale)",
    "offset": "page104",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forty years of contour detection\nRoberts (1965)\nSobel (1968)\nPrewitt (1970)\nMarr Hildreth (1980)\nCanny (1986)\nPerona Malik (1990)\n105\nLihi Zelnik-Manor, Computer Vision\nMartin Fowlkes Malik (2004)\nMaire Arbelaez Fowlkes Malik (2008)\nDollar Zitnick (2013)",
    "offset": "page105",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Crisp Boundary Detection using Pointwise Mutual Information (Isola et al. ECCV 2014)\nPixel color combinations that are unlikely to be together are edges\nAlgorithm:\nKernel density estimation\nSpectral clustering\nhttp://web.mit.edu/phillipi/www/publications/crisp_boundaries.pdf",
    "offset": "page106",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Crisp Boundary Detection using Pointwise Mutual Information",
    "offset": "page107",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\n Trevor Darell  Kristen Grauman  Jitendra Malik  FeiFei Li  Derek Hoiem  and Seitz, Marschner, Lazebnik and others\n108\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page108",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "109\nEnd – finding lines\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page109",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nFrom points to regions\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local invariant features\n Motivation  Requirements, invariances\n Keypoint localization\n Harris corner detector  Hessian detector\n Scale invariant region selection\n Automatic scale selection  Laplacian-of-Gaussian detector  Difference-of-Gaussian detector\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris Detector: Properties\n Is it invariant to image scale?\nAll points will be classified as edges\nNo: Not invariant to image scale!\n3\nLihi Zelnik-Manor, Computer Vision\nCorner !",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "From points to regions\n The Harris and Hessian operators define interest points\n Precise localization  High repeatability\n In order to compare (and match) those points, we need\nto compute a descriptor over their local region  How can we define such a region in a scale invariant manner?  How can we detect scale invariant interest region?\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Naïve approach: Exhaustive search\n Multi-scale procedure\n Compare descriptors while varying patch size\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Naïve approach: Exhaustive search\n Multi-scale procedure\n Compare descriptors while varying patch size\n6\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Naïve approach: Exhaustive search\n Multi-scale procedure\n Compare descriptors while varying patch size\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Naïve approach: Exhaustive search\n Multi-scale procedure\n Compare descriptors while varying patch size\n=\n8\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Naïve approach: Exhaustive search\n Compare descriptors while varying patch size\n Computationally inefficient  Prohibitive for retrieval in large databases  Prohibitive for recognition\n=\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic scale selection\n Solution:\n Design a function on the region, which is “scale invariant” (the same for\ncorresponding regions, even if they are at different scales)\nExample: average intensity. For corresponding regions (even of different sizes) it will be the same.  For a point in one image, we can consider it as a function of region size\n(patch width)\nf\nImage 1\nf\nscale = 1/2\nregion size\n10\nLihi Zelnik-Manor, Computer Vision\nImage 2\nregion size",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "f\nAutomatic scale selection\n Common approach:\n Take a local maximum of this function  Observation: region size, for which the maximum is achieved, should be\ninvariant to image scale.\nImportant: this scale invariant region size is found in each image independently!\nImage 1\nf\nscale = 1/2\ns1\nregion size\ns2\n11\nLihi Zelnik-Manor, Computer Vision\nImage 2\nregion size",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic Scale Selection\n Function responses for increasing scale (scale signature)\n13\n)),((1xIfmii\nLihi Zelnik-Manor, Computer Vision\n)),((1xIfmii",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic Scale Selection\n Function responses for increasing scale (scale signature)\n14\n)),((1xIfmii\nLihi Zelnik-Manor, Computer Vision\n)),((1xIfmii",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic Scale Selection\n Function responses for increasing scale (scale signature)\n15\n)),((1xIfmii\nLihi Zelnik-Manor, Computer Vision\n)),((1xIfmii",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic Scale Selection\n Function responses for increasing scale (scale signature)\n16\n)),((1xIfmii\nLihi Zelnik-Manor, Computer Vision\n)),((1xIfmii",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic Scale Selection\n Function responses for increasing scale (scale signature)\n17\n)),((1xIfmii\nLihi Zelnik-Manor, Computer Vision\n)),((1xIfmii",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic Scale Selection\n Function responses for increasing scale (scale signature)\n18\n)),((1xIfmii\nLihi Zelnik-Manor, Computer Vision\n)),((1xIfmii",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Automatic Scale Selection\n Normalize: rescale selected regions to a fixed size\n)),((1xIfmii\n)),((1xIfmii\n19\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "A useful scale “signature” function\n Laplacian-of-Gaussian = “blob” detector\n20\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris – Laplace [Mikolajczyk’01]\n1. Keypoint detection:\n Multi-scale Harris corner detection\n2. Scale selection\n Scale selection based on Laplacian signature\nHarris points\nHarris-Laplace points\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris – Laplace [Mikolajczyk’01]\n1. Keypoint detection:\n Multi-scale Harris corner detection\n2. Scale selection\n Scale selection based on Laplacian signature\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Harris – Laplace [Mikolajczyk’01]\n1. Keypoint detection:\n Multi-scale Harris corner detection\n2. Scale selection\n Scale selection based on Laplacian signature\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local invariant features\n Motivation  Requirements, invariances\n Keypoint localization\n Harris corner detector  Hessian detector\n Scale invariant region selection\n Automatic scale selection  Laplacian-of-Gaussian detector  Difference-of-Gaussian detector\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Characteristic scale\n We define the characteristic scale as the scale that\nproduces peak of Laplacian response\ncharacteristic scale\nT. Lindeberg (1998). \"Feature detection with automatic scale selection.\" International Journal of Computer Vision 30 (2): pp 77--116.\n25\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Laplacian-of-Gaussian (LoG)\n Interest points:\n5\nLocal maxima in scale space of Laplacian-of- Gaussian\n4\n)()(yyxxLL\n3\n2\n\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Laplacian-of-Gaussian (LoG)\n Interest points:\n5\nLocal maxima in scale space of Laplacian-of- Gaussian\n4\n)()(yyxxLL\n3\n2\n\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Laplacian-of-Gaussian (LoG)\n Interest points:\n5\nLocal maxima in scale space of Laplacian-of- Gaussian\n4\n)()(yyxxLL\n3\n2\n\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Laplacian-of-Gaussian (LoG)\n Interest points:\n5\nLocal maxima in scale space of Laplacian-of- Gaussian\n4\n)()(yyxxLL\n3\n2\n\n29\nLihi Zelnik-Manor, Computer Vision\n List of (x, y, σ)",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "LoG detector: workflow\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "LoG detector: workflow\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "LoG detector: example result\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "ro"
  },
  {
    "filetype": "application/pdf",
    "text": "LoG technical details\n We can efficiently approximate the Laplacian with a\ndifference of Gaussians:  Laplacian:\n2(,,)(,)xxyyLGxyGxy\n DoG = Difference of Gaussians:\n(,,)(,)DoGGxykGxyL\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Local invariant features\n Motivation  Requirements, invariances\n Keypoint localization\n Harris corner detector  Hessian detector\n Scale invariant region selection\n Automatic scale selection  Laplacian-of-Gaussian detector  Difference-of-Gaussian detector\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Key point localization with DoG\nDetect maxima of difference-of- Gaussian (DoG) in scale space\nThen reject points with low contrast (threshold)\nEliminate edge responses Subtract\nEliminate edge responses Subtract\nCandidate keypoints: list of (x,y,σ)\n35",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "DoG – efficient computation\n Computation in Gaussian scale pyramid\nSampling with step 𝜎4 = 2\nOriginal image\n36\nLihi Zelnik-Manor, Computer Vision\n[Lowe 2004]",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "DoG – example result\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "DoG – example result\n38\nLihi Zelnik-Manor, Computer Vision\n(a)\n233x189 image\n(b) 832 DOG extrema\n(c) 729 left after peak value threshold\n(d) 536 left after testing ratio of principle curvatures (removing\nedge responses)",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scale Invariant Detection: Summary  Given: two images of the same scene with a large scale\ndifference between them\n Goal: find the same interest points independently in each image\n Solution: search for maxima of suitable functions in scale and in\nspace (over the image) 1. 2. Difference of Gaussians (DoG) – fast approximation of LoG 3. Harris + Laplace 4. Hessian + Laplace\nLaplacian of Gaussian (LoG)\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Invariant regions\n So far our regions are:\n Translation invariant (since they are centered at keypoints)  Scale-invariant\n What about:  Orientation?\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Rotation invariant regions\n Find local orientation  Compute a weighted histogram of gradient directions\n Find the dominant direction\n Normalize orientation\n Rotate patch according to\nthis angle\n This puts the patches into a\ncanonical orientation.\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Invariant regions\n So far our regions are:\n Translation invariant (since they are centered at keypoints)  Scale-invariant  Rotation-invariant\n What about:\n Other transformations?\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine invariant regions\n Above we considered:\nSimilarity transform (rotation + uniform scale)\n Now we go on to:\nAffine transform (rotation + non-uniform scale)\n43\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine adaption\n Problem\n Determine the characteristic shape of the region\n Assumption\n Shape can be described by a “local affine frame”\n Solution\n Use a circular window to compute the second-moment matrix  Compute eigenvectors to adapt the circle to an ellipse  Re-compute second-moment matrix using the new window  Iterate…\n44\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Iterative affine adaptation\n1. Detect keypoint (e.g., multi-scale Harris) 2. Automatically select the scales (e.g., Laplace signature) 3. Adapt affine shape based on second order moment matrix 4. Refine point location\n45\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine normalization (deskewing)\n Steps:\n Rotate the ellipse’s main axis to horizontal  Scale the x axis, such that it forms a circle\nrotate\nrescale\n46\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine adaptation example\nScale-invariant regions\n47\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine adaptation example\nAffine-adapted regions\n48\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine invariant regions example\n49\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Affine invariant regions - summary\n50\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "51\nEnd – From points to regions\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/10-points-to-regions.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nImage segmentation – part 2\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Graph theoretic segmentation\n Normalized cuts\n Segmentation as energy minimization\n Markov random fields\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Images as graphs\n Node for every pixel  Edge between every pair of pixels (or every pair of\n“sufficiently close” pixels)\n Each edge is weighted by the affinity or similarity of the\ntwo nodes\nj\nwij\ni\n3\nLihi Zelnik-Manor, Computer Vision\nSource: S. Seitz",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation by graph partitioning\n Break Graph into Segments\n Delete links that cross between segments  Easiest to break links that have low affinity  similar pixels should be in the same segments  dissimilar pixels should be in different segments\nwij i\nA\nB\nC\n4\nLihi Zelnik-Manor, Computer Vision\nj\nSource: S. Seitz",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Measuring affinity\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scale affects affinity\n Small σ: group only nearby points  Large σ: group far-away points\n6\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Graph cut\n Set of edges whose removal makes a graph disconnected\n Cost of a cut: sum of weights of cut edges\n A graph cut gives us a segmentation\n What is a “good” graph cut and how do we find one?\nA\nB\n7\nLihi Zelnik-Manor, Computer Vision\nSource: S. Seitz",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Minimum cut\nWe can segment by finding the minimum cut in a graph\n\nEfficient algorithms exist for doing this\nMinimum cut example\n8\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Minimum cut\nWe can segment by finding the minimum cut in a graph\n\nEfficient algorithms exist for doing this\nMinimum cut example\nThe cut is defined by the block diagonal structure of the affinity matrix. • Can this be generalized?\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Minimum cut drawback\n Minimum cut tends to cut off very small, isolated\ncomponents\nBetter Cut\n10\nLihi Zelnik-Manor, Computer Vision\nCuts with lesser weight than the ideal cut",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Normalized cut (Ncut)\n The drawback of mincut can be fixed by normalizing the\ncost by the weight of all the edges incident to the segment\n The normalized cut cost is:\n(,)(,)(,)(,)(,)cutABcutABNcutABassocAVassocBV\n(,)cutAB\n= sum of weights of all edges between A and B\n(,)assocAB\n= sum of weights of all edges in V that touch A\n,,11(,)(,)pqpqpAqBNcutABcutABww\nJ. Shi and J. Malik. Normalized cuts and image segmentation. PAMI 2000\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Ncut as a generalized eigenvector problem\nLet W be the adjacency matrix of the graph • Let D be the diagonal matrix with diagonal entries D(i, i) = Σj W(i, j)\nThen the normalized cut cost can be written as ()(,)TTyDWyNcutAByDy\nThen the normalized cut cost can be written as ()(,)TTyDWyNcutAByDy\n1()pAypnegativeotherwise\nJ. Shi and J. Malik. Normalized cuts and image segmentation. PAMI 2000\n12",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Ncut as a generalized eigenvector problem\n Problem:\nFinding the exact minimum of the normalized cut cost is NP-complete (because y is discrete)\n Solution:\n Relax y to take on arbitrary values, then solved by a generalized\neigenvalue problem\n()NDWyDy\n The solution y is given by the eigenvector corresponding to the\nsecond smallest eigenvalue\n Continuous results need to be converted into discrete\n13\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Normalized cut algorithm\n1. Construct a weighted graph G = (V,E) from an image 2. Connect each pair of pixels, and assign weights w(i,j) = prob(i,j belong to same region)\n3. Compute diagonal matrix D(i, i) = Σj W(i, j)\n4.\nSolve (D − W)y = λDy for the eigenvector with the second smallest eigenvalue\n5. Threshold eigenvector to get a discrete cut 6. Recursively partition the segmented parts, if necessary\n14\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example results\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example results\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Results: Berkeley Segmentation Engine\nhttp://www.cs.berkeley.edu/~fowlkes/BSE/\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Normalized cuts: Pros and cons\nPros  Generic framework, can be used with many different\nfeatures and affinity formulations\n No model or data distribution\nCons\n High storage requirement and time complexity\n\nBias towards partitioning into equal segments\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Eigenvectors carry contour information\n19\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Avoiding Ncut drawback\n Do not try to find regions from the eigenvectors\n20\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Avoiding Ncut drawback\n Do not try to find regions from the eigenvectors  Key idea:\n Reshape eigenvectors into images  Compute edge probability 𝑃𝑏 on eigenvector images  Final edge probability is the sum of all responses\n21\nLihi Zelnik-Manor, Computer Vision\neigenvectors\nedges",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example results\nFinal Pb\nPb\nAfter threshold continuous\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~2008 (color)\nGlobal\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Graph theoretic segmentation\n Normalized cuts\n Segmentation as energy minimization\n Markov random fields\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation as energy minimization\nP(foreground | image)\nNormalizing constant called “partition function”\nedgesjijiNiidatayyfdatayfZdataP,2..11),;,(),;(1),;(y\nLabels to be predicted\nIndividual predictions\nPairwise predictions",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Writing Likelihood as an “Energy”\nedgesjijiNiidatayypdataypZdataP,2..11),;,(),;(1),;(y\nlog\nedgesjijiiidatayydataydataEnergy,21),;,(),;(),;(y\nCost of assignment yi\nCost of pairwise assignment yi ,yj",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Notes on energy-based formulation\nedgesjijiiidatayydataydataEnergy,21),;,(),;(),;(y\n Primarily used when you only care about the most likely\nsolution (not the confidences)\n Can think of it as a general cost function\n Can have larger “cliques” than 2\n Clique is the set of variables that go into a potential function",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Markov Random Fields\nNode yi: pixel label\nEdge: constrained pairs\nCost to assign a label to each pixel\nCost to assign a pair of labels to connected pixels\nedgesjijiiidatayydataydataEnergy,21),;,(),;(),;(y",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Markov Random Fields  Example: “label smoothing” grid\nUnary potential 0: -logP(yi = 0 | data) 1: -logP(yi = 1 | data)\nPairwise Potential 0 1 0 0 K 1 K 0\nK>0\nedgesjijiiidatayydataydataEnergy,21),;,(),;(),;(y",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "id"
  },
  {
    "filetype": "application/pdf",
    "text": "Solving MRFs with graph cuts\nSource (Label 0)\nCost to assign to 1\nCost to split nodes\nCost to assign to 0\nSink (Label 1)\nedgesjijiiidatayydataydataEnergy,21),;,(),;(),;(y",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Solving MRFs with graph cuts\nSource (Label 0)\nCost to assign to 1\nCost to split nodes\nCost to assign to 0\nSink (Label 1)\nedgesjijiiidatayydataydataEnergy,21),;,(),;(),;(y",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "GrabCut segmentation\nUser provides rough indication of foreground region.\nGoal: Automatically provide a pixel-level segmentation.",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "GrabCut\n Convert MRF into source-sink graph\nSink\nSource\nPairwise potentials\nSingle-node potentials\n Minimun cost can be computed in polynomial time\n[Kwatra et al., SIGGRAPH 2003]\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Graph cuts\nBoykov and Jolly (2001)\nImage\nForeground (source)\nBackground (sink)\nCut: separating source and sink; Energy: collection of edges\nMin Cut: Global minimal energy in polynomial time\nMin Cut\nSource: Rother",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Binary segmentation as energy minimization\n Define a labeling L as an assignment of each pixel with\na 0-1 label (background or foreground)\n Problem statement: find the labeling L that minimizes\n{ { smoothness cost match cost (how similar is each pixel to the foreground / background?)",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": ": “distance” from pixel to foreground pixels { usually computed by\n: “distance” from pixel to background pixels\ncreating a color model from user-labeled pixels",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Colour Model\nR\nForeground & Background\nIterated graph cut\nR\nForeground\nBackground\nG\nBackground\nGaussian Mixture Model (typically 5-8 components)\nG\nSource: Rother",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": " Neighboring pixels should generally have the same labels\n Unless the pixels have very different intensities\n: similarity in intensity of p and q\n= 10.0\n= 0.1",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Binary segmentation as energy minimization\n For this problem, we can easily find the global minimum!\n Use max flow / min cut algorithm",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Graph min cut problem\n Given a weighted graph G with source and sink nodes (s\nand t), partition the nodes into two sets, S and T such that the sum of edge weights spanning the partition is minimized  and s\nS and t T",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation by min cut\nmin cut\nt (“background”)\ns (“foreground”)\n Graph\n node for each pixel, link between adjacent pixels  specify a few pixels as foreground and background\n create an infinite cost link from each bg pixel to the t node  create an infinite cost link from each fg pixel to the s node  create finite cost links from s and t to each other node\n compute min cut that separates s from t\n The min-cut max-flow theorem [Ford and Fulkerson 1956]",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Segmentation by min cut\nmin cut\nt\ns\n The partitions S and T formed by the min cut give the\noptimal foreground and background segmentation\n I.e., the resulting labels minimize",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "GrabCut segmentation 1. Define graph\n\n\nusually 4-connected or 8-connected Divide diagonal potentials by sqrt(2)\n2. Define unary potentials\n Color histogram or mixture of Gaussians for background\n));(());((log)(_backgroundforegroundxcPxcPxpotentialunary\nand foreground\n3. Define pairwise potentials\n22212)()(exp),(_ycxckkyxpotentialedge\n4. Apply graph cuts 5. Return to 2, using current labels to compute foreground, background models",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "GrabCut\nGrabcut [Rother et al., SIGGRAPH 2004]",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "GrabCut\n Implemented in MS office …. Let’s try it\n46\nLihi Zelnik-Manor, Computer Vision\nReported results",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Easier examples",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "More difficult Examples\nCamouflage & Low Contrast\nFine structure\nInitial Rectangle\nInitial Result\nHarder Case",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Graph cuts with multiple labels\n Alpha expansion\nRepeat until no change For 𝛼 = 1. . 𝑀\nAssign each pixel to current label or 𝛼 (2-class graphcut)\n Achieves “strong” local minimum\n Alpha-beta swap\nRepeat until no change\nFor 𝛼 = 1. . 𝑀, 𝛽 = 1. . 𝑀 (except 𝛼)\nRe-assign all pixels currently labeled as 𝛼 or 𝛽 to one of those two labels while keeping all other pixels fixed",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Other application: synthesis\n50\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Using graph cuts for recognition\nTextonBoost (Shotton et al. 2009 IJCV)",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Using graph cuts for recognition\nUnary Potentials from classifier\nAlpha Expansion Graph Cuts\n(note: edge potentials are from input image also; this is illustration from paper)\nTextonBoost (Shotton et al. 2009 IJCV)",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Summary: MRF and graph-cuts\n Pros:\n Powerful, based on probabilistic model (MRF)  Applicable to a wide range of problems  Very efficient algorithms available for many problems  Becoming a standard for segmentation\n Cons\n Graph-cuts can only solve a limited class of problems:\n Sub-modular energy functions  Can only capture part of the power of MRF\n Only approximate solutions available for multi-label case\n53\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Graph cuts: Pros and Cons\n Pros\n Very fast inference  Can incorporate data likelihoods and priors  Applies to a wide range of problems (stereo, image labeling,\nrecognition)\n Cons\n Not always applicable (associative only)  Need unary terms (not used for bottom-up segmentation, for\nexample)\n Use whenever applicable",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Further reading and resources\n Graph cuts\n http://www.cs.cornell.edu/~rdz/graphcuts.html  Classic paper: What Energy Functions can be Minimized via Graph Cuts?\n(Kolmogorov and Zabih, ECCV '02/PAMI '04)\n Belief propagation\nYedidia, J.S.; Freeman, W.T.; Weiss, Y., \"Understanding Belief Propagation and Its Generalizations”, Technical Report, 2001: http://www.merl.com/publications/TR2001-022/",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CNN for affinity learning\n Maire and Yu, 2015\n56\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CNN for affinity learning\n Maire and Yu, 2015\n57\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "End – image segmentation part 2\nNow you know how it works\n58\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/08-Segmentation_part2-Normalized-cuts-Markov-random_fields.pdf",
    "lang": "en"
  }
]

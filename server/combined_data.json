[
  {
    "filetype": "application/pdf",
    "text": "1\nFinding lines – part 2\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  (Generalized) Hough transform application  RANSAC\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting a parametric model to data\n# parameters 2 parametric equation\ny = mx + b\n3 r2 = (x-x0)2 + (y-y0)2\nparameters m, b\nr, x0, y0\nImage credit Zhaozheng Yin @ wisc.edu\nImage credit Yuan-Liang Tang on Mathworks\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Fitting a parametric model to data\n Design questions:\n What is a good model to represent our data?  Do we plan to fit multiple instances?\n Challenges:\n Which features belong to the model? To which instance?  How many instances are there?  Computational complexity (typically we cannot examine all\npossible models).\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\ndetection of power lines in helicopter navigation systems\nImage credit: Horev et al. SIAM’15\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\nlane detection from car cameras in crashpreventing systems\n6\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\ndetection of long filaments in high-throughput biological imaging\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\nSports\n8\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting applications\n“Interactive 3D Architectural Modeling from Unordered Photo Collections” Sinha et al. 2008\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Challenges of line fitting\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Challenges of line fitting\n Which points on which line?  Noisy edge detection:\n Clutter  Missed parts  Points are only approximately\nalong the line\n Large search space.  How many lines are there?\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Voting\n Problem:\n We cannot try all possible models\n Solution by voting:\n Features (points) vote for models they are compatible with  Search for models with lots of votes\nfeature space\nmodel space\n2\nVoting\nr e e m a r a p\nt\nl\ne d o M\nModel parameter 1\n12\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\n\n14\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\n\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough transform\n\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Finding lines with the Hough transform\n Discretize Hough space  Each edge point votes for all possible parameters in Hough\nspace\n Parameters with lots of votes indicate lines in image space\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Polar representation for lines\n\nd\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Hough-transform algorithm\n\n19\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example\nFor a given point (x0,y0)\nd(q)=x0cosq+y0sinq\ny\nd\nx\n20\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Example\nFor a given point (x0,y0)\nd(q)=x0cosq+y0sinq\ny\nd\nx\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: an image with straight lines\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Properties\n Noise and clutter votes are inconsistent, so will not\naccumulate.\n Can handle occlusions if not all points are present as long as\nmodel gets enough votes.\n Efficient.\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: a real image\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example: a real image\n25\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Impact of noise on Hough transform\n What difficulties does noise introduce?\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Impact of noise on Hough transform\n Here everything is “noise” but we still see peaks in the\nvote space\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Voting: Practical tips\n Use only trustworthy points\n E.g., edges points with significant gradient magnitude\n(alternatively weight votes)\n Szeliski suggests using edgels instead of points\n Choose a good quantization grid\n Not too coarse – too many lines fall in the same bucket  Not too fine – collinear points vote for different lines\n Smooth the voting (vote also for neighbors)  Non-maxima suppression  Refit line using accumulated votes  Reduce number of parameters, if possible\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hough transform summary\n Pros\n Can handle occlusions  Some robustness to noise  Can detect multiple lines in a single pass over the image\n Cons\n Clutter can produce spurious peaks in parameter space  Hard to select the right quantization\n29\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Generalized Hough Transform\n Can be extended to other parametric models such as:\ncircles, ellipses, rectangles etc.\n Complexity increases exponentially with the number of\nparameters.\n Can be used to detect complex non-parametric models as\ndescribed in Leibe et al. “Combined object categorization and segmentation with an implicit shape model”.\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANdom SAmple Consensus [Fischler & Bolles 1981]\n Key ideas:\n Look for “inliers” and use only them  If we fit a model to “outliers” we will not get a good fitting\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC algorithm\nLoop: 1.Randomly select a group of points 2.Fit a model to the selected group 3.Find the inliers of the computed model 4.If number of inliers is large enough re-compute model using only inliers 5.Compute number of inliers of updated model The winner: model with the largest number of inlier\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Input:\nA set of edge points\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 1:\nSelect two points\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 2:\nFit a line to the selected points\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 3:\nIdentify inliers\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 4:\nFit line to inliers\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Line fitting with RANSAC\n Step 5:\nCount number of new inliers\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC – stopping criteria\n\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC – for multiple models?\n How can we use RANSAC to compute multiple models?\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RANSAC - summary\n Pros\n General method that works well for lots of model fitting\nproblems\n Easy to implement\n Cons\n When the percentage of outliers is high too many iterations\nare needed and failure rate increases\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "43\nEnd – finding lines\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/06-Line_Fitting_-_RANSAC_-_HOUGH.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nFinding lines – part 1\nLihi Zelnik-Manor, Computer Vision\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n2\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why edges?\n We know edges are special\n3\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge detection - goal\n Goal:\nMap image from 2d array of pixels to a set of curves or line segments or contours.  Most semantic and shape information from the image can be\nencoded in the edges\n A more compact representation than a complete image\n Ideal:\nArtist’s Line drawing (but artists use prior knowledge)\n4\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What can cause an edge?\nSurface normal discontinuity\nDepth discontinuity\nIllumination discontinuity\nSurface color discontinuity\n5\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What can cause an edge?\nReflectance change: appearance information, texture\nChange in surface orientation: shape\n6\nLihi Zelnik-Manor, Computer Vision\nDepth discontinuity: object boundary\nCast shadows",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contrast and invariance\n7\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edges look like steep cliffs\n8\nLihi Zelnik-Manor, Computer Vision\nSource: S. Seitz",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n9\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivatives and edges\n An edge is a place of rapid change in the image intensity\nfunction.\nimage\nintensity function (along horizontal scanline)\nfirst derivative\nedges correspond to extrema of derivative\n10\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image gradient\nThe gradient of an image:\nThe gradient points in the direction of most rapid change in intensity\nThe gradient direction (orientation of edge normal) is given by:\nThe edge strength is given by the gradient magnitude\n11\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Differentiation and convolution\nFor 2D function, f(x,y), the partial derivative is:\n),(),(lim),(0yxfyxfxyxf\nFor discrete data, we can approximate using finite differences:\n(,)(1,)(,)fxyfxyfxyxx\nTo implement above as convolution, what would be the associated filter?\n1 1\n12\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Assorted finite difference filters\n>> My = fspecial(‘sobel’); >> outim = imfilter(double(im), My); >> imagesc(outim); >> colormap gray;\n13\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Partial derivatives of an image\nxyxf),(\nWhich shows changes with respect to x? y?\n14\nLihi Zelnik-Manor, Computer Vision\nyyxf),(",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Intensity profile of one row\nIntensity\nGradient\n15\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\nConsider a single row or column of the image\n Plotting intensity as a function of position gives a signal\nWhere is the edge?\n16\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\n Finite difference filters respond strongly to noise\n Image noise results in pixels that look very different from\ntheir neighbors\n Generally, the larger the noise the stronger the response\n What can be done?\n17\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effects of noise\n Finite difference filters respond strongly to noise\n Image noise results in pixels that look very different from\ntheir neighbors\n Generally, the larger the noise the stronger the response\n What can be done?\n Smoothing the image should help – it forces pixels to look\nmore like their neighbors\n18\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Solution: smooth first\nf\ng\nfg\ndfgdx\nWhere is the edge?\nLook for peaks in\n19\nLihi Zelnik-Manor, Computer Vision\ndfgdx",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative theorem of convolution\nDifferentiation property of convolution:\nf\ndgdx\ndfgdx\n20\nLihi Zelnik-Manor, Computer Vision\n\nddfgfgdxdx",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative of Gaussian filter\n11\nIs this a separable filter?\n21\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Derivative of Gaussian filters\nx-direction\ny-direction\nWhich one finds horizontal/vertical edges?\n22\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smoothing tradeoffs\n1 pixel\n3 pixels\n7 pixels\nSmoothed derivative removes noise, but blurs edge. Also finds edges at different “scales”.\n23\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Laplacian of Gaussian (LoG filter)\nf\n22dgdx\n22dfgdx\nWhere is the edge? Zero-crossings of bottom graph\n24\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "2D edge detection filters\nGaussian\nderivative of Gaussian\ng\ndgdx\n25\nLihi Zelnik-Manor, Computer Vision\nLaplacian of Gaussian\n2222dgdgdxdy",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "DoG = Difference of Gaussians\n Can approximate Laplacian filter\n26\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is a good edge detector?  Good detection:\n Minimize false positives (wrong detections)\n Minimize false negatives (missing real edges)\n Maximize true detections\n Good localization:\n Detected edges should be as close as possible to the\ntrue edges\n Single response:\n Return a single detection for each true edge point\n Connect detections to lines\n27\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is a good edge detector?  Good detection\n Good localization\n Single response\nWhich of these detections is the best?\n28\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What are the parameters?\n Scale  Threshold\n29\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Scale selection\n Recall: We first smooth the image with a Gaussian\nkernel to reduce noise.\n The scale of the Gaussian determines how much\nsmoothing we apply\n…\n30\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Effect of σ on derivatives\n The apparent structures differ depending on Gaussian’s\nscale parameter.\n Large scale: larger scale edges detected  Small scale: finer features detected\nσ = 1 pixel\nσ = 3 pixels\n31\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "How do we chose the scale?  It depends what we’re looking for:\n Too fine of a scale…can’t see the forest for the trees.  Too coarse of a scale…can’t tell the maple grain from the\ncherry.\n32\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What are the parameters?\n Scale  Threshold\n33\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Thresholding\n Choose a threshold value  Set any pixels less than thresh to zero (off)  Set any pixels greater than or equal to thresh to one (on)\n34\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original image\n35\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Gradient magnitude\n36\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Using a low threshold\n37\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Using a higher threshold\n38\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Canny edge detector\n Probably the most widely used edge detector in computer\nvision\n Key idea:\ndetect step-edges that are corrupted by additive Gaussian noise\n Theorem:\nCanny has shown that the first derivative of the Gaussian closely approximates the operator that optimizes the product of signal-to-noise ratio and localization\nJ. Canny, A Computational Approach To Edge Detection, IEEE Trans. Pattern Analysis and Machine Intelligence, 8:679--‐714, 1986.\n39\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Canny edge detector\n\n\n\n\nFilter image with derivative of Gaussian Find magnitude and orientation of gradient Non-maximum suppression: (Localization)  Thin multi-pixel wide “ridges” down to single pixel width Linking and thresholding (hysteresis): (Linking)  Define two thresholds: low and high  Use the high threshold to start edge curves and the low\nthreshold to continue them\n\nMATLAB: edge(image, ‘canny’);\n\n>>help edge\n40\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example - input\noriginal image (Lena)\n41\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 1\nnorm of the gradient\n42\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 2\nthresholding\n43\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 3\nthresholding\n44\nLihi Zelnik-Manor, Computer Vision\nHow to turn these thick regions of the gradient into curves?",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Non-maximum suppression\nCheck if pixel q is local maximum along gradient direction,\nselect single max across width of the edge  requires checking interpolated pixels p and r\n45\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example – step 3\nThinning (non-maximum supression)\n46\nLihi Zelnik-Manor, Computer Vision\nProblem: pixels along this edge didn’t survive the thresholding",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge linking\n Assume the marked point is an edge point.  Then we construct the tangent to the edge curve (which is normal to the gradient at that point) and use this to predict the next points (here either r or s).\n47\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\n Check that maximum value of gradient value is\nsufficiently large  drop-outs? use hysteresis\n use a high threshold to start edge curves and a low threshold to\ncontinue them.\n48\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\noriginal image\nhigh threshold (strong edges)\nlow threshold (weak edges)\n49\nLihi Zelnik-Manor, Computer Vision\nhysteresis threshold",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nhigh threshold (strong edges)\n50\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nlow threshold (weak edges)\n51\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Hysteresis thresholding\nhysteresis threshold\n52\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Canny - results\n53\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Object boundaries vs. edges\nBackground 54\nTexture\nLihi Zelnik-Manor, Computer Vision\nShadows",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n Edge detection\n Canny edge detector  Berkeley edge probability\n Line fitting\n Hough transform  RANSAC\n55\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "At Berkeley:\n1. Collect Data Set of Human segmented images\n2.\nLearn Local Boundary Model for combining brightness, color and texture\n3. Global framework to capture closure, continuity 4. Detect and localize junctions Integrate low, mid and high-level information for grouping and figure-ground segmentation\nD. Martin, C. Fowlkes, D. Tal, J. Malik. \"A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics\", ICCV, 2001\nhtpp://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/\n56\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Berkeley Segmentation DataSet [BSDS]\nInput\nHuman segmentation\n57\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "id"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~1970\n58\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~1990\n59\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~2004\n60\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Contour detection ~2008\nInclude global cues\n61\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "Martin, Fowlkes, Malik PAMI 04\nGradient\nCue Combination\nBrightness\nColor\nModel\nTexture\n Goal: learn the posterior probability of a boundary\nPb(x,y,) from local information only\n Challenges:\n computing the cues,  cue combination\n62\nLihi Zelnik-Manor, Computer Vision\nPb",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: gradient cue\nImage\nOE = Oriented Energy\n63\nLihi Zelnik-Manor, Computer Vision\n+",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: brightness and color cues\nImage\nBG = Brightness Gradient\nCG = Color Gradient\n64\nLihi Zelnik-Manor, Computer Vision\nDifference of L* distributions\nBG = χ2(h1(L),h2(L))\nDifference of a* distributions\nCG = χ2(h1(a),h2(a))+ χ2(h1(b),h2(b))",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: texture cue\nImage\nTG = Texture Gradient\n65\nLihi Zelnik-Manor, Computer Vision\nDifference of filter distributions\nTG= 𝑓 χ2(h1(f),h2(f))",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Pb: cue design\nImage\n66\nLihi Zelnik-Manor, Computer Vision\nMultiple orientations\nMultiple disk radii",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Filter banks\norientations\nscales\n“Edges”\n“Bars”\n“Spots”\n What filters to put in the bank?\n Typically we want a combination of scales and\norientations, different types of patterns.\nMatlab code available for these examples: http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html\n67\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page67",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Filter bank\n68\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page68",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "g p\nj .\n2 p a c n\ni t s u a m o c . r e r o p x e s a x e\n/\nl\nt .\nw w w\n/ / :\np\nt t\nh m o r f\ne g a m\nI\n69\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page69",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "70\nShowing magnitude of responses\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page70",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "71\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page71",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "72\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page72",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "73\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page73",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "74\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page74",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "75\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page75",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "76\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page76",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "77\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page77",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "78\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page78",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "79\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page79",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "80\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page80",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "81\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page81",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "82\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page82",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "83\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page83",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "84\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page84",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "85\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page85",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "86\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page86",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "87\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page87",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "88\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page88",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n2\n3\nYou try: Can you match the texture to the response?\nFilters\nA\nB\nC\nMean abs responses\n89\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page89",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n2\n3\nYou try: Can you match the texture to the response?\nFilters\nA\nB\nC\nMean abs responses\n90\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page90",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "91\nLihi Zelnik-Manor, Computer Vision\n[r1, r2, …, r38]\nWe can form a feature vector from the list of responses at each pixel.",
    "offset": "page91",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Martin, Fowlkes, Malik PAMI 04\nGradient OE\nCue Combination\nBrightness BG\nColor CG\nModel\nTexture TG\n Goal: learn the posterior probability of a boundary\nPb(x,y,) from local information only\n Challenges:\n computing the cues,  cue combination\n92\nLihi Zelnik-Manor, Computer Vision\nPb",
    "offset": "page92",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "93\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page93",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "94\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page94",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Parameter tuning (cue optimization)\n Scale  Disk radius  Number of bins in histogram\nTrained on labeled data\n95\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page95",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Cue combination\n Tested many options:\n Logistic regression – the winner!  SVM (support vector machines)  Hierarchical Mixture of Experts  Classification trees\n96\nLihi Zelnik-Manor, Computer Vision\nThe logistic function",
    "offset": "page96",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Various cue combinations\n97\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page97",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Example results\n98\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page98",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forty years of contour detection\nRoberts (1965)\nSobel (1968)\nPrewitt (1970)\nMarr Hildreth (1980)\nCanny (1986)\nPerona Malik (1990)\n99\nLihi Zelnik-Manor, Computer Vision\nMartin Fowlkes Malik (2004)\nMaire Arbelaez Fowlkes Malik (2008)\n99",
    "offset": "page99",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Global pB boundary detector\nFigure from Fowlkes",
    "offset": "page100",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests (Dollar Zitnick ICCV 2013)\n Goal: quickly predict whether each pixel is an\nedge\n Insights\n Predictions can be learned from training data  Predictions for nearby pixels should not be\nindependent\n Solution\n Train structured random forests to split data into\npatches with similar boundaries based on features\n Predict boundaries at patch level, rather than pixel level, and aggregate (average votes)\nhttp://research.microsoft.com/pubs/202540/DollarICCV13edges.pdf\nBoundaries in patch",
    "offset": "page101",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests\n Algorithm\n1. Extract overlapping 32x32 patches at three scales\n2.\nFeatures are pixel values and pairwise differences in feature maps (LUV color, gradient magnitude, oriented gradient)\n3. Predict 𝑇 boundary maps in the central 16x16 region using 𝑇 trained decision trees\n4. Average predictions for each pixel across all patches",
    "offset": "page102",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests Results\nBSDS 500\nNYU Depth dataset edges",
    "offset": "page103",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Edge Detection with Structured Random Forests\nGround truth\nResults (multiscale)",
    "offset": "page104",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Forty years of contour detection\nRoberts (1965)\nSobel (1968)\nPrewitt (1970)\nMarr Hildreth (1980)\nCanny (1986)\nPerona Malik (1990)\n105\nLihi Zelnik-Manor, Computer Vision\nMartin Fowlkes Malik (2004)\nMaire Arbelaez Fowlkes Malik (2008)\nDollar Zitnick (2013)",
    "offset": "page105",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Crisp Boundary Detection using Pointwise Mutual Information (Isola et al. ECCV 2014)\nPixel color combinations that are unlikely to be together are edges\nAlgorithm:\nKernel density estimation\nSpectral clustering\nhttp://web.mit.edu/phillipi/www/publications/crisp_boundaries.pdf",
    "offset": "page106",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Crisp Boundary Detection using Pointwise Mutual Information",
    "offset": "page107",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\n Trevor Darell  Kristen Grauman  Jitendra Malik  FeiFei Li  Derek Hoiem  and Seitz, Marschner, Lazebnik and others\n108\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page108",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "109\nEnd – finding lines\nNow you know how it works\nLihi Zelnik-Manor, Computer Vision",
    "offset": "page109",
    "ref": "/home/ameer/Kaleidoo/server/uploads/05-Edge_Detection.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nImage Resampling",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image Scaling\nThis image is too big to fit on the screen. How can we generate a half-sized version?\nSource: S. Seitz",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\n1/4\nThrow away every other row and column to create a 1/2 size image - called image sub-sampling\n1/8\nSource: S. Seitz",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\n1/2\n1/4 (2x zoom)\nWhy does this look so crufty?\n1/8 (4x zoom)\nSource: S. Seitz",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image sub-sampling\nSource: F. Durand",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Even worse for synthetic images\nSource: L. Zhang",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Aliasing\nOccurs when your sampling rate is not high enough to capture the amount of detail in your image • Can give you the wrong signal/image—an alias\nTo do sampling right, need to understand the structure of your signal/image\nEnter Monsieur Fourier…\nTo avoid aliasing:\n– sampling rate ≥ 2 * max frequency in the image • said another way: ≥ two samples per cycle\n– This minimum sampling rate is called the Nyquist rate\nSource: L. Zhang",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Wagon-wheel effect\n(See http://www.michaelbach.de/ot/mot_wagonWheel/index.html)\nSource: L. Zhang",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Nyquist limit – 2D example\nGood sampling\nBad sampling",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Aliasing\nWhen downsampling by a factor of two\n– Original image has frequencies that are too high\nHow can we fix this?",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pre-filtering\nG 1/4\nGaussian 1/2\nSolution: filter the image, then subsample\nG 1/8\nSource: S. Seitz",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Subsampling with Gaussian pre-filtering\nGaussian 1/2\nG 1/4\nSolution: filter the image, then subsample\nG 1/8\nSource: S. Seitz",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1/2\nCompare with...\n1/4 (2x zoom)\n1/8 (4x zoom)\nSource: S. Seitz",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pre-filtering • Solution: filter the image, then subsample\nblur\nF0\nsubsample\nF0 H*\nblur\nF1 subsample …\nF2\nF1 H*",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramid\nblur\nF0\nsubsample\nF0 H*\nblur\nF1 subsample …\nF2\nF1 H*",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramids [Burt and Adelson, 1983]\nIn computer graphics, a mip map [Williams, 1983] • A precursor to wavelet transform\nGaussian Pyramids have all sorts of applications in computer vision\nSource: S. Seitz",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian pyramids [Burt and Adelson, 1983]\nHow much space does a Gaussian pyramid take compared to the original image?\nSource: S. Seitz",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian Pyramid",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "lt"
  },
  {
    "filetype": "application/pdf",
    "text": "0G\nThe Laplacian Pyramid\n)expand(1iiiGGL\nGaussian Pyramid\n)expand(1iiiGLG\nnG\n2G\n=\n1G\n=\n=\nLaplacian Pyramid\nnnGL\n2L\n1L\n0L",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nImage Interpolation",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image Scaling\nLast time:\nThis image is too big to fit on the screen. How can we generate a half-sized version?\nSource: S. Seitz",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Upsampling\nThis image is too small for this screen: • How can we make it 10 times as big? • Simplest approach: repeat each row and column 10 times\n(“Nearest neighbor interpolation”)",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nd = 1 in this example\n1\n2\n3\n4\n5\nRecall how a digital image is formed\nIt is a discrete point-sampling of a continuous function • If we could somehow reconstruct the original function, any new image could be generated, at any resolution and scale\nAdapted from: S. Seitz",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nd = 1 in this example\n1\n2\n3\n4\n5\nRecall how a digital image is formed\nIt is a discrete point-sampling of a continuous function • If we could somehow reconstruct the original function, any new image could be generated, at any resolution and scale\nAdapted from: S. Seitz",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\n1\n1\n2\n2.5\n3\n4\n5\nWhat if we don’t know ?\nGuess an approximation: • Can be done in a principled way: filtering • Convert to a continuous function:\nReconstruct by convolution with a reconstruction filter, h\nd = 1 in this example\nAdapted from: S. Seitz",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\n“Ideal” reconstruction\nNearest-neighbor interpolation\nLinear interpolation\nGaussian reconstruction\nSource: B. Curless",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Reconstruction filters • What does the 2D version of this hat function look like?\nperforms linear interpolation\n(tent function) performs bilinear interpolation\nOften implemented without cross-correlation\nE.g., http://en.wikipedia.org/wiki/Bilinear_interpolation\nBetter filters give better resampled images\nBicubic is common choice\nCubic reconstruction filter",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nOriginal image: x 10\nNearest-neighbor interpolation\nBilinear interpolation\nBicubic interpolation",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image interpolation\nAlso used for resampling",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Raster to Vector Graphics",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Depixelating Pixel Art",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/03-Sampling.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "1\nAlgorithms and Applications in Computer Vision\nLihi Zelnik-Manor lihi@ee.technion.ac.il\nLihi Zelnik-Manor, Computer vision",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n “What is computer vision?”  Administration\n2\nLihi Zelnik-Manor, Computer vision",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is computer vision?\nDone?\n3\nLihi Zelnik-Manor, Computer vision",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The goal of computer vision",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is computer vision?\n Automatic understanding of images and video\n Measurement: Computing properties of the 3D world from\nvisual data\n Perception and interpretation: Algorithms and representations to allow a machine to recognize objects, people, scenes, and activities.\n Image enhancement: super-resolution, synthesis, deblur\n(computational photography).\n5\nLihi Zelnik-Manor, Computer vision",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision for measurement\nReal-time stereo\nStructure from motion\nMulti-view stereo for community photo collections\nNASA Mars Rover\nPollefeys et al.\nGoesele et al.\n6\nLihi Zelnik-Manor, Computer vision\nSlide credit: L. Lazebnik",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision for perception, interpretation\nThe Wicked Twister\nride\nsky\namusement park\nCedar Point\nFerris wheel\nride\nObjects Activities Scenes Locations Text / writing Faces Gestures Motions Emotions…\n12 E\nLake Erie\nwater\nride\ntree\ntree\npeople waiting in line\npeople sitting on ride\numbrellas\n7\ndeck\ntree\nbench\ncarousel\ntree\npedestrians\nLihi Zelnik-Manor, Computer vision\nmaxair",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "“Enhancing” images (c.f. Computational Photography)\nTexture synthesis / increased field of view (uncropping) (image credit: Efros and Leung)\nSuper-resolution / denoising (source: 2d3)\nInpainting / image completion (image credit: Hays and Efros)",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Related disciplines\nGraphics\nArtificial intelligence\nMachine learning\nImage processing\nComputer vision\nCognitive science\nAlgorithms\n9\nLihi Zelnik-Manor, Computer vision",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision and graphics\nImages\nVision\nModel\nGraphics\nInverse problems: analysis and synthesis.\n10\nLihi Zelnik-Manor, Computer vision",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why study computer vision?\n Vision is useful\n Vision is interesting\n Vision is difficult\n Half of primate cerebral cortex is devoted to visual processing  Achieving human-level visual perception is probably\n“AI-complete” (is this really true??)\n11\nLihi Zelnik-Manor, Computer vision",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is vision useful?\n As image sources multiply, so do applications\n Relieve humans of boring, easy tasks\n Enhance human abilities: human-computer interaction,\nvisualization\n Perception for robotics / autonomous agents\n Organize and give access to visual content\n12\nLihi Zelnik-Manor, Computer vision",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is it interesting?  Images and videos are everywhere!\nPersonal photo albums\nMovies, news, sports\nSurveillance and security\nMedical and scientific images\n13\nLihi Zelnik-Manor, Computer vision\nSlide credit; L. Lazebnik",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why is it difficult?\n14\nLihi Zelnik-Manor, Computer vision",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Viewing angle\n15\nLihi Zelnik-Manor, Computer vision\nMichelangelo, David",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Lighting\n16\nLihi Zelnik-Manor, Computer vision",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Size\n17\nLihi Zelnik-Manor, Computer vision",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Occlusions\n18\nLihi Zelnik-Manor, Computer vision",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Deformation\n19\nLihi Zelnik-Manor, Computer vision",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Deformation\n20\nLihi Zelnik-Manor, Computer vision",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Camera limitations (e.g. saturation)\n21\nLihi Zelnik-Manor, Computer vision",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Motion blur\n22\nLihi Zelnik-Manor, Computer vision",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Intra-class variability\n23\nLihi Zelnik-Manor, Computer vision",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "But there are lots of cues we can exploit…\nSource: S. Lazebnik",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Bottom line  Perception is an inherently ambiguous problem\n Many different 3D scenes could have given rise to a particular\n2D picture\n We often need to use prior knowledge about the structure of\nthe world\nImage source: F. Durand",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computer vision in practice\n26\nLihi Zelnik-Manor, Computer vision",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision Demo?\nTerminator 2\n27\nwe’re not quite there yet….\nLihi Zelnik-Manor, Computer vision",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Earth viewers (3D modeling)\nImage from Microsoft’s Virtual Earth (see also: Google Earth)\n28\nLihi Zelnik-Manor, Computer vision",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photosynth\nhttp://labs.live.com/photosynth/\nBased on Photo Tourism technology developed by Noah Snavely, Steve Seitz, and Rick Szeliski\n29\nLihi Zelnik-Manor, Computer vision",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photo Tourism overview\nScene reconstruction\nPhoto Explorer\nInput photographs\nRelative camera positions and orientations\nPoint cloud\nSparse correspondence\nSystem for interactive browsing and exploring large collections of photos of a scene. Computes viewpoint of each photo as well as a sparse 3d model of the scene.\n30\nLihi Zelnik-Manor, Computer vision",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Photo Tourism overview\n31\nLihi Zelnik-Manor, Computer vision",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Optical character recognition (OCR)\n Technology to convert scanned docs to text  If you have a scanner, it probably came with OCR\nsoftware\nDigit recognition, AT&T labs http://www.research.att.com/~yann/\nLicense plate readers http://en.wikipedia.org/wiki/Automatic_number_plate_recognition\n32\nLihi Zelnik-Manor, Computer vision",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Face detection\n Most digital cameras now detect faces in realtime\n33\nLihi Zelnik-Manor, Computer vision",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smile detection?\nSony Cyber-shot® T70 Digital Still Camera\n34\nLihi Zelnik-Manor, Computer vision",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Face Recognition\nhttp://developers.face.com/tools/",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Object recognition (in supermarkets)\nLaneHawk by EvolutionRobotics “A smart camera is flush-mounted in the checkout lane, continuously watching for items. When an item is detected and recognized, the cashier verifies the quantity of items that were found under the basket, and continues to close the transaction. The item can remain under the basket, and with LaneHawk,you are assured to get paid for it… “\n36\nLihi Zelnik-Manor, Computer vision",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Biometrics\nWho is she?\n37\nLihi Zelnik-Manor, Computer vision",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision-based biometrics\n“How the Afghan Girl was Identified by Her Iris Patterns” Read the story\n38\nLihi Zelnik-Manor, Computer vision",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Login without a password…\nFingerprint scanners on many new laptops, other devices\nFace recognition systems now beginning to appear more widely http://www.sensiblevision.com/\n39\nLihi Zelnik-Manor, Computer vision",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Object recognition (in mobile phones)\n40\nLihi Zelnik-Manor, Computer vision",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Google Goggles",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "da"
  },
  {
    "filetype": "application/pdf",
    "text": "Google Search by Image",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Leaf Recognition",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Special effects: shape capture\nThe Matrix movies, ESC Entertainment, XYZRGB, NRC\n44\nLihi Zelnik-Manor, Computer vision",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Special effects: motion capture\nPirates of the Carribean, Industrial Light and Magic\n45\nLihi Zelnik-Manor, Computer vision",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sports\nSportvision first down line Nice explanation on www.howstuffworks.com\n46\nLihi Zelnik-Manor, Computer vision",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smart cars\n Mobileye https://www.youtube.com/watch?v=HXpiyLUEOOY  Tesla https://www.youtube.com/watch?v=4CZe5DXeYzw\n47\nLihi Zelnik-Manor, Computer vision\nSource: Amnon Shashua",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision-based interaction (and games)\nDigimask: put your face on a 3D avatar.\nNintendo Wii has camera-based IR tracking built in. See Lee’s work at CMU on clever tricks on using it to create a multi-touch display!\n“Game turns moviegoers into Human Joysticks”, CNET Camera tracking a crowd, based on this work.\n48\nLihi Zelnik-Manor, Computer vision",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Kinect",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Vision in space\nNASA'S Mars Exploration Rover Spirit captured this westward view from atop a low plateau where Spirit spent the closing months of 2007. Vision systems (JPL) used for several tasks\nPanorama stitching • 3D terrain modeling • Obstacle detection, position tracking • For more, read “Computer Vision on Mars” by Matthies et al. Lihi Zelnik-Manor, Computer vision\nPanorama stitching • 3D terrain modeling • Obstacle detection, position tracking • For more, read “Computer Vision on Mars” by Matthies et al. Lihi Zelnik-Manor, Computer vision",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Robotics\nNASA’s Mars Spirit Rover http://en.wikipedia.org/wiki/Spirit_rover\nhttp://www.robocup.org/\n51\nLihi Zelnik-Manor, Computer vision",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Medical imaging\n3D imaging MRI, CT\n52\nImage guided surgery Grimson et al., MIT\nLihi Zelnik-Manor, Computer vision",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Current state of the art\n You just saw examples of current systems.  Many of these are less than 5 years old\n This is a very active research area, and rapidly changing\n Many new apps in the next 5 years\n To learn more about vision applications and companies\n David Lowe maintains an excellent overview of vision\ncompanies  http://www.cs.ubc.ca/spider/lowe/vision.html\n53\nLihi Zelnik-Manor, Computer vision",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "AI has come\n https://openai.com/blog/introducing-openai/\n Toyota Invests $1 Billion in Artificial Intelligence in U.S.\nhttp://www.nytimes.com/2015/11/06/technology/toyota- silicon-valley-artificial-intelligence-research- center.html?_r=0\n Facebook AI Research (FAIR)\nhttps://research.facebook.com/ai\n54\nLihi Zelnik-Manor, Computer vision",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Again, what is computer vision?\n Mathematics of geometry of image formation?  Statistics of the natural world?  Models for neuroscience?  Engineering methods for matching images?  Science Fiction?\n55\nLihi Zelnik-Manor, Computer vision",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today\n “What is computer vision?”  Administration\n56\nLihi Zelnik-Manor, Computer vision",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Course overview (tentative)\n1.\nLow-level vision\n2.\n\nimage processing, edge detection, feature detection, cameras, image formation Basic Geometry\n\nprojective geometry, Optical flow, panoramas\n3.\nRecognition\n\nface detection / recognition, category recognition, segmentation\n4.\nIntroduction to Deep Learning",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Prerequisites\n : What I expect you to already know  A good working knowledge of Python programming\n(or willingness and time to pick it up quickly!)\n Linear algebra\n58\nLihi Zelnik-Manor, Computer vision",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Books\n Rick Szeliski’s book:\nComputer Vision: Algorithms and applications\n Forsyth and Ponce,\nComputer Vision: A Modern Approach.\n59\nLihi Zelnik-Manor, Computer vision",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Szeliski Book\n60\nLihi Zelnik-Manor, Computer vision",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "sl"
  },
  {
    "filetype": "application/pdf",
    "text": "Forsyth & Ponce Book\n61\nLihi Zelnik-Manor, Computer vision",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Programming\n Problem sets and projects will involve Python programming (you are\nfree to use alternative packages).a\n62\nLihi Zelnik-Manor, Computer vision",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Grading\n There will be three components to the course grade\n HW assignments, 2-3, including programming projects\n Final Project\n Class attendance, class participation, short quizes?a\n63\nLihi Zelnik-Manor, Computer vision",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Problem sets – still not finalized\n\n\n\n\nPset1 – Edge detection and voting techniques Pset2 – Image segmentation Pset3 – Feature tracking and alignment Pset4 – Recognition\n\n\nCan discuss, but must have your own code. Submit work in singles.a\n64\nLihi Zelnik-Manor, Computer vision",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Course goals….\n You’ll know something about computer vision\n65\nLihi Zelnik-Manor, Computer vision",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "And now, who are you?\n What do you expect to get out of this class?  Previous experience in vision, learning, graphics?  Research agenda?  (Project topics?)\n66\nLihi Zelnik-Manor, Computer vision",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/01-Introduction.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670/5670: Intro to Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CS4670: Computer Vision\nNoah Snavely\nLecture 1: Images and image filtering\nHybrid Images, Oliva et al., http://cvcl.mit.edu/hybridimage.htm",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Reading\nSzeliski, Chapter 3.1-3.2",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nWe’ll focus on these in this class\n(More on this process later)\nDigital Camera\nThe Eye\nSource: A. Efros",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nA grid (matrix) of intensity values\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255\n20\n0 255 255 255 255 255 255 255\n255 255 255\n75\n75\n75 255 255 255 255 255 255\n=\n255 255\n75\n95\n95\n75 255 255 255 255 255 255\n255 255\n96 127 145 175 255 255 255 255 255 255\n255 255 127 145 175 175 175 255 255 255 255 255\n255 255 127 145 200 200 175 175\n95 255 255 255\n255 255 127 145 200 200 175 175\n95\n47 255 255\n255 255 127 145 145 175 127 127\n95\n47 255 255\n255 255\n74 127 127 127\n95\n95\n95\n47 255 255\n255 255 255\n74\n74\n74\n74\n74\n74 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n255 255 255 255 255 255 255 255 255 255 255 255\n(common to use one byte per value: 0 = black, 255 = white)",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "What is an image?\nWe can think of a (grayscale) image as a function, f, from R2 to R: – f (x,y) gives the intensity at position (x,y)\nf (x, y)\nx\ny\n– A digital image is a discrete (sampled, quantized)\nversion of this function",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image transformations\nAs with any function, we can apply operators to an image\ng (x,y) = f (x,y) + 20\ng (x,y) = f (-x,y)\nWe’ll talk about a special kind of operator, convolution (linear filtering)",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Question: Noise reduction • Given a camera and a still scene, how can you\nreduce noise?\nTake lots of images and average them! What’s the next best thing?\nSource: S. Seitz",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Image filtering\nModify the pixels in an image based on some function of a local neighborhood of each pixel\n10\n5\n3\nSome function\n4\n5\n1\n7\n1\n1\n7\nLocal image data\nModified image data\nSource: L. Zhang",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Linear filtering\nOne simple version: linear filtering (cross-correlation, convolution)\n– Replace each pixel by a linear combination (a weighted\nsum) of its neighbors\nThe prescription for the linear combination is called the “kernel” (or “mask”, “filter”)\n10\n5\n3\n0\n0\n0\n4\n6\n1\n0\n0.5 0\n8\n1\n1\n8\n0\n1\n0.5\nLocal image data\nkernel\nModified image data\nSource: L. Zhang",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Cross-correlation\nLet be the image, be the kernel (of size 2k+1 x 2k+1), and be the output image. The cross-correlation operation is defined as:\nCan think of as a “dot product” between local neighborhood and kernel for each pixel\nShort notation:",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Convolution\nSame as cross-correlation, except that the kernel is “flipped” (horizontally and vertically)\nThis is called a convolution operation:\nConvolution is commutative and associative",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Convolution\nAdapted from F. Durand",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "1\n1\n1\n1\n1\n1\n1\n1 *\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nMean filtering\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n90\n90\n90\n90\n90\n0\n90\n90\n90\n90\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n0\n=\n0\n90\n90\n90\n90\n90\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n90\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n10 20 30 30 30 20 10\n0\n20 40 60 60 60 40 20\n0\n30 60 90 90 90 60 30\n0\n30 50 80 80 90 60 30\n0\n30 50 80 80 90 60 30\n0\n20 30 50 50 60 40 20\n10 20 30 30 30 30 20 10\n10 10 10\n0\n0\n0\n0\n0",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n1\n0\n0\n0\n0\n=\nIdentical image\nSource: D. Lowe",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n0\n0\n0\n1\n0\n=\nShifted left By 1 pixel\nSource: D. Lowe",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Linear filters: examples\n1\n1\n1\n1\n1\n1\n1\n1\n1\n=\nOriginal\nBlur (with a mean filter)\nSource: D. Lowe",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Original\nLinear filters: examples\n0\n0\n0\n0\n2\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n=\nSharpening filter (accentuates edges)\nSource: D. Lowe",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sharpening\nSource: D. Lowe",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Smoothing with box filter revisited\nSource: D. Forsyth",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian Kernel\nSource: C. Rasmussen",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian filters\n= 1 pixel\n= 5 pixels\n= 10 pixels\n= 30 pixels",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "ca"
  },
  {
    "filetype": "application/pdf",
    "text": "Mean vs. Gaussian filtering",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Gaussian filter\nRemoves “high-frequency” components from the image (low-pass filter)\nConvolution with self is another Gaussian\n=\n– Convolving twice with Gaussian kernel of width\n= convolving once with kernel of width\nSource: K. Grauman",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Sharpening revisited\nWhat does blurring take away?\n–\n=\noriginal\nsmoothed (5x5)\nLet’s add it back:\n+ α\n=\noriginal\ndetail\ndetail\nsharpened\nSource: S. Lazebnik",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "image\nblurred image\nscaled impulse\nSharpen filter\nGaussian\nunit impulse (identity)\nLaplacian of Gaussian (LoG)",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "unfiltered\nfiltered\nSharpen filter",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "no"
  },
  {
    "filetype": "application/pdf",
    "text": "“Optical” Convolution\nCamera shake\n=\nSource: Fergus, et al. “Removing Camera Shake from a Single Photograph”, SIGGRAPH 2006\nBokeh: Blur in out-of-focus regions of an image.\nSource: http://www.diyphotography.net/diy_create_your_own_bokeh/",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Questions?\nFor next time:\n– Read Szeliski, Chapter 3.1-3.2",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/02-Filtering.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computer Vision\nLihi Zelnik-Manor lihi@ee.technion.ac.il",
    "offset": "page1",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "de"
  },
  {
    "filetype": "application/pdf",
    "text": "Color\nColor\n`\nReadings:\n– Forsyth and Ponce, Chapter 6 – Szeliski, 2.3.2",
    "offset": "page2",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\nTrevor Darrell • Kristen Grauman: 3-48, 50-75, 79-86 • Bob Woodham: 49, 87-90 • and others, indirectly (Steve Palmer, Brian Wandell, etc!)",
    "offset": "page3",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page4",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color and light\nColor of light arriving at camera depends on\n– Spectral reflectance of the surface light is leaving – Spectral radiance of light falling on that patch\nColor perceived depends on\n– Physics of light – Visual system receptors – Brain processing, environment",
    "offset": "page5",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color and light\nWhite light: composed of about equal energy in all wavelengths of the visible spectrum\nNewton 1665\nImage from http://micro.magnet.fsu.edu/",
    "offset": "page6",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Electromagnetic spectrum\nHuman Luminance Sensitivity Function\nImage credit: nasa.gov",
    "offset": "page7",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Measuring spectra\nSpectroradiometer: separate input light into its different wavelengths, and measure the energy at each.\nFoundations of Vision, B. Wandell",
    "offset": "page8",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Spectral power distribution\nThe power per unit area at each wavelength of a radiant object\n# Photons(per ms.)\n400 500 600 700Wavelength (nm.)\nFigure © Stephen E. Palmer, 2002",
    "offset": "page9",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Spectral power distributions\nSome examples of the spectra of light sources\n# PhotonsD. Normal DaylightWavelength (nm.)B. Gallium Phosphide Crystal400 500 600 700# PhotonsWavelength (nm.)A. Ruby Laser\n# PhotonsC. Tungsten Lightbulb400 500 600 700\n.\n400 500 600 700400 500 600 700\n# Photons\n© Stephen E. Palmer, 2002",
    "offset": "page10",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The color viewed is also affected by the surface’s spectral reflectance properties.\nSpectral reflectances for some natural objects: how much of each wavelength is reflected for that surface\nForsyth & Ponce, measurements by E. Koivisto",
    "offset": "page11",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "d e\nt c e\nl f\ne R s n o\nt\no h P %\nSurface reflectance spectra\nSome examples of the reflectance spectra of surfaces\nRed\nYellow\nBlue\nPurple\n400 700\n400 700\n400 700\n400 700\nWavelength (nm)\n© Stephen E. Palmer, 2002",
    "offset": "page12",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nThere is no simple functional description for the perceived color of all lights under all viewing conditions, but …...\nA helpful constraint:\nConsider only physical spectra with normal distributions\nmean\nWavelength (nm.)# Photons400700\n500600\narea\nvariance\n© Stephen E. Palmer, 2002",
    "offset": "page13",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nMean\nHue\ns n o\nt\no h P #\nyellowgreenblue\nWavelength\n© Stephen E. Palmer, 2002",
    "offset": "page14",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nVariance\nSaturation\nhighmediumlow\nhi.med.low\ns n o\nt\no h P #\nWavelength\n© Stephen E. Palmer, 2002",
    "offset": "page15",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "The Psychophysical Correspondence\nArea\nBrightness\ns n o\nt\no h P #\nbrightdark\nB. Area Lightness\nWavelength\n© Stephen E. Palmer, 2002",
    "offset": "page16",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color mixing\nCartoon spectra for color names:\nSource: W. Freeman",
    "offset": "page17",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Additive color mixing\nColors combine by adding color spectra\nLight adds to black.\nSource: W. Freeman",
    "offset": "page18",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Examples of additive color systems\nCRT phosphors\nmultiple projectors\nhttp://www.jegsworks.com\nhttp://www.crtprojectors.co.uk/",
    "offset": "page19",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Subtractive color mixing\nColors combine by multiplying color spectra.\nPigments remove color from incident light (white).\nSource: W. Freeman",
    "offset": "page20",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Examples of subtractive color systems\nPrinting on paper • Most photographic film",
    "offset": "page21",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page22",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Why specify color numerically?\nAccurate color reproduction is commercially valuable – Many products are identified by color\nFew color names are widely recognized by English speakers – 11: black, blue, brown, grey, green, orange, pink, purple, red, white, and\nyellow.\n– Other languages have fewer/more. – Common to disagree on appropriate color names.\nColor reproduction problems increased by prevalence of digital imaging – e.g. digital libraries of art. – How to ensure that everyone perceives the same color? – What spectral radiances produce the same response from people under\nsimple viewing conditions?\nForsyth & Ponce",
    "offset": "page23",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nGoal:\nWhat spectral radiances produce same response in human observers?",
    "offset": "page24",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nObserver adjusts weight (intensity) for primary lights (fixed SPD’s) to match appearance of test light.\nFoundations of Vision, by Brian Wandell, Sinauer Assoc., 1995\nAfter Judd & Wyszecki.",
    "offset": "page25",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiments\nGoal:\nWhat spectral radiances produce same response in human observers?\nAssumption:\nUnder simple viewing conditions only “test light” affects perception – Ignoring additional factors for now like adaptation,\ncomplex surrounding scenes, etc.",
    "offset": "page26",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights",
    "offset": "page27",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page28",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page29",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 1\nTest light\nPrimary lights\nThe primary color amounts needed for a match\np1 p2 p3",
    "offset": "page30",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights",
    "offset": "page31",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page32",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide credit: W. Freeman\nColor matching experiment 2\nTest light\nPrimary lights\np1 p2 p3",
    "offset": "page33",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching experiment 2\nWe say a “negative” amount of p2 was needed to make the match, because we added it to the test color’s side.\nTest light\nPrimary lights\nThe primary color amounts needed for a match:\np1 p2 p3\np1 p2 p3\np1 p2 p3",
    "offset": "page34",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color matching\nWhat must we require of the primary lights chosen? • How are three numbers enough to represent entire spectrum?\nWhat must we require of the primary lights chosen? • How are three numbers enough to represent entire 121233ecolorePPPe\nweights",
    "offset": "page35",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Metamers\nLights forming a perceptual match still may be physically different\n– Match light: a combination of primaries – Test light: any light\nMetamers: pairs of lights that match perceptually but not physically\nDifferent spectrum\nSame primary mixture weights",
    "offset": "page36",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "How to compute the weights of the primaries to match any new spectral signal?\nGiven: a choice of three primaries and a target color signal\nFind: weights of the primaries needed to match the color signal\n?\np1 p2 p3\ne1\ne2 e3\nChallenge: we cannot use manual tuning for all colors in the world",
    "offset": "page37",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\n1.\nSelect primaries\n2. Collect weights for all monochromatic lights:\n112131ccc\nPut them in a big matrix:\n111212313()()()()()()NNNcccccc",
    "offset": "page38",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\n1.\nSelect primaries\n2. Collect weights for all monochromatic lights:\n112131ccc\n3. Compute the weights of any color by:\n1111121223133()()()()()()NNNNtccecceccet",
    "offset": "page39",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\nArbitrary new spectral signal is linear combination of the monochromatic sources.\n)()(1Nttt\nt\n…\nColor matching functions specify how to match a unit of each wavelength, so:\n)()()()()()()()()(21313212111321NNNNtttcccccceee\nCte\nKristen Grauman",
    "offset": "page40",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Computing color matches\nWhy is computing the color\nmatch for any color signal for a given set of primaries useful? – Want to paint a carton of Kodak film\nwith the Kodak yellow color. – Want to match skin color of a\nperson in a photograph printed on an ink jet printer to their true skin color.\n– Want the colors in the world, on a monitor, and in a print format to all look the same.\nAdapted from W. Freeman\nImage credit: pbs.org",
    "offset": "page41",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page42",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Standard color spaces\nUse a common set of primaries/color matching functions\nLinear color space examples\n– RGB – CIE XYZ\nNon-linear color space\n– HSV – CIE LAB",
    "offset": "page43",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "RGB color space\nSingle wavelength primaries • Good for devices (e.g., phosphors for monitor), but not for perception\nRGB color matching functions",
    "offset": "page44",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE XYZ color space\nEstablished by the commission international d’eclairage (CIE), 1931\nUsually projected to display: (x,y) = (X/(X+Y+Z), Y/(X+Y+Z))\nCIE XYZ Color matching functions",
    "offset": "page45",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Distances in color space\nAre distances between points in a color space perceptually meaningful?",
    "offset": "page46",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Distances in color space\nNot necessarily: CIE XYZ is not a uniform color space, so magnitude of differences in coordinates are poor indicator of color “distance”.\nMcAdam ellipses: Just noticeable differences in color",
    "offset": "page47",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE XYZ\nUniform color spaces\nCIE Lu’v’\nCIE Lab",
    "offset": "page48",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "es"
  },
  {
    "filetype": "application/pdf",
    "text": "CIE LAB color space\nEstablished by the CIE in 1948 and then 1976 • Goal: perceptually uniform",
    "offset": "page49",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "HSV color space\nHue, Saturation, Value (Brightness) • Nonlinear – reflects topology of colors by coding hue as an angle\nIntuitive for color picking\nImage from mathworks.com",
    "offset": "page50",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page51",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color\nColor of light arriving at camera depends on\n– Spectral reflectance of the surface light is leaving – Spectral radiance of light falling on that patch\nColor perceived depends on\n– Physics of light – Visual system receptors – Brain processing, environment",
    "offset": "page52",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nRods responsible for intensity -Cones responsible for color -Fovea: small region (1 or 2°) at the center of the visual field containing the highest density of cones (and no rods). – Less visual acuity in the periphery\nAdapted from Seitz, Duygulu",
    "offset": "page53",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Two types of light-sensitive receptors\nCones\ncone-shaped less sensitive operate in high light color vision\nRods\nrod-shaped highly sensitive operate at night gray-scale vision\n© Stephen E. Palmer, 2002\nSlide credit: Alyosha Efros",
    "offset": "page54",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nReact only to some\nwavelengths, with different sensitivity (light fraction absorbed)\nThree kinds of cones\nBrain fuses responses from local neighborhood of several cones for perceived color\nSensitivities vary from person to person, and with age\ny t i v i t i s n e S\nColor blindness: deficiency in at least one type of cone\nWavelength (nm)",
    "offset": "page55",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Human photoreceptors\nPossible evolutionary pressure for developing receptors for different wavelengths in primates\nOsorio & Vorobyev, 1996",
    "offset": "page56",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Trichromacy\nExperimental facts:\n– Three primaries will work for most people if we\nallow subtractive matching; “trichromatic” nature of the human visual system\n– Most people make the same matches for a given set of primaries (i.e., select the same mixtures)",
    "offset": "page57",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Environmental effects & adaptation\nChromatic adaptation: we adapt to a particular illuminant\nAssimilation, contrast effects, chromatic induction: nearby colors affect what is perceived; receptor excitations interact across image and time\nAfterimages\nColor matching ~= color appearance\nPhysics of light ~= perception of light",
    "offset": "page58",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nIf the visual system is exposed to a certain illuminant for a while, color system starts to adapt / skew.",
    "offset": "page59",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page60",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page61",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Chromatic adaptation\nhttp://www.planetperplex.com/en/color_illusions.html",
    "offset": "page62",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page63",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page64",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Brightness perception\nEdward Adelson\nhttp://web.mit.edu/persci/people/adelson/illusions_demos.html",
    "offset": "page65",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page66",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page67",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Look at blue squares\nLook at yellow squares\nContent © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page68",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page69",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page70",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page71",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "fr"
  },
  {
    "filetype": "application/pdf",
    "text": "Content © 2008 R.Beau Lotto • http://www.lottolab.org/articles/illusionsoflight.asp",
    "offset": "page72",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "it"
  },
  {
    "filetype": "application/pdf",
    "text": "After images\nTired photoreceptors send out negative response after a strong stimulus\nhttp://www.sandlotscience.com/Aftereffects/Andrus_Spiral.htm\nSource: Steve Seitz",
    "offset": "page73",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "After images\nTired photoreceptors send out negative response after a strong stimulus\nhttp://www.sandlotscience.com/Aftereffects/Andrus_Spiral.htm\nSource: Steve Seitz",
    "offset": "page74",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Name that color\nHigh level interactions affect perception and processing.",
    "offset": "page75",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page76",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\nBlobworld system, Carson et al, 1999",
    "offset": "page77",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\ns t n u o c\nl\ne x i P\nR\nG\nColor intensity\nB\nColor histograms: Use distribution of colors to describe image\nNo spatial info – invariant to translation, rotation, scale",
    "offset": "page78",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color as a low-level cue for CBIR\nCompute distance between histograms:\nIntersection\nSimilar\nDifferent",
    "offset": "page79",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nGiven a collection (database) of images:\n– Extract and store one color histogram per image\nGiven new query image:\n– Extract its color histogram – For each database image:\nCompute intersection between query histogram and database histogram\n– Sort intersection values (highest score = most similar) – Rank database items relative to query based on this sorted\norder",
    "offset": "page80",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample database",
    "offset": "page81",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample retrievals",
    "offset": "page82",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based image retrieval\nExample retrievals",
    "offset": "page83",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "http://images.google.com/\nSearch for similar images. Try:\nBuildings • Dogs • Concert",
    "offset": "page84",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Shazam for Fashion\nThere are several products doing that. • They have to deal with color similarity: – E.g.: http://www.spylight.com/",
    "offset": "page85",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Shazam for Fashion\nThere are several products doing that. • They have to deal with color similarity: – E.g.: http://www.asap54.com/",
    "offset": "page86",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nM. Jones and J. Rehg, Statistical Color Models with Application to Skin Detection, IJCV 2002.",
    "offset": "page87",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection",
    "offset": "page88",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nhttp://www.ghvandoorn.nl/skindetection.html",
    "offset": "page89",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based skin detection\nOpenCV\nhttps://www.youtube.com/watch?v=vZk9k9azonw",
    "offset": "page90",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based tracking\nD. Ramanan, D. Forsyth, and A. Zisserman. Tracking People by Learning their Appearance. PAMI 2007.\nSlide credit: L. Lazebnik",
    "offset": "page91",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Color-based tracking\nhttp://www.roborealm.com/tutorial/color_obj ect_tracking_2/slide010.php\nhttps://www.youtube.com/watch?v=WPnWD Gl3XZc",
    "offset": "page92",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Viewing Colored Objects",
    "offset": "page93",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Slide Credits\nTrevor Darrell • Kristen Grauman: 3-48, 50-75, 79-86 • Bob Woodham: 49, 87-90 • and others, indirectly (Steve Palmer, Brian Wandell, etc!)",
    "offset": "page94",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  },
  {
    "filetype": "application/pdf",
    "text": "Today: Color\nMeasuring color\n– Spectral power distributions – Color mixing – Color matching experiments – Color spaces\nUniform color spaces\nPerception of color\n– Human photoreceptors – Environmental effects, adaptation\nUsing color in machine vision systems",
    "offset": "page95",
    "ref": "/home/ameer/Kaleidoo/server/uploads/04-Color.pdf",
    "lang": "en"
  }
]

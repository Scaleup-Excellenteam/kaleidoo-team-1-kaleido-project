{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import time \n",
    "import psutil\n",
    "from  paths import ENGPATH1,ENGPATH2,ENGPATH3,RUSSPATH1, VOSKENGMOD\n",
    "# Load pre-trained Wav2Vec2 model and tokenizer\n",
    "# TODO: Find a model that can recognize a language, \n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(tokenizer, speech, model):\n",
    "    # Tokenize the audio\n",
    "    input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "\n",
    "    # Get the model's predictions\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Decode the predicted token IDs back to text\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    return tokenizer.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Transformer-------------------------------------------\n",
      "\n",
      "--------------------------audio1_converted.wav---------------------------------------\n",
      "Transcription: SO TELL ME WHAT DO YOU THINKS CAN HAPPEN ANYWAY A MONSTERS GOING TI COME OUT AT THE CUPOD I DON'T THINK SIR NO THAT'S JUST YO MIND PLAYIN CHECKS ON YE YE GE DINNER\n",
      "Elapsed time: 1.74 seconds\n",
      "CPU usage at end: 61.6%\n",
      "Memory used at start: 14461.80 MB\n",
      "Memory used at end: 14675.32 MB\n",
      "--------------------------audio2_converted.wav---------------------------------------\n",
      "Transcription: THE BIRCH CANEN SLID ON THE SMOOTH PLANK GLE THE CHEET TO THE DARK BLUE BACKGROUND IT IS EASY TO TELL THE DEPTH OF THE WELL THESE DAY A CHICK A MEG IS A RARE DISH RICE IS OTEN SERVED IN ROUND BULL THE JUICE OF LONDONS MAKES FINE PUNCH THE BOX WAS THOWNL  BESIDE THE PARK TRUK THE HOX WAS FED CHOPPED CORN AND GARBAGE FOUR HOURS A STEADY WORK FACED US E LARGE SIDE AN STOCKINGS IS HARD TO SELL\n",
      "Elapsed time: 3.18 seconds\n",
      "CPU usage at end: 76.1%\n",
      "Memory used at start: 14677.34 MB\n",
      "Memory used at end: 14555.17 MB\n",
      "--------------------------audio3_converted.wav---------------------------------------\n",
      "Transcription: I WANT TO DANCE CAN YOU HELP ME\n",
      "Elapsed time: 0.25 seconds\n",
      "CPU usage at end: 77.0%\n",
      "Memory used at start: 14555.11 MB\n",
      "Memory used at end: 14569.88 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def monitor_resources(file_path):\n",
    "    # Record the start time and resource usage\n",
    "    start_time = time.time()\n",
    "    start_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    start_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    # Read audio file and perform transcription\n",
    "    speech, sample_rate = sf.read(file_path)\n",
    "    transcription = transcript(tokenizer, speech, model)\n",
    "\n",
    "    # Record the end time and resource usage\n",
    "    end_time = time.time()\n",
    "    end_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    end_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Transcription: {transcription}\")\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"CPU usage at end: {end_cpu_percent}%\")\n",
    "    print(f\"Memory used at start: {start_memory_info:.2f} MB\")\n",
    "    print(f\"Memory used at end: {end_memory_info:.2f} MB\")\n",
    "\n",
    "# Process multiple files\n",
    "print('-------------------------------Transformer-------------------------------------------')\n",
    "print()\n",
    "print('--------------------------audio1_converted.wav---------------------------------------')\n",
    "monitor_resources(ENGPATH1)\n",
    "print('--------------------------audio2_converted.wav---------------------------------------')\n",
    "monitor_resources(ENGPATH2)\n",
    "print('--------------------------audio3_converted.wav---------------------------------------')\n",
    "monitor_resources(ENGPATH3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np \n",
    "from paths import *\n",
    "import time \n",
    "import psutil\n",
    "import os\n",
    "import soundfile  as sf \n",
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_audio_segment(segment_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    audio = whisper.load_audio(segment_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    result = model.transcribe(audio)\n",
    "    return result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(ms):\n",
    "    return str(datetime.timedelta(milliseconds=ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transcribe a single audio segment\n",
    "def transcribe_segment(file_path, start_time, end_time, tokenizer, model):\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    segment = audio[start_time:end_time]\n",
    "    segment.export(\"segment.wav\", format=\"wav\")\n",
    "    speech, sample_rate = sf.read(\"segment.wav\")\n",
    "    \n",
    "    # Transcribe the audio segment\n",
    "    inputs = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\")\n",
    "    logits = model(**inputs).logits\n",
    "    predicted_ids = logits.argmax(axis=-1)\n",
    "    transcription = tokenizer.decode(predicted_ids[0])\n",
    "    \n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_transcribe(file_path, interval_ms, output_json_path):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    duration_ms = len(audio)\n",
    "    num_segments = int(np.ceil(duration_ms / interval_ms))\n",
    "    \n",
    "    transcript_data = []\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        start_time_ms = i * interval_ms\n",
    "        end_time_ms = min((i + 1) * interval_ms, duration_ms)\n",
    "        \n",
    "        segment = audio[start_time_ms:end_time_ms]\n",
    "        segment_file_path = f\"segment_{i + 1}.wav\"\n",
    "        segment.export(segment_file_path, format=\"wav\")\n",
    "        \n",
    "        transcript = transcribe_audio_segment(segment_file_path)\n",
    "        \n",
    "        transcript_data.append({\n",
    "            \"offset\": f'{format_time(start_time_ms)}, {format_time(end_time_ms)}',\n",
    "            \"text\": transcript,\n",
    "            'lang':detect(transcript)\n",
    "        })\n",
    "        os.remove(segment_file_path)\n",
    "    \n",
    "    \n",
    "    if output_json_path :\n",
    "        with open(output_json_path, 'a+') as f:\n",
    "            f.seek(0)\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []\n",
    "            existing_data.append({\n",
    "                       \"type\": \"audio\",\n",
    "                        \"ref\": file_path,\n",
    "                        'met_data': transcript_data,\n",
    "                        })\n",
    "            f.seek(0)\n",
    "            f.truncate()\n",
    "\n",
    "            json.dump(existing_data, f,indent=4)\n",
    "\n",
    "            print(f'Data successfully written to {file_path}')    \n",
    "    else:\n",
    "        return json.dumps(transcript_data, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_resources(file_path, time_interval, out_put_json):\n",
    "    # Record the start time and resource usage\n",
    "    start_time = time.time()\n",
    "    start_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    start_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "\n",
    "    print(segment_and_transcribe(file_path, time_interval,out_put_json))\n",
    "\n",
    "    # Record the end time and resource usage\n",
    "    end_time = time.time()\n",
    "    end_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    end_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"CPU usage at end: {end_cpu_percent}%\")\n",
    "    print(f\"Memory used at start: {start_memory_info:.2f} MB\")\n",
    "    print(f\"Memory used at end: {end_memory_info:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Transformer-------------------------------------------\n",
      "\n",
      "--------------------------audio1_converted.wav---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to /home/ameer/Kaleidoo/Audio_Data/English/A1.wav\n",
      "None\n",
      "Elapsed time: 4.01 seconds\n",
      "CPU usage at end: 43.3%\n",
      "Memory used at start: 4645.68 MB\n",
      "Memory used at end: 4680.36 MB\n",
      "None\n",
      "--------------------------audio2_converted.wav---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to /home/ameer/Kaleidoo/Audio_Data/English/A2.wav\n",
      "None\n",
      "Elapsed time: 6.27 seconds\n",
      "CPU usage at end: 45.7%\n",
      "Memory used at start: 4680.36 MB\n",
      "Memory used at end: 4511.80 MB\n",
      "None\n",
      "--------------------------audio3_converted.wav---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to /home/ameer/Kaleidoo/Audio_Data/English/A3.wav\n",
      "None\n",
      "Elapsed time: 2.32 seconds\n",
      "CPU usage at end: 41.5%\n",
      "Memory used at start: 4511.80 MB\n",
      "Memory used at end: 4539.42 MB\n",
      "None\n",
      "--------------------------img-processing.mp3-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to /home/ameer/Kaleidoo/Audio_Data/English/img-processing.mp3\n",
      "None\n",
      "Elapsed time: 24.96 seconds\n",
      "CPU usage at end: 44.5%\n",
      "Memory used at start: 4539.42 MB\n",
      "Memory used at end: 4506.57 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "time_interval_ms = 80000 # Segment length in milliseconds (e.g., 10000 ms = 10 seconds)\n",
    "output_json = \"transcriptions.json\"  # Output JSON file path\n",
    "\n",
    "\n",
    "\n",
    "print('-------------------------------Transformer-------------------------------------------')\n",
    "print()\n",
    "print('--------------------------audio1_converted.wav---------------------------------------')\n",
    "print ( monitor_resources(ENGPATH1, time_interval_ms,output_json) )\n",
    "print('--------------------------audio2_converted.wav---------------------------------------')\n",
    "print( monitor_resources(ENGPATH2, time_interval_ms,output_json) )\n",
    "print('--------------------------audio3_converted.wav---------------------------------------')\n",
    "print( monitor_resources(ENGPATH3, time_interval_ms,output_json) )\n",
    "print('--------------------------img-processing.mp3-----------------------------------------')\n",
    "print(monitor_resources(ENGPATH4, time_interval_ms,output_json) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

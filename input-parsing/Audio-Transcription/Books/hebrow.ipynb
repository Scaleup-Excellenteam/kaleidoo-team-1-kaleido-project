{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.0.0-py3-none-any.whl (474 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 KB\u001b[0m \u001b[31m657.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Requirement already satisfied: filelock in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Collecting fsspec[http]<=2024.6.1,>=2023.1.0\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, six, safetensors, regex, pyyaml, packaging, numpy, multidict, idna, fsspec, frozenlist, dill, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, python-dateutil, pyarrow, multiprocess, aiosignal, pandas, huggingface-hub, aiohttp, tokenizers, transformers, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.3.2 datasets-3.0.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.6.1 huggingface-hub-0.25.0 idna-3.10 multidict-6.1.0 multiprocess-0.70.16 numpy-2.1.1 packaging-24.1 pandas-2.2.2 pyarrow-17.0.0 python-dateutil-2.9.0.post0 pytz-2024.2 pyyaml-6.0.2 regex-2024.9.11 requests-2.32.3 safetensors-0.4.5 six-1.16.0 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.2 tzdata-2024.1 urllib3-2.2.3 xxhash-3.5.0 yarl-1.11.1\n",
      "Requirement already satisfied: torch in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: networkx in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: sympy in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: filelock in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: jinja2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets\n",
    "!pip install torch  # for PyTorch backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: setuptools in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting keras>=3.2.0\n",
      "  Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pygments, protobuf, optree, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, opt-einsum, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 pygments-2.18.0 rich-13.8.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tokens for masked position: ['מומלץ']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch \n",
    "\n",
    "# Load the tokenizer and model for HeBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"avichr/HeBERT\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"avichr/HeBERT\")\n",
    "\n",
    "# Example usage: Tokenize some Hebrew text with a mask\n",
    "text = \"הספר הזה מאוד [MASK]\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Run the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predictions for the masked token\n",
    "predictions = outputs.logits\n",
    "\n",
    "# Decode the predictions\n",
    "masked_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "predicted_ids = torch.argmax(predictions[0, masked_index], dim=-1)\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_ids)\n",
    "\n",
    "print(\"Predicted tokens for masked position:\", predicted_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Replace 'bert-base-uncased' with your HBERT model identifier\n",
    "model_name = \"bert-base-uncased\"  # Example public model\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torchaudio) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: fsspec in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (2024.6.1)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (1.13.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchaudio) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from jinja2->torch==2.4.1->torchaudio) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "test_dataset = load_dataset(\"common_voice\", \"he\", split=\"test\") # there is no common dataset for Hebrew, please, paste your data\n",
    "wer = load_metric(\"wer\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"imvladikon/wav2vec2-large-xlsr-53-hebrew\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"imvladikon/wav2vec2-large-xlsr-53-hebrew\").to(\"cuda\")\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays\n",
    "def speech_file_to_array_fn(batch):\n",
    "  batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()\n",
    "  speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "  batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "  return batch\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays\n",
    "def evaluate(batch):\n",
    "  inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "  with torch.no_grad():\n",
    "    logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "  pred_ids = torch.argmax(logits, dim=-1)\n",
    "  batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "  return batch\n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[2024-09-19 09:58:08.920] [ctranslate2] [thread 143738] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.\n"
     ]
    }
   ],
   "source": [
    "import faster_whisper\n",
    "\n",
    "# Load the Whisper model (change 'ivrit-ai/faster-whisper-v2-d4' to the correct model path if necessary)\n",
    "model = faster_whisper.WhisperModel('ivrit-ai/faster-whisper-v2-d4')\n",
    "\n",
    "# Specify the path to the media file (audio or video)\n",
    "media_file_path = '/home/ameer/Kaleidoo/Data/Audio_Data/Hebrow/test.mp3'  # Replace with actual media file\n",
    "\n",
    "# Transcribe the media file with the model, specifying the language\n",
    "segs, _ = model.transcribe(media_file_path, language='he')  # 'he' for Hebrew\n",
    "\n",
    "# Extract the text segments from the transcription\n",
    "texts = [s.text for s in segs]\n",
    "\n",
    "# Join all the text segments into a single string\n",
    "transcribed_text = ' '.join(texts)\n",
    "\n",
    "# Print the final transcribed text\n",
    "print(f'Transcribed text: {transcribed_text}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

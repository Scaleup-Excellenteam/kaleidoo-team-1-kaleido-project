{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np \n",
    "from paths import *\n",
    "import soundfile  as sf \n",
    "from langdetect import detect, detect_langs\n",
    "import time \n",
    "import psutil\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_audio_segment(segment_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    audio = whisper.load_audio(segment_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    result = model.transcribe(audio)\n",
    "    return result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(ms):\n",
    "    return str(datetime.timedelta(milliseconds=ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transcribe a single audio segment\n",
    "def transcribe_segment(file_path, start_time, end_time, tokenizer, model):\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    segment = audio[start_time:end_time]\n",
    "    segment.export(\"segment.wav\", format=\"wav\")\n",
    "    speech, sample_rate = sf.read(\"segment.wav\")\n",
    "    \n",
    "    # Transcribe the audio segment\n",
    "    inputs = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\")\n",
    "    logits = model(**inputs).logits\n",
    "    predicted_ids = logits.argmax(axis=-1)\n",
    "    transcription = tokenizer.decode(predicted_ids[0])\n",
    "    \n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_transcribe(file_path, interval_ms, output_json_path):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    duration_ms = len(audio)\n",
    "    num_segments = int(np.ceil(duration_ms / interval_ms))\n",
    "    \n",
    "    transcript_data = []\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        start_time_ms = i * interval_ms\n",
    "        end_time_ms = min((i + 1) * interval_ms, duration_ms)\n",
    "        \n",
    "        segment = audio[start_time_ms:end_time_ms]\n",
    "        segment_file_path = f\"{GARBAGE}segment_{i + 1}.wav\"\n",
    "        segment.export(segment_file_path, format=\"wav\")\n",
    "        \n",
    "        transcript = transcribe_audio_segment(segment_file_path)\n",
    "        \n",
    "        transcript_data.append({\n",
    "            \"offset\": f'{format_time(start_time_ms)}, {format_time(end_time_ms)}',\n",
    "            \"text\": transcript,\n",
    "            'lang':detect(transcript)\n",
    "        })\n",
    "        os.remove(segment_file_path)\n",
    "    \n",
    "    \n",
    "    if output_json_path :\n",
    "        with open(output_json_path, 'a+') as f:\n",
    "            f.seek(0)\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []\n",
    "            existing_data.append({\n",
    "                       \"type\": \"audio\",\n",
    "                        \"ref\": file_path,\n",
    "                        'met_data': transcript_data,\n",
    "                        })\n",
    "            f.seek(0)\n",
    "            f.truncate()\n",
    "\n",
    "            json.dump(existing_data, f,indent=4)\n",
    "\n",
    "            print(f'Data successfully written to {file_path}')    \n",
    "    else:\n",
    "        return json.dumps(transcript_data, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_resources(file_path, time_interval, out_put_json):\n",
    "    # Record the start time and resource usage\n",
    "    start_time = time.time()\n",
    "    start_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    start_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "\n",
    "    print(segment_and_transcribe(file_path, time_interval,out_put_json))\n",
    "\n",
    "    # Record the end time and resource usage\n",
    "    end_time = time.time()\n",
    "    end_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    end_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"CPU usage at end: {end_cpu_percent}%\")\n",
    "    print(f\"Memory used at start: {start_memory_info:.2f} MB\")\n",
    "    print(f\"Memory used at end: {end_memory_info:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from moviepy) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from moviepy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from moviepy) (2.35.1)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.4.0)\n",
      "Requirement already satisfied: setuptools in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (59.6.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: SpeechRecognition in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ameer/Kaleidoo/.venv/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install moviepy\n",
    "%pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_path, audio_path):\n",
    "    try:\n",
    "        # Load the video file\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        \n",
    "        # Extract the audio and save it as an audio file\n",
    "        video.audio.write_audiofile(audio_path)\n",
    "        print(f\"Audio extracted and saved to {audio_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting audio: {e}\")\n",
    "\n",
    "def transcribe_audio_segment(segment_path):\n",
    "    # Initialize the recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Load the audio file\n",
    "    with sr.AudioFile(segment_path) as source:\n",
    "        audio_data = recognizer.record(source)  # Read the audio file\n",
    "\n",
    "    # Convert speech to text\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech was not understood\"\n",
    "    except sr.RequestError:\n",
    "        return \"Could not request results from the speech recognition service\"\n",
    "\n",
    "def format_time(ms):\n",
    "    return str(datetime.timedelta(milliseconds=ms))\n",
    "\n",
    "def segment_and_transcribe(audio_path, interval_ms, output_json_path):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    duration_ms = len(audio)\n",
    "    num_segments = int(np.ceil(duration_ms / interval_ms))\n",
    "    \n",
    "    transcript_data = []\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        start_time_ms = i * interval_ms\n",
    "        end_time_ms = min((i + 1) * interval_ms, duration_ms)\n",
    "        \n",
    "        segment = audio[start_time_ms:end_time_ms]\n",
    "        segment_file_path = f\"{GARBAGE}segment_{i + 1}.wav\"\n",
    "        segment.export(segment_file_path, format=\"wav\")\n",
    "        \n",
    "        transcript = transcribe_audio_segment(segment_file_path)\n",
    "        \n",
    "        transcript_data.append({\n",
    "            \"offset\": f'{format_time(start_time_ms)}, {format_time(end_time_ms)}',\n",
    "            \"text\": transcript,\n",
    "            'lang': detect(transcript)\n",
    "        })\n",
    "        os.remove(segment_file_path)\n",
    "    \n",
    "    if output_json_path:\n",
    "        with open(output_json_path, 'a+') as f:\n",
    "            f.seek(0)\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []\n",
    "            existing_data.append({\n",
    "                \"type\": \"video\",\n",
    "                \"ref\": audio_path,\n",
    "                'met_data': transcript_data,\n",
    "            })\n",
    "            f.seek(0)\n",
    "            f.truncate()\n",
    "            json.dump(existing_data, f, indent=4)\n",
    "            print(f'Data successfully written to {output_json_path}')\n",
    "    else:\n",
    "        return json.dumps(transcript_data, indent=4)\n",
    "\n",
    "def monitor_resources(audio_path, time_interval, output_json):\n",
    "    # Record the start time and resource usage\n",
    "    start_time = time.time()\n",
    "    start_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    start_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    print(segment_and_transcribe(audio_path, time_interval, output_json))\n",
    "\n",
    "    # Record the end time and resource usage\n",
    "    end_time = time.time()\n",
    "    end_cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    end_memory_info = psutil.virtual_memory().used / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"CPU usage at end: {end_cpu_percent}%\")\n",
    "    print(f\"Memory used at start: {start_memory_info:.2f} MB\")\n",
    "    print(f\"Memory used at end: {end_memory_info:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /home/ameer/Kaleidoo/Data/Audio_Data/English/audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted and saved to /home/ameer/Kaleidoo/Data/Audio_Data/English/audio.wav\n",
      "Data successfully written to /home/ameer/Kaleidoo/Data/Data-Dumper/Video/transcriptions2.json\n",
      "None\n",
      "Elapsed time: 69.52 seconds\n",
      "CPU usage at end: 0.7%\n",
      "Memory used at start: 3017.07 MB\n",
      "Memory used at end: 2720.25 MB\n",
      "Temporary audio file /home/ameer/Kaleidoo/Data/Audio_Data/English/audio.wav removed\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "output_json = f'{DUMPVIDEO}transcriptions2.json'\n",
    "time_interval_ms = 80000  # Segment length in milliseconds (e.g., 10000 ms = 10 seconds)\n",
    "\n",
    "# Step 1: Extract audio from video\n",
    "extract_audio_from_video(TONNY, AUDIO_TONNY)\n",
    "\n",
    "# Step 2: Segment and transcribe the extracted audio\n",
    "monitor_resources(AUDIO_TONNY, time_interval_ms, output_json)\n",
    "\n",
    "# Clean up\n",
    "if os.path.exists(AUDIO_TONNY):\n",
    "    os.remove(AUDIO_TONNY)\n",
    "    print(f\"Temporary audio file {AUDIO_TONNY} removed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
